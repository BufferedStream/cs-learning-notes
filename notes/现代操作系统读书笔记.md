## 现代操作系统读书笔记

读书目的：了解操作系统的基本概念，学习操作系统中的经典算法。



### 第 1 章	引论

现代计算机系统由一个或多个处理器、主存、磁盘、打印机、键盘、鼠标、显示器、网络接口以及各种其它输入/输出设备组成。一般而言，现代计算机系统是一个复杂的系统。如果每位语言程序员都不得不掌握系统的所有细节，那就不可能再编写代码了。而且，管理这些部件并加以优化实验，是一件挑战性极强的工作。所以，计算机安装了一层软件，称为**操作系统**，它的任务是为用户程序提供一个更好、更简单、更清晰的计算机模型，并管理刚才提到的所有设备。本书的主体就是操作系统。

多数读者都会对诸如 Windows、Linux、FreeBSD 或 OS X 等某个操作系统有些体验，但表面现象是会骗人的。用户与之交互的程序，基于文本的通常称为 **shell**，而基于图标的则称为**图形用户界面**（Graphical User Interface，GUI），它们实际上并不是操作系统的一部分，尽管这些程序使用操作系统来完成工作。

图 1-1 给出了这里所讨论的主要部件的一个简化视图。图的底部是硬件。硬件包括芯片、电路板、磁盘、键盘、显示器以及类似的设备。在硬件的顶部是软件。多数计算机有两种运行模式：内核态和用户态。软件中最基础的部分是操作系统，它运行在**内核态**（也称为**管态**、**核心态**）。在这个模式中，操作系统具有对所有硬件的完全访问权，可以执行机器能够运行的任何指令。软件的其余部分运行在**用户态**下。在用户态下，只使用了机器指令中的一个子集。特别地，那些会影响机器的控制或可进行 **I/O**（输入/输出）操作的指令，在用户态中的程序里是禁止的。在本书中，我们会不断地讨论内核态和用户态之间的差别，这些差别在操作系统的运作中扮演着极其重要的角色。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE1.jpg"/>
</div>

用户接口程序（shell 或者 GUI）处于用户态程序中的最低层次，允许用户运行其他程序，诸如 Web 浏览器、电子邮件阅读器或音乐播放器等。这些程序也大量使用操作系统。

操作系统所在的位置如图 1-1 所示。它运行在裸机之上，为所有其他软件提供基础的运行环境。

操作系统和普通软件（用户态）之间的主要区别是，如果用户不喜欢某个特定的电子邮件阅读器，他可以自由选择另一个，或者自己写一个，但是不能自行写一个属于操作系统一部分的时钟中断处理程序。这个程序由硬件保护，防止用户试图对其进行修改。

然而，有时在嵌入式系统（该系统没有内核态）或解释系统（如基于 Java 的操作系统，它采用解释方式而非硬件方式区分组件）中，上述区别是模糊的。

另外，在许多系统中，一些在用户态下运行的程序协助操作系统完成特权功能。例如，经常有一个程序供用户修改其口令之用。但是这个程序不是操作系统的一部分，也不在内核态下运行，不过它明显地带有敏感的功能，并且必须以某种方式给予保护。在某些系统中，这种想法被推向了极致，一些传统上被认为是操作系统的部分（诸如文件系统）在用户空间中运行。在这类系统中，很难划分出一条明显的界限。在内核态中运行的当然是操作系统的一部分，但是一些在内核外运行的程序也有争议地被认为是操作系统地一部分，或者至少与操作系统密切相关。



#### 1.1	什么是操作系统

很难给出操作系统的准确定义。操作系统是一种运行在内核态的软件——尽管这个说法并不总是符合事实。部分原因是操作系统有两个基本上独立的任务，即为应用程序员（实际上是应用程序）提供一个资源集的清晰抽象，并管理这些硬件资源，而不仅仅是一堆硬件。另外，还取决于从什么角度看待操作系统。读者多半听说过其中一个或另一个的功能。下面我们逐项进行讨论。



##### 1.1.1	作为扩展机器的操作系统

在机器语言一级上，多数计算机的体系结构（指令集、存储组织、I/O 和总线结构）是很原始的，而且编程是很困难的，尤其是对输入/输出操作而言。为了更细致地考察这一点。我们以大多数电脑使用的更现代的 **SATA**（Serial ATA）硬盘为例。曾有一本描述早期版本硬盘接口（程序员为了使用硬盘而需要了解的东西）的书，它的页数超过 450 页。自 2007 年起，接口又被修改过很多次，因而比当时更加复杂。显然，没有任何理智的程序员想要在硬件层面上和硬盘打交道。相反，他们使用一些叫做**硬盘驱动**（disk driver）的软件来和硬件交互。这类软件提供了读写硬盘块的接口，而不用深入细节。操作系统包含很多用于控制输入/输出设备的驱动。

但就算是在这个层面，对于大多数应用来说还是太底层了。因此，所有的操作系统都提供使用硬盘的又一层抽象：文件。使用该抽象，程序能创建、读写文件，而不用处理硬件实际工作中那些恼人的细节。

抽象是管理复杂性的一个关键。好的抽象可以把一个几乎不可能管理的任务划分成为两个可管理的部分。其第一部分是有关抽象的定义和实现，第二部分是随时用这些抽象解决问题。几乎每个计算机用户都理解的一个抽象是文件，正如上文所提到的。文件是一种有效的信息片段，诸如数码照片、保存的电子邮件、歌曲或 Web 页面等。处理数码照片、电子邮件、歌曲以及 Web 页面等，要比处理 SATA（或者其他）硬盘的细节容易，这些磁盘的具体细节与前面叙述过的软盘一样。操作系统的任务是创建好的抽象，并实现和管理它所创建的抽象对象。本书中，我们将研究许多关于抽象的内容，因为这是理解操作系统的关键。

上述观点是非常重要的，所以值得用不同的表达方式来再次叙述。即使怀着如此小心翼翼对设计 Macintosh 机器的工业设计师的尊重，还是不得不说，硬件是丑陋的。真实的处理起、内存条、磁盘和其他装置都是非常复杂的，对于那些为使用某个硬件而不得不编写软件的人们而言，他们使用的是困难、特殊和不一致的接口。有时这是由于需要兼容旧的硬件，有时是为了节省成本，但是，有时硬件设计师们并没有意识到（或在意）他们给软件设计带来了多大的麻烦。操作系统的一个主要任务是隐藏硬件，呈现给程序（以及程序员）良好、清晰、优雅、一致的抽象。如图 1-2 所示，操作系统将丑陋转变为美丽。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE7.jpg"/>
</div>

需要指出的是，操作系统的实际客户是应用程序（当然是通过应用程序员）。它们直接与操作系统及其抽象打交道。相反，最终用户与用户接口所提供的抽象打交道，或者是命令行 shell 或者是图形接口。而用户接口的抽象可以与操作系统提供的抽象类似，但也不总是这样。为了更清晰地说明这一点，请读者考虑普通的 Windows 桌面以及面向行的命令提示符。两者都是运行在 Windows 操作系统上的程序，并使用了 Windows 提供的抽象，但是它们提供了非常不同的用户接口。类似地，运行 Gnome 或者 KDE 的 Linux 用户与直接在 X Window 系统（面向文本）顶部工作的 Linux 用户看到的是非常不同的界面，但是在这两种情形中，操作系统下面的抽象是相同的。

在本书中，我们将具体讨论提供给应用程序的抽象，不过很少涉及用户界面。尽管用户界面是一个巨大和重要的课题，但是它们毕竟只和操作系统的外围相关。



##### 1.1.2	作为资源管理者的操作系统

把操作系统看做向应用程序提供基本抽象的概念，是一种自顶向下的观点。按照另一种自底向上的观点，操作系统则用来管理一个复杂系统的各个部分。现代计算机包含处理器、存储器、时钟、磁盘、鼠标、网络接口、打印机以及许多其他设备。从这个角度看，操作系统的任务是在相互竞争的程序之间有序地控制对处理器、存储器以及其他 I/O 接口设备的分配。

现代操作系统允许同时在内存中运行多道程序。假设在一台计算机上运行的三个程序试图同时在同一台打印机上输出计算结果，那么开始的几行可能是程序 1 的输出，接着几行是程序 2 的输出，然后又是程序 3 的输出等，最终结果将是一团糟。采用将打印结果送到磁盘上缓冲区的方法，操作系统可以把潜在的混乱有序化。在一个程序结束后，操作系统可以将暂存在磁盘上的文件送到打印机输出，同时其他程序可以继续产生更多的输出结果，很明显，这些程序的输出还没有真正送至打印机。

当一个计算机（或网络）有多个用户时，管理和保护存储器、I/O 设备以及其他资源的需求变得强烈起来，因为用户间可能会互相干扰。另外，用户通常不仅共享硬件，还要共享信息（文件、数据库等）。简而言之，操作系统的这种观点认为，操作系统的主要任务是记录哪个程序在使用什么资源，对资源请求进行分配，评估使用代价，并且为不同的程序和用户调解互相冲突的资源请求。

资源管理包括用以下两种不同方式实现**多路复用**（共享）资源：在时间上复用和在空间上复用。当一种资源在时间上复用时，不同的程序或用户轮流使用它。先是第一个获得资源的使用，然后下一个，以此类推。例如，若在系统中只有一个 CPU，而多个程序需要在该 CPU 上运行，操作系统则首先把该 CPU 分配给某个程序，在它运行了足够长的时间之后，另一个程序得到 CPU，然后是下一个，如此进行下去，最终，轮到第一个程序再次运行。至于资源是如何实现时间复用的——谁应该是下一个以及运行多长时间等——则是操作系统的任务。还有一个有关时间复用的例子是打印机的共享。当多个打印作业在一台打印机上排队等待打印时，必须决定将轮到打印的是哪个作业。

另一类复用是空间复用，每个客户都得到资源的一部分，从而取代了客户排队。例如，通常在若干运行程序之间分割内存，这样每一个运行程序都可同时入驻内存（例如，为了轮流使用 CPU）。假设有足够的内存可以存放多个程序，那么在内存中同时存放若干个程序的效率，比把所有内存都分给一个程序的效率要高得多，特别是，如果一个程序只需要整个内存的一小部分，结果更是这样。当然，如此的做法会引起公平、保护等问题，这有赖于操作系统解决它们。有关空间复用的其他资源还有磁盘。在许多系统中，一个磁盘同时为许多用户保存文件。分配磁盘空间并记录谁正在使用哪个磁盘块，是操作系统的典型任务。



#### 1.2	操作系统的历史

**批处理系统**（batch system）。其思想是：在输入室收集全部的作业，然后用一台相对便宜的计算机如 IBM 1401 计算机将它们读到磁带上。IBM 1401 计算机适用于读卡片、复制磁带和输出打印，但不适用于数值运算。另外用较昂贵的计算机如 IBM 7094 来完成真正的计算。这些情况如图 1-3 所示。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE2.jpg"/>
</div>

**多道程序设计**（multiprogramming）。在 7094 机上，若当前作业因等待磁盘或其他 I/O 操作而暂停，CPU 就只能简单地踏步直至该 I/O 完成。对于 CPU 操作密集的科学计算问题，I/O 操作较少，因而浪费的时间很少。然而，对于商业数据处理，I/O 操作等待的时间通常占到 80%~90%，所以必须采取某种措施减少（昂贵的）CPU 空闲时间的浪费。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE3.jpg"/>
</div>

解决方案是将内存分为几个部分，每一部分存放不同的作业，如图 1-5 所示。当一个作业等待 I/O 操作完成时，另一个作业可以使用 CPU。如果内存中可以同时存放足够多的作业，则 CPU 利用率可以接近 100%。在内存中同时驻留多个作业需要特殊的硬件来对其进行保护，以避免作业的信息被窃取或受到攻击。360 及其他第三代计算机都配有此类硬件。



**分时系统（timesharing）**：它实际上是多道程序的一个变体，每个用户都有一个联机终端。在分时系统中，假设有 20 个用户登录，其中 17 个在思考、讨论或喝咖啡，则 CPU 可分派给其他三个需要的作业轮流执行。由于调式程序的用户常常只发出简短的命令（如编译一个五页的源文件），而很少有长的费时命令（比如上百万条的文件排序），所以计算机能够为许多用户提供快速的交互时服务，同时在 CPU 空闲时还可能在后台运行一个大作业。第一个通用的分时系统——**兼容分时系统**（Compatible Time Sharing System，CTSS），是 MIT在一台改装过的 7094 机上开发成功的。但直到第三台计算机广泛采用了必需的保护硬件之后，分时系统才逐渐流行开来。



**POSIX**：IEEE 提出的 UNIX 的标准。posix 定义了一个凡是 UNIX 必须支持的小型系统调用接口。事实上，某些其他操作系统也支持 POSIX 接口。



**x86**：在本书中我们使用 **x86** 则会个术语代表所有使用指令集体系结构家族的现代处理器。



**网络操作系统**和**分布式操作系统**：在网络操作系统中，用户知道多台计算机的存在，能够登录到一台远程机器上并将文件从一台机器复制到另一台机器，每台计算机都运行自己本地的操作系统，并有自己的本地用户（或多个用户）。

网络操作系统与单处理器的操作系统没有本质区别。很明显，它们需要一个网络接口控制器以及一些底层软件来驱动它，同时还需要一些程序来运行远程登录和远程文件访问，但这些附加成分并未改变操作系统的本质。

相反，分布式操作系统是以一种传统单处理器操作系统的形式出现在用户面前的，尽管它实际上是由多处理器组成的。用户应该不知晓自己的程序在何处运行或者自己的文件存放于何处，这些应该由操作系统自动和有效地处理。

真正的分布式操作系统不仅仅是在单机操作系统上增添一小段代码，因为分布式系统与集中式系统有本质的区别。例如，分布式系统通常允许一个应用在多台处理器上同时运行，因此，需要更复杂的处理器调度算法来获得最大的并行度优化。

网络中的通信延迟往往导致分布式赛算法必须能适应信息不完备、信息过时甚至信息不正确的环境。这与单机系统完全不同，对于后者，操作系统掌握着整个系统的完备信息。





#### 1.3	计算机硬件简介

操作系统与运行该操作系统的计算机硬件联系密切。操作系统扩展了计算机指令并管理计算机的资源。为了能够工作，操作系统必须了解大量的硬件，至少需要了解硬件如何面对程序员。处于这个原因，这里我们先简要地介绍现代个人计算机中的计算机硬件，然后开始讨论操作系统的具体工作细节。

从概念上讲，一台简单的个人计算机可以抽象为类似于图 1.6 中的模型。CPU、内存以及 I/O 设备都由一条系统总线连接起来并通过总线与其他设备通信。现代个人计算机结构更加复杂，包含多重总线，我们将在后面讨论。目前，这一模式还是够用的。在下面葛小姐中，我们将简要地介绍这些部件，并且讨论一些操作系统设计师所考虑的硬件问题。毫无疑问，这是一个非常简要的概括介绍。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE4.jpg"/>
</div>





##### 1.3.1	处理器

计算机的 “大脑” 是 CPU，它从内存中取出指令并执行之。在每个 CPU 基本周期中，首先从内存中取出指令，解码以确定其类型和操作数，接着执行之，然后取值、解码并执行下一条指令。按照这一方式，程序被执行完成。

每个 CPU 都有一套可执行的专门指令集。所以，X86 处理器不能执行 ARM 程序，而 ARM 处理器也不能执行 x86 程序。**由于用来访问内存以得到指令或数据的时间要比执行指令花费的时间长得多，因此，所有的 CPU 内都有一些用来保存关键变量和临时数据的寄存器**。这与，通常在指令集中提供一些指令，用以将一个字从内存调入寄存器，以及将一个字从寄存器存入内存。其他得指令可以把来自寄存器、内存的操作数组合，或者用两者产生一个结果，如将两个字相加并把结果存在寄存器或内存中。

除了用来保存变量和临时结果的通用寄存器之外，多数计算机还有一些对程序员可见的专用寄存器，其中之一是**程序计数器**（IP），它保存了将要取出的下一条指令的内存地址。在指令取出之后，程序计数器就被更新以便指向后继的指令。

另一个寄存器是**堆栈指针**（SP），它指向内存中当前栈的顶端。该栈包含了每个执行过程的栈帧。一个过程的栈帧中保存了有关的输入参数、局部变量以及那些没有保存在寄存器中的临时变量。

当然还有**程序状态字**（Program Status Word，PSW）寄存器。这个寄存器包含了条件码位（由比较指令设置）、CPU 优先级、模式（用户态或内核态），以及各种其他控制位。用户程序通常读入整个 PSW，但是，只对其中的少量字段写入。在系统调用和 I/O 中，PSW 的作用很重要。

操作系统必须知晓所有的寄存器。在时间多路复用（time multiplexing）CPU 中，操作系统经常会中止正在运行的某个程序并启动（或再启动）另一个程序。每次停止一个运行着的程序时，操作系统必须保存所有的寄存器值，这样在稍后该程序被再次运行时，可以把这些寄存器重新装入。

为了改善性能，CPU 设计师早就放弃了同时读取、解码和执行一条指令的简单模型。许多现代 CPU 具有同时取出多条指令的机制。例如，一个 CPU 可以有单独的取指单元、解码单元和执行单元，于时当它执行指令 n 时，还可以同时对指令 n+1 解码，并且读取指令 n+2。这与的机制称为**流水线**（pipeline），图 1-7a 是一个有着三个阶段的流水线示意图。更长的流水线也是常见的。在多数的流水线设计中，一旦一条指令被取进流水线中，它就必须被执行完毕，即便前一条取出的指令是条件转移，它也必须被执行完毕。流水线使得编译器和操作系统的编写者很头疼，因为它造成了在机器中实现这些软件的复杂性问题，而机器必须处理这些问题。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE5.jpg"/>
</div>



比流水线更先进的设计是**超标量** CPU，如图 1-7b 所示。在这种设计中，有多个执行单元，例如，一个 CPU 用于整数算术运算，一个 CPU 用于浮点算术运算，一个 CPU 用于布尔运算。两个或更多的指令被同时取出、解码并装入暂存缓冲区中，直至它们执行完毕。只要有一个执行单元空闲，就检查保持缓冲区中是否还有可处理的指令，如果有，就把指令从缓冲区中移出并执行之。这种设计存在一种隐含的作用，即程序的指令经常不按顺序执行。在多数情况下，硬件负责保证这种运算的结果与顺序执行指令时的结果相同，但是，仍然有部分令人烦恼的复杂情形被强加给操作系统处理，我们在后面会讨论这种情况。

除了用在嵌入式系统中的非常简单的 CPU 之外，多数 CPU 都有两种模式，即前面已经提及的内核态和用户态。通常，在 PSW 中有一个二进制位控制这两种模式。当在内核态运行时，CPU 可以执行指令集中的每一条指令，并且使用硬件的每种功能。在台式机和服务器上，操作系统在内核态下运行，从而可以访问整个硬件。而在大多数嵌入式系统中，一部分操作系统运行在内核态，其余的部分则运行在用户态。

相反，用户程序在用户态下运行，仅允许执行整个指令集的一个子集和访问所有功能的一个子集。一般而言，在用户态中有关 I/O 和内存保护的所有指令是禁止的。当然，将 PSW 中的模式位设置成内核态也是禁止的。

为了从操作系统中获得服务，用户程序必须使用**系统调用**（system call）以陷入内核并调用操作系统。TRAP 指令把用户态切换成内核态，并启用操作系统。当有关工作完成之后，在系统调用后面的指令把控制权返回给用户程序。在本章的后面我们将具体解释系统调用过程，但是在这里，请读者把它看成是一个特别的过程调用指令，该指令具有从用户态切换到内核态的特别能力。

有必要指出的是，计算机使用陷阱而不是一条指令来执行系统调用。其他的多数陷阱是由硬件引起的，用于警告有异常情况发生，如试图被零除或浮点下溢等。在所有的情况下，操作系统都得到控制权并决定如何处理异常情况。有时，由于出错的原因，程序不得不停止。在其他情况下可以忽略出错（如下溢数可以被置为零）。最后，若程序已经提前宣布它希望处理某类条件，那么控制权还必须返回给该程序，让其处理相关的问题。



**多线程和多核芯片**

Intel Pentium 4 引入了被称为**多线程**（multithreading）或**超线程**（hyperthreading，这是 Intel 公司的命名）的特性，x86 处理器和其他一些 CPU 芯片就是这样做的，包括 SPARC、Power5、Intel Xeon 和 Intel Core 系列。近似地说，多线程允许 CPU 保持两个不同的线程状态，然后在纳秒级的时间尺度内来回切换。（线程是一种轻量级进程，即一个运行中的程序。我们将在第 2 章中具体讨论。）例如，如果某个进程需要从内存中读出一个字（需要花费多个时钟周期），多线程 CPU 则可以切换至另一个线程。多线程不提供真正的并行处理。在一个时刻只有一个进程在运行，但是线程的切换时间则减少到纳秒数量级。

多线程对操作系统而言是有意义的，因为每个线程在操作系统看来就像是单个的 CPU。考虑一个实际有两个 CPU 的系统，每个 CPU 有两个线程。这样操作系统将把它看成是 4 个 CPU。如果在某个特定时间点上，只有能够维持两个 CPU 忙碌的工作量，那么在同一个 CPU 上调度两个线程，而让另一个 CPU 完全空转，就没有优势了。这种选择远远不如在每个 CPU 上运行一个线程的效率高。



##### 1.3.2	存储器

在任何一种计算机中，第二种主要部件都是存储器。在理想情形下，存储器应该极为迅速（快于执行一条指令，这样 CPU 不会受到存储器的限制），充分大，而且非常便宜。但是目前的计数无法同时满足这三个目标，于是出现了不同的处理凡是。存储器系统采用一种分层次的机构，如图 1-9 所示。顶层的存储器速度较高，容量较小，与底层的存储器相比每位成本较高，其差别往往是十亿数量级。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE6.jpg"/>
</div>



存储器系统的顶层是 CPU 中的寄存器。它们用与 CPU 相同的材料制成，所以和 CPU 一样快。显然，访问它们是没有时延的。其典型的存储容量是，在 32 位 CPU 中为 32×32 位，而在 64 位 CPU 中为 64×64 位。在这两种情形下，其存储容量都小于 1KB。程序必须在软件中自行管理这些寄存器（即决定如何使用它们）。

下一层是高速缓存，它多数由硬件控制。主存被分割成**高速缓存行**（cache line），其典型大小为 64 字节，地址 0 至 63 对应高速缓存行 1，以此类推。最常用的高速缓存行放置在 CPU 内部或者非常接近 CPU 的高速缓存中。当某个程序需要读一个存储字时，高速缓存硬件检查所需要的高速缓存行是否在高速缓存中。如果是，称为**高速缓存命中**，缓存满足了请求，就不需要通过总线把请求送往内存。高速缓存命中通常需要两个时钟周期。高速缓存未命中就必须访问内存，这要付出大量的时间代价。由于高速缓存的价格昂贵，所以其大小有限。有些机器具有两级甚至三级高速缓存，每一级高速缓存比前一级慢且容量更大。

缓存在计算机科学的许多领域中起着重要的作用，并不仅仅是 RAM 的缓存行。只要存在大量的资源可以划分为小的部分，那么，这些资源中的某些部分就会比其他部分更频繁地得到使用，通常缓存的使用会带来性能上的改善。操作系统一直在使用缓存。例如，多数操作系统在内存中共保留频繁使用的文件（的一部分），以避免从磁盘中重复地调取这些文件。相似地，类似于

/home/ast/projects/minix3/src/kernel/clock.c

的长路径名转换成文件所在的磁盘地址的结果，也可以放入缓存，以避免重复寻找地址。还有，当一个 Web 页面（URL）的地址转换为网络地址（IP 地址）后，这个转换结果也可以缓存起来供将来使用。还有许多其他的类似应用。

在任何缓存系统中，都有若干需要尽快考虑的问题，包括：

1. 何时把一个新的内容放入缓存。
2. 把新内容放在缓存的哪一行上。
3. 在需要时，应该把哪个内容从缓存汇总移走。
4. 应该把新移走的内容放在某个较大存储器的何处。

并不是每个问题的解决方案都符合每种缓存处理。对于 CPU 缓存中的主存缓存行，每当有缓存未命中时，就会调入新的内容。通常通过所引用内存地址的高位计算应该使用的缓存行。例如，对于 64 字节的 4096 个缓存行以及 32 位地址，其中 6~17 位用来定位缓存行，而 0~5 位则用来确定缓存行中的字节。在这个例子中，被移走内容的位置就是新数据要进入的位置，但是在有的系统中未必是这样。最后，当将一个缓存行的内容重写进主存时（该内容被缓存后，可能会被修改），通过该地址来唯一确定需重写的主存位置。

在图 1-9 的层次结构中，再往下一层是主存。这是存储器系统的助力。主存通常称为**随机访问存储器（Ra**ndom Access Memory，RAM）。过去有时称之为**磁芯存储器**，因为在 20 世纪 50 年代和 60 年代，使用很小的可磁化的铁磁体制作主存。虽然它们已经绝迹了很多年，但名称还是传承了下来。目前，存储器的容量在几百兆字节到若干吉字节之间，并且其容量正在迅速增长。所有不能在高速缓存中得到满足的访问请求都会转往主存。

除了主存之外，许多计算机已经在使用少量的非易失性随机访问存储器。它们与 RAM 不同，在电源切断之后，非易失性随机访问存储器并不丢失其内容。**只读存储器**（Read Only Memory，ROM）在工厂中就被编程完毕，然后再也不能被修改。ROM 速度快且便宜。在有些计算机中，用于启动计算机的引导加载模块就存放在 ROM 中。另外，一些 I/O 卡也采用 ROM 处理底层设备控制。

**EEPROM**（Electrically Erasable PROM，电可擦除可编程 ROM）和**闪存**（flash memory）也是非易失性的，但是与 ROM 相反，它们可以擦除和重写。不过重写它们需要比写入 RAM 更高数量级的时间，所以它们的使用方式与 ROM 相同，而其与众不同的特点使它们有可能通过字段重写的方式纠正所保存程序中的错误。

在便携式电子设备中共，闪存通常作为存储媒介。闪存是数码相机中的胶卷，是便携式音乐播放器的磁盘，这仅仅是闪存用途中的两项。闪存在速度上介于 RAM 和磁盘之间。另外，与磁盘存储器不同，如果闪存擦除的次数过多，就被磨损了。

还有一类存储器是 CMOS，它是易失性的。许多计算机利用 CMOS 存储器保持当前时间和日期。CMOS 存储器和递增时间的时钟电路由一小块电池驱动，所以，即使计算机没有上电，时间也仍然可以正确地更新。CMOS 存储器还可以保存配置参数，如哪一个是启动磁盘等。之所以采用 CMOS 是因为它消耗的电能非常少。



##### 1.3.3	磁盘

下一个层次是磁盘（硬盘）。磁盘同 RAM 相比，每个二进制位的成本低了两个数量级，而且经常也有两个数量级大的容量。磁盘唯一的问题是随机访问数据时间大约慢了三个数量级。其低速的原因是因为磁盘是一种机械装置，如图 1-10 所示。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE8.jpg"/>
</div>

在一个磁盘中有一个或多个金属盘片，它们以 5400rpm、7200rpm、10800rpm 或更高的速度旋转。从边缘开始有一个机械臂悬横在盘面上，这类似于老式播放塑料唱片 33 转唱机上的拾音臂。信息写在磁盘的一系列同心圆上。在任意一个给定臂的位置，每个磁头可以读取一段环形区域，称为**磁道**（track）。把一个给定臂的位置上的所有磁道合并起来，组成了一个**柱面**（cylinder）。

每个磁道划分为若干扇区，扇区的典型值是 512 字节。在现代磁盘中，较外部的柱面比较内部的柱面有更多的扇区。机械臂从一个柱面移到相邻的柱面大约需要 1ms。而随机移到一个柱面的典型时间为 5ms 至 10ms，其具体时间取决于驱动器。一旦磁臂到达正确的磁道上，驱动器就必须等待所需的扇区旋转到磁头之下，这就增加了 5ms 至 10ms 的时延，其具体延时取决于驱动器的转速。一旦所需要的扇区移到磁头之下，就开始读写，低端磁盘的速率是 50MB/s，而高速磁盘的速率是 160MB/s。

有时，你会听到人们在讨论一些实际上根本不是磁盘的磁盘，比如**固态硬盘**（Solid State Disk，SSD）。固态硬盘并没有可以移动的部分，外形也不像唱片那样，并且数据是存储在存储器（闪存）中的。与磁盘唯一的相似之处就是它也存储了大量即使在电源关闭时也不会丢失的数据。

许多计算机支持一种著名的虚拟内存机制，这将在第 3 章周工讨论。这种机制使得期望运行大于物理内存的程序称为可能，其方法是将程序放在磁盘上，而将主存作为一种缓存，用来保存最频繁使用的部分程序。这种机制需要快速地映像内存地址，以便把程序生成的地址转换为有关字节在 RAM 中的物理地址。这种映像由 CPU 中的一个称为**存储器管理单元**（Memory Management Unit，MMU）的部件来完成，如图 1-6 所示。

缓存和 MMU 的出现对系统的性能有着重要的影响。在多道程序系统中，从一个程序切换到另一个程序，有时称为**上下文切换**（context switch），有必要对来自缓存的所有修改过的块进行写回磁盘操作，并修改 MMU 中的映像寄存器。但是这两种操作的代价很昂贵，所以程序员努力避免使用这些操作。我们稍后将看到这些操作产生的影响。



##### 1.3.4	I/O 设备

CPU 和存储器不是操作系统唯一需要管理的资源。I/O 设备也与操作系统有密切的相互影响。如图 1-6 所示，I/O 设备一遍包括两个部分：设备控制器和设备本身。控制器事插在电路板上的一块芯片或一组芯片，这块电路板物理地控制设备。它从操作系统接受命令，例如，从设备读数据，并且完成数据的处理。

在许多情形下，对这些设备的控制事非常复杂和具体的，所以，控制器的任务是为操作系统提供一个简单的接口（不过还是很复杂）。例如，磁盘控制器可以接受一个命令从磁盘 2 读出 11206 号扇区，然后，控制器把这个线性扇区号转化为柱面、扇区和磁头。由于外柱面比内柱面有较多的扇区，而且一些坏扇区已经被映射到磁盘的其他地方，所以这种转换是很复杂的。磁盘控制器必须确定磁头臂应该在哪个柱面上，并对磁头臂发出指令以使其前后移动到所要求的柱面号上，接着必须等待对应的扇区转动到磁头下面并开始读出数据，随着数据从驱动器读出，要消去引导块并计算校验和。最后，还得把输入的二进制位组成字并存放到存储器中。为了完成这些工作，在控制器中经常安装一个小的嵌入式计算机，该嵌入式计算机运行为执行这些工作而专门编好的程序。

I/O 设备的另一个部分是实际设备的自身。设备本身有个相对简单的接口，这是一位内接口既不能做很多工作，又已经被标准化了。例如，标准化后任何一个 SATA 磁盘控制器就可以适配任一种 SATA 磁盘，所以标准化是必要的。**ATA** 代表**高级技术附件**（AT Attachment），而 **SATA** 表示**串行高级技术附件**（Serail ATA）。

现在 SATA 是很多计算机的标准硬盘接口。由于实际的标准接口隐藏在控制器中，所以，操作系统看到的是对控制器的接口，这个接口可能和设备接口有很大的差别。

每类设备控制器都是不同的，所以，需要不同的软件进行控制。专门与控制器对话，发出命令并接受响应的软件，称为**设备驱动程序**（device driver）。每个控制器厂家必须为所支持的操作系统提供相应的设备驱动程序。

为了能够使用设备驱动程序，必须把设备驱动程序装入操作系统中，这样它可在核心态运行。设备驱动程序可以在内核外运行，现代的 Linux 和 Windows 操作系统也的确对这种方式提供一些支持。绝大多数驱动程序仍然需要在内核态运行。只有很少一部分现代系统（如 MINIX 3）在用户态运行全部驱动程序。在用户态运行的驱动程序必须能够以某种受控的方式访问折别，然而这并不容易。

要将设备驱动程序装入操作系统，有三个途径。第一个途径是将内核与设备驱动程序重新链接，然后重启系统。许多 UNIX 系统以这种方式工作。第二个途径是在一个操作系统文件中设置一个入口，并通知该文件需要一个设备驱动程序，然后重启系统。在系统启动时，操作系统去找寻所需的设备驱动程序并装载之。Windows 就是以这种方式工作。第三种途径是，操作系统能够在运行时接受新的设备驱动程序并且立即将其安装好，无须重启系统。这种方式采用得较少，但是正在变得普及起来。热插拔设备，诸如 USB 和 IEEE 1394 设备都需要动态可装载设备驱动程序。

每个设备控制器都有少量用于通信的寄存器。例如，一个最小的磁盘控制器也会有用于指定磁盘地址、内存地址、扇区计数和方向（读或写）的寄存器。要激活控制器，设备驱动程序从操作系统获得一条命令，然后翻译成对应的值，并写进设备寄存器中。所有设备寄存器的集合构成了 **I/O 端口空间**，我们将在第 5 章讨论有关内容。

在有些计算机中，设备寄存器被映射到操作系统的地址空间（操作系统可使用的地址）。这样，它们就可以像普通存储字一样读出和写入。在这种计算机中，不需要专门的 I/O 指令，用户程序可以被硬件阻挡在外，防止其接触这些存储器地址（例如，采用基址和界限寄存器）。在另外一些计算机中，设备寄存器被放入一个专门的 I/O 端口空间中，每个寄存器都有一个端口地址。在这些机器中，提供在内核态中可使用的专门 IN 和 OUT 指令，供设备驱动程序读写这些寄存器用。前一种方式不需要专门的 I/O 指令，但是占用了一些地址空间。后者不占用地址空间，但是需要专门的指令。这两种方式的应用都很广泛。

实现输入和输出的方式有三种。在最简单的方式中，用户程序发出一个系统调用，内核将其翻译成一个对应设备驱动程序的过程调用。然后设备驱动程序启动 I/O 并在一个连续不断的循环中检查该设备，看该设备是否完成了工作（一般有一些二进制位用来指示设备仍在忙碌中）。当 I/O 结束后，设备驱动程序把数据送到指定的地方（若有此需要），并返回。然后操作系统将控制返回给调用者。这种方式称为**忙等待**（busy waiting），其缺点是要占据 CPU，CPU 一直轮询设备直到对应的 I/O 操作完成。

第二种方式是设备驱动程序启动设备并且让该设备在操作完成时发出一个中断。设备驱动程序在这个时刻返回。操作系统接着在需要时阻塞调用者并安排其他工作进行。当设备驱动程序监测到该设备的操作完毕时，它发出一个**中断**通知操作完成。

在操作系统中，中断是非常重要的，所以需要更具体地讨论。在图 1-11a 中，有一个 I/O 的三部三步过程。在第 1 步，设备驱动程序通过写设备寄存器通知设备控制器做什么。然后，设备控制器启动该设备。当设备控制器传送完毕被告知要进行读写的字节数量后，它在第 2 步中使用特定的总线发信号给中断控制器芯片。如果中断控制器已经准备接收中断（如果正忙于一个更高级的中断，也可能不接收），它会在 CPU 芯片的一个管脚上声明，这就是第 3 步。在第 4 步中，中断控制器把该设备的编号放到总线上，这样 CPU 可以读总线，并且知道哪个设备刚刚完成了操作（可能同时有许多设备在运行）。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE9.jpg"/>
</div>

一旦 CPU 决定取中断，通常程序计数器和 PSW 就被压入当前堆栈中，并且 CPU 被切换到用户态。设备编号可以成为部分内存的一个引用，用于寻找该设备中断处理程序的地址。这部分内存被称为**中断向量**（interrupt vector）。当中断处理程序（中断设备的设备驱动程序的一部分）开始后，它取走已入栈的程序计数器和 PSW，并保存之，然后查询设备的状态。在中断处理程序全部完成之后，它返回到先前运行的用户程序中尚未执行的头一条指令。这些步骤如图 1-11b 所示。

第三种方式是，为 I/O 使用一种特殊的**直接存储器访问**（Direct Memory Access，DMA）芯片，它可以控制在内存和某些控制器之间的位流，而无须持续的 CPU 干预。CPU 对 DMA 芯片进行设置，说明需要传送的字节数、有关的设备和内存地址以及操作方向，接着启动 DMA。当 DMA 芯片完成时，它引发一个中断，其处理方式如前所述。有关 DMA 和 I/O 硬件会在第 5 章中具体讨论。

中断会（并且经常会）在非常不合适的时刻发生，比如，在另一个中断程序正在运行时发生。正由于此，CPU 有办法关闭中断并在稍后再开启中断。在中断关闭时，任何已经发出中断的设备，可以继续保持其中断信号，但是 CPU 不会被中断，直至中断再次启用为止。如果在关闭中断时，已有多个设备发出了中断，中断控制器将决定先处理哪个中断，通常这取决于事先赋予每个设备的静态优先级。最高优先级的设备赢得竞争并且首先获得服务，其他设备则必须等待。



##### 1.3.5	总线

略



##### 1.3.6	启动计算机

简要启动过程如下。在每台计算机上有一块双亲板（在政治因素影响到计算机充业之前，它们曾称为 “母板”）。在双亲板上有一个称为**基本输入输出系统**（Basic Input Output System，BIOS）的程序。在 BIOS 内有底层 I/O 软件，包括读键盘、写屏幕、进行磁盘 I/O 以及其他过程。现在这个程序存放在一块闪速 RAM 中，它是非易失性的，但是在发现 BIOS 中有错时可以通过操作系统对它进行更新。

在计算机启动时，BIOS 开始运行。它首先检查所安装的 RAM 数量，键盘和其他设备是否已安装并正常响应。接着，它开始扫描 PCIe 和 PCI 总线并找出连在上面的所有设备。即插即用设备也被记录下来。如果现有的设备和系统上一次启动时的设备不同，则新的设备将被配置。

然后，BIOS 通过尝试存储在 CMOS 存储器中的设备清单决定启动设备。用户可以在系统刚启动之后进入一个 BIOS 配置程序，对设备清单进行修改。典型地，如果存在 CD-ROM（有时是 USB），则系统试图从中启动；如果失败，系统将从硬盘启动。启动设备上的第一个扇区被读入内存并执行。这个扇区包含一个对保存在启动扇区末尾的分区表检查的程序，以确定哪个分区是活动的。然后，从该分区读入第二个启动装载模块。来自活动分区的这个装载模块被读入操作系统，并启动之。

然后，操作系统询问 BIOS，以获得配置信息。对于每种设备，系统检查对应的设备驱动程序是否存在。如果没有，系统要求用户插入含有该设备驱动程序的 CD-ROM（由设备供应商提供）或者从网络上下载驱动程序。一旦有了全部的设备驱动程序，操作系统就将它们调入内核。然后初始化有关表格，创建需要的任何背景进程，并在每个终端上启动登录程序或 GUI。



#### 1.4	操作系统大观园

略



#### 1.5	操作系统该概念

多数操作系统都使用某些基本概念和抽象，如进程、地址空间以及文件等，它们是需要理解的核心内容。作为引论，在下面的几节中，我们将较为简单地考察这些基本概念中的一部分。在本书的后面，我们将详细地讨论它们。为了说明这些概念，我们有时使用示例，这些示例通常源自 UNIX。不过，类似的例子在其他操作系统中也明显地存在，我们将在之后深入了解其中的一些操作系统。



##### 1.5.1	进程

在所有操作系统中，一个重要的概念是**进程**（process）。进程本质上是正在执行的一个程序。与每个进程相关的是**地址空间**（address space），这是从某个最小值的存储位置（通常是零）到某个最大值的存储位置的列表。在这个地址空间中，进程可以进行读写。该地址空间中存放有可执行程序、程序的数据以及程序的堆栈。与每个进程相关的还有资源集，通常包括寄存器（含有程序计数器和堆栈指针）、打开文件的清单、突出的报警、有关进程清单，以及运行该程序所需要的所有其他信息。进程基本上是容纳运行一个程序所需要所有信息的容器。

进程的概念将在第 2 章详细讨论，不过，对进程建立一种直观感受的最便利方式是分析一个多道程序设计系统。用户启动一个视频编辑程序，指示它按照某个格式转换一小时的视频（有时会花费数小时），然后离开去浏览网页。同时，一个被周期性唤醒、用来检查进来的电子邮件的后台进程会开始运行。这样，我们就有了（至少）三个活动进程：视频编辑器、Web 浏览器以及电子邮件接收程序。操作系统周期性地挂起一个进程然后启动运行另一个进程，这可能是由于在过去的一两秒钟内，第一个进程已使用完分配给它的时间片。

一个进程暂时被挂起后，在随后的某个时刻里，该进程再次启动时的状态必须与先前暂停时完全相同，这就意味着在挂起时该进程的所有信息都要保存下来。例如，为了同时读入信息，进程打开了若干文件。与每个被打开文件有关的是指向当前位置的指针（即下一个将读出的字节或记录）。在一个进程暂时被挂起时，所有这些指针都必须保存起来，这样在该进程重新启动之后，所执行的读调用才能读到正确的数据。在许多操作系统中，与一个进程有关的所有信息，除了该进程自身地址空间的内容以外，均存放在操作系统的一张表中，称为**进程表**（process table），进程表是数组（或链表）结构，当前存在的每个进程都要占用其中一项。

所以，一个（挂起的）进程包括：进程的地址空间（往往称为**磁芯映像**，core image，纪念过去使用的磁芯存储器），以及对应的进程表项（其中包括寄存器以及稍后重启该进程所需要的许多其他信息）。

与进程管理有关的最关键的系统调用是那些进程创建和进程终止的系统调用。考虑一个典型的例子。有一个称为**命令解释器**（command interpreter）或 **shell** 的进程从终端中读命令。此时，用户刚键入一条命令要求编译一个程序。shell 必须先创建一个新进程来执行编译程序。当执行编译的进程结束时，它执行一个系统调用来终止自己。

若一个进程能够创建一个或多个进程（称为**子进程**），而且这些进程又可以创建子进程，则很容易得到进程树，如图 1-13 所示。合作完成某些作业的相关进程经常需要彼此通信以便同步它们的行为。这种通信称为**进程间通信**（interprocess communication），将在第 2 章中详细讨论。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE10.jpg"/>
</div>

其他可用的进程系统调用包括：申请更多的内容（或释放不再需要的内存）、等待一个子进程结束、用另一个程序覆盖该程序等。

有时，需要向一个正在运行的进程传送信息，而该进程并没有等待接收信息。例如，一个进程通过网络向另一台机器上的进程发送消息进行通信。为了保证一条消息或消息的应答不会丢失，发送者要求它所在的操作系统在指定的若干秒后给一个通知，这样如果对方尚未收到确认消息就可以进行重发。在设定该定时器后，程序可以继续做其他工作。

在限定的秒数流逝之后，操作系统向该进程发送一个**警告信号**（alarm signal）。此信号引起该进程暂时挂起，无论该进程正在做什么，系统将其寄存器的值保存到堆栈，并开始运行一个特别的信号处理过程，比如重新发送可能丢失的消息。这些信号是软件模拟的硬件中断，除了定时器到期之外，该信号可以由各种原因产生。许多由硬件检测出来的陷阱，如执行了非法指令或使用了无效地址等，也被转换成该信号并交给这个进程。

系统管理器授权每个进程使用一个给定的 **UID**（User IDentification）。每个被启动的进程都由一个启动该进程的用户 UID。子进程拥有与父进程一样的 UID。用户可以是某个组的成员，每个组也有一个 **GID**（Group IDentification）。

在 UNIX 中，有一个 UID 称为**超级用户**（superuser），或者 Windows 中的**管理员**（administrator），它具有特殊的权力，可以违背一些保护规则。在大型系统中，只有系统管理员掌握着成为超级用户的密码，但是许多普通用户（特别是学生）做出了可观的努力，试图找出系统的缺陷，从而使他们不用密码就可以成为超级用户。 

在第 2 章中，我们将讨论进程以及进程间通信的相关内容。



##### 1.5.2	地址空间

每台计算机都有一些主存，用来保存正在执行的程序。在非常简单的操作系统中，内存中一次只能有一个程序。如果要运行第二个程序，第一个程序就必须被移出内存，再把第二个程序装入内存。

较复杂的操作系统允许在内存中同时允许多道程序。为了避免它们互相干扰（包括操作系统），需要有某种保护机制。虽然这钟机制必须是以硬件形式的，但是由操作系统掌控。

上述的观点涉及对计算机主存的管理和保护。另一种不同但是同样重要并与存储器有关的内容，是管理进程的地址空间。通常，每个进程可以有一些可以使用的地址集合，典型值从 0 开始直到某个最大值。在最简单的情形下，一个进程可拥有的最大地址空间小于主存。在这种方式下，进程可以用满其地址空间，而且内存中也有足够的空间容纳该进程。

但是，在许多 32 位或 64 位地址的计算机中，分别有 2^32^ 或 2^64^ 字节的地址空间。若果一个进程有比计算机拥有的主存还大的地址空间，而且该进程希望使用全部的内存，那怎么办呢？在早期的计算机中，这个进程只好 “认命” 了。现在，有了一种称为虚拟内存的计数，正如前面已经介绍过的，操作系统可以把部分地址空间装入主存，部分留在磁盘上，并且在需要时来回交换它们。在本质上，操作系统创建了一个地址空间的抽象，作为进程可以引用地址的集合。该地址空间与机器的物理内存解耦，可能大于也可能小于该物理空间。对地址空间和物理空间的管理组成了操作系统功能的一个重要部分，整个第 3 章都与这个主题有关。



##### 1.5.3	文件

实际上，支持操作系统的另一个关键概念是文件系统。如前所述，操作系统的一项主要功能是隐藏磁盘和其他 I/O 设备的细节特性，提供给程序员一个良好、清晰的独立于设备的抽象文件模型。显然，创建文件、删除文件、读文件和写文件等都需要系统调用。在文件可以读取之前，必须先在磁盘上定位和打开文件，在文件读过之后应该关闭该文件，有关的系统调用则用于完成这类操作。

为了提供保存文件的地方，大多数操作系统支持**目录**（directory）的概念，从而可以把文件分类成组。比如，学生可给所选的每个课程创建一个目录（用于保存该课程所需的程序），另设一个目录存放电子邮件，再有一个目录用于保存万维网主页。这就需要系统调用创建和删除目录、将已有的文件放入目录中、从目录中删除文件等。目录项可以是文件或者目录，这样就产生了层次结构——文件系统，如图 1-14 所示。

进程和文件层次都可以组成树状结构，但这两种树状结构有不少不同之处。一般进程的树状结构层次不深（很少超过三层），而文件树树状结构的层次常常多达四层、五层或更多层。进程树层次结构是暂时的，通常最多存在几分钟，而目录层次则可能存在数年之久。进程和文件在所有权及保护方面也是有区别的。典型地，只有父进程能够控制和访问子进程，而在文件和目录中通常存在一种机制，使文件所有者之外的其他用户也可以访问该文件。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE11.jpg"/>
</div>

目录层结构中的每一个文件都可以通过从目录的顶部即**根目录**（root directory）开始的**路径名**（path name）来确定。绝对路径名包含了从根目录到该文件的所有目录清单，它们之间用正斜线 / 隔开。最开始的正斜线表示这是从根目录开始的绝对路径。由于历史原因，在 Windows 中用反斜线 \ 作为分隔符。在本书中，我们一般使用 UNIX 的路径惯例。

在实例中，每个进程有一个**工作目录**（working directory），对于没有以斜线开头给出绝对路径的路径，将在这个工作目录下寻找。进程可以通过使用系统调用指定新的工作目录，从而变更其工作目录。

在读写文件之前，首先要打开文件，检查其访问权限。若权限许可，系统将返回一个小整数，称为**文件描述符**（file descriptor），供后续操作使用。若禁止访问，系统则返回一个错误码。

UNIX 的一个重要概念是安装文件系统。大多数台式机都由一个或多个光盘驱动器，可以插入 CD-ROM、DVD 和蓝色光盘。它们几乎都有 USB 接口，可以插入 USB 存储棒（实际上是固态磁盘驱动器）。为了提供一个出色的方式处理可移动介质，UNIX 允许把光盘上的文件系统接到主文件树上。考虑图 1-15a 的情形。在 mount 调用之前，根文件系统在硬盘上，而第二个文件系统在 CD-ROM 上，它们是分离且无关的。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE12.jpg"/>
</div>

然而，不能使用 CD-ROM 上的文件系统，因为上面没有可指定的路径。UNIX 不允许在路径前面加上驱动器名称或代码，那样做就完全成了设备相关类型了，这是操作系统应该消除的。代替的方法是，mount 系统调用允许把在 CD-ROM 上的文件系统连接到程序所希望的**根文件系统**上。在图 1-15b 中，CS-ROM 上的文件系统安装到了目录 b 上，这样就允许访问文件 /b/x 以及 /b/y。如果 CD-ROM 已安装好，但目录 b 中有任何不能访问的文件，则是因为 /b 指向了 CS-ROM 的根目录。（在开始时，不能访问这些文件似乎并不是一个严重问题；文件系统几乎总是安装在空目录上。）如果系统有多个硬盘，它们可以都安装在单个树上。

在 UNIX 中，另一个重要的概念是**特殊文件**（special file）。提供特殊文件是为了使 I/O 设备看起来像文件一般。这样，就像使用系统调用读写文件一样，I/O 设备也可通过同样的系统调用进行读写。有两类特殊文件：**块特殊文件**（block special file）和**字符特殊文件**（character special file）。块特殊文件指那些由可随机存区的块组成的设备，如磁盘等。比如打开一个块特殊文件，然后读第 4 块，程序可以直接访问设备的第 4 块而不必考虑存放该文件的文件系统结构。类似地，字符特殊文件用于打印机、调制解调器和其他接收或输出字符流的设备。按照管理，特殊文件保存在 /dev 目录中。例如，/dev/lp 是打印机（曾经称为行式打印机）。

本小节中讨论的最后一个特性既与进程有关也与文件有关：管道。**管道**（pipe）是一种虚文件，它可连接两个基础你好，如图 1-16 所示。如果进程 A 和 B 希望通过管道通话，它们必须提前设置该管道。当进程 A 想对进程 B 发送数据时，它把数据写到管道上，仿佛管道就是输出文件一样。进程 B 可以通过读该管道而得到数据，仿佛该管道就是一个输入文件一样。这样，在 UNIX 中两个进程之间的通信就非常类似于普通文件的读写了。更为强大的是，若进程想发现它所写入的输出文件并不是真正的文件而是管道，则需要使用特殊的系统调用。文件系统是非常重要的。我们将在第 4、10、11 章中具体讨论它们。



##### 1.5.4	输入/输出

所有的计算机都有用来获取输入和产生输出的物理设备。毕竟，如果用户不能告诉计算机该做什么，而在计算机完成了所要求的工作之后竟不能得到结果，那么计算机还有什么用处呢？有各种类型的输入和输出设备，包括键盘、显示器、打印机等。对这些设备的管理全然依靠操作系统。

所以，每个操作系统都有管理器 I/O 设备的 I/O 子系统。某些 I/O 软件是设备独立的，即这些 I/O 软件部分可以同样应用于许多或者全部的 I/O 设备上。I/O 软件的其他部分，如设备驱动程序，是专门为特定的 I/O 设备设计的。在第 5 章中，我们将讨论 I/O 软件。



##### 1.5.5	保护

计算机中有大量的信息，用户经常希望对其进行保护，并保守秘密。这些信息包括电子邮件、商业计划、退税等诸多内容。管理系统的安全性完全依靠操作系统，例如，文件仅供授权用户访问。

作为一个简单的例子，以便读者对如何实现安全有一个概念，请考察 UNIX。UNIX 操作系统通过对每个文件赋予一个 9 位的二进制保护代码，对 UNIX 中的文件实现保护。该保护代码有三个 3 位字段，一个用于所有者，一个用户与所有者同组（用户被系统管理原划分成组）的其他成员，一个用于其他人。每个字段中有一位用于读访问，一位用于写访问，一位用于执行访问。这些位就是知名的 **rwx位**。对一个文件而言，x 的含义是允许执行该文件。对一个目录而言，x 的含义是允许查询。一条短横线的含义是，不存在对应的许可。

除了文件保护之外，还有很多有关安全的问题。保护系统不被人类或非人类（如病毒）入侵，则是其中之一。我们将在第 9 章中研究各种安全性问题。



##### 1.5.6	shell

操作系统是进行系统调用的代码。编辑器、编译器、汇编程序、链接程序、效用程序以及命令解释器等，尽管非常重要，也非常有用，但是它们确实不是操作系统的组成部分。为了避免可能发生的混淆，本小节将大致介绍一下 UNIX 的命令解释器，称为 shell。尽管 shell 本身不是操作系统的一部分，但它体现了许多操作系统的特性，并很好地说明了系统调用的具体用法。shell 同时也是终端用户与操作系统之间的接口，除非用户使用的是图形用户界面。有许多种 shell，如 sh、csh、ksh 以及 bash 等。它们全部支持下面所介绍的功能，这些功能可追溯到早期的 shell（即 sh）。

用户登录时，同时启动了一个 shell。它终端作为标准输入和标准输出。首先显示**提示符**（prompt），它可能是一个美元符号，提示用户 shell 正在等待接收命令。加入用户键入

data

shell 创建一个子进程，并运行 date 程序作为子进程。在该子进程运行期间，shell 等待它结束。在子进程结束后，shell 再次显示提示符，并等待下一行输入。

用户可以将标准输出重定向到一个文件，如键入

date > file

同样，也可以将标准输入重定向，如：

sort < file1 > file2

该命令调用 sort 程序，从 file1 中取得输入，输出送到 file2.

可以将一个程序的输出通过管道作为另一程序的输入，因此有

cat file1 file2 file3 | sort > /dev/lp

所调用的 cat 程序将这三个文件合并，其结果送到 sort 程序并按字典序排序。sort 的输出又被重定向到文件 /dev/lp 中，显然，这是打印机。

如果用户在命令后加上一个 "&" 符号，则 shell 将不等待其结束，而直接显示出提示符。所以

cat file1 file2 file3 | sort > /dev/lp &

将启动 sort 程序作为后台任务执行，这样就运行用户继续工作，而 sort 命令页继续进行。shell 还有许多其他有用的特性，由于篇幅有限而不能在这里讨论。

现在，许多个人计算机使用 GUI。事实上，GUI 与 shell 类似，GUI 只是一个运行在操作系统顶部的程序。在 Linux 系统中，这个事实更加明显，因为用户（至少）可以在两个 GUI 中选择要给：Gnome 和 KDE，或者干脆不用。



##### 1.5.7	个体重复系统发育

略





#### 1.6	系统调用

我们已经看到操作系统具有两种功能：**为用户程序提供抽象和管理计算机资源**。在多数情形下。用户程序和操作系统之间的交互处理的是前者，例如，创建、写入、读出和删除文件。对用户而言，资源管理部分主要是透明和自动完成的。这样，用户程序和操作系统之间的交互主要就是处理抽象。为了真正理解操作系统的行为，我们必须仔细地分析这个接口。接口中所提供的调用随着操作系统的不同而变化（尽管基于的概念是类似的）。

这样我们不得不在如下的可能方式中进行选择：（1）含混不清的一般性描述（“操作系统提供读取文件的系统调用”）；（2）某个特定的系统（“UNIX 提供一个有三个参数的 read 系统调用：一个参数指定文件，一个说明数据应存放的位置，另一个说明应读出多少字节”）。

我们选择后一种方式。这种方式需要更多的努力，但是它能更多地洞察操作系统具体在做什么。尽管这样的讨论会涉及专门的 POSIX，以及 UNIX、System V、BSD、Linux、MINIX 3 等，但是多数现代操作系统都有实现相同功能的系统调用，尽管它们在细节上差别很大。由于引发系统调用的实际机制是非常依赖于机器的，而且必须用汇编代码表达，所以，通过提供过程库使 C 程序中能够使用系统调用，当然也包括其他语言。

记住下列事项是有益的。任何单 CPU 计算机一次只能执行一条指令。如果一个进程正在用户态进行一个用户程序，并且需要一个系统服务，比如从一个文件读数据，那么它就必须执行一个陷阱或系统调用指令，将控制转移到操作系统。操作系统接着通过参数检查找出所需要的调用进程。然后，它执行系统调用，并把控制返回给出在系统调用后面跟随着的指令。在某种意义上，进行系统调用就像进行一个特殊的过程调用，但是只有系统调用可以进入内核，而过程调用则不能。

为了使系统调用机制更清晰，我们简要地考察 read 系统调用。如上所述，它有三个参数：第一个参数指定文件，第二个指向缓冲区，第三个说明要读出的字节数。几乎与所有的系统调用一样，它的调用由 C 程序完成，方法是调用一个与该系统调用名称相同的库过程：read。由 C 程序进行的调用形式如下：

count = read(fd, buffer, nbytes);

系统调用（以及库过程）在 count 中返回实际读出的字节数。这个值通常和 nbytes 相同，但也可能更小，例如，如果在读过程中遇到了文件尾的情形就是如此。

如果系统调用不能执行，不论是因为无效的参数还是磁盘错误，count 都会被设置为 -1，而在全局变量 errno 中放入错误号。程序应该经常检查系统调用的结果，以了解是否出错。

系统调用是通过一系列的步骤实现的。为了更清楚地说明这个概念，考察上面的 read 调用。在准备调用这个实际用来进行 read 系统调用的 read 库过程时，调用程序首先把参数压进堆栈，如图 1-17 中步骤 1~步骤 3 所示。 

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE13.jpg"/>
</div>

由于历史的原因，C 以及 C++ 编译器使用逆序（必须把第一个参数赋给 printf（格式字符串），放在堆栈的顶部）。第一个和第三个参数是值调用，但是第二个参数通过引用传递，即传递的是缓冲区的地址（由 & 指示），而不是缓冲区的内容。接着是对库过程的实际调用（第 4 步）。这个指令是用来调用所有过程的正常过程调用指令。

在可能是由汇编语言写成的库过程中，一般把系统调用的编号放在操作系统所期望的地方，如寄存器中（第 5 步）。然后执行一个 TRAP 指令，将用户态切换到内核态，并在内核中的一个固定地址开始执行（第 6 步）。TRAP 指令实际上与过程调用指令非常类似，它们后面都跟随一个来自远处位置的指令，以及供以后使用的一个保存在栈中的返回地址。

然而，TRAP 指令与过程指令存在两个方面的差别。首先，它的副作用是，切换到内核态。而过程调用指令并不改变模式。其次，不像给定过程所在的相对或绝对地址那样，TRAP 指令不能跳转到任意地址上。根据机器的体系结构，或者跳转到一个单固定地址上，或者指令中有一 8 位长的字段，它给定了内存中一张表格的索引，这张表格中含有跳转地址。

跟随在 TRAP 指令后的内核代码开始检查系统调用编号，然后分派给正确的系统调用处理器，这通常是通过一张由系统调用编号所引用的、指向系统调用处理器的指针表来完成（第 7 步）。此时，系统调用处理器运行（第 9 步）。这个过程接着以通常的过程调用返回的方式，返回到用户程序（第 10 步）。

为了完成整个工作，用户程序还必须清除堆栈，如同它在进行任何过程调用之后一样（第 11 步）。假设堆栈向下增长，如经常所做的那样，编译后的代码准确地增加堆栈针值，以便清除调用 read 之前压入的参数。在这之后，原来的程序就可以随意执行了。

在前面第 9 节中，我们提到 “控制可能会在跟随 TRAP 指令后面的指令中返回给用户空间库过程”，这是有原因的。系统调用可能阻塞调用者，避免它继续执行。例如，如果试图读键盘，但是并没有任何键入，那么调用者就必须被阻塞。在这种情形下，操作系统会查看是否有其他可以运行的进程。稍后，当需要的收入出现时，进程会提醒系统注意，然后步骤 9~步骤 11会接着进行。

下面几小节中，我们将考察一些常用的 POSIX 系统调用，或者用更专业的说法，考察进行这些系统调用的库过程。POSIX 大约有 100 个过程调用，它们中最重要的过程调用列在图 1-18 中。为方便起见，它们被分成 4 类。我们用文字简要地叙述其作用。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE14.jpg"/>
</div>

从广义上看，由这些调用所提供的服务确定了多数操作系统应该具有的功能，而在个人计算机上，资源管理功能是较弱的（至少与多用户的大型机相比较是这样）。所包含的服务有创建与终止进程，创建、删除、读出和写入文件，目录管理以及完成输入/输出。

有必要指出，将 POSIX 过程映射到系统调用并不是一对一的。POSIX 标准定义了构造系统所必须提供的一套过程，但是并没有规定它们是系统调用、库调用还是其他的形式。如果不通过系统调用就可以执行一个过程（即无须陷入内核），那么从性能方面考虑，它通常会在用户空间中完成。不过，多数 POSIX 过程确实进行系统调用，通常是一个过程直接映射到一个系统调用上。在一些情形下，特别是所需要的过程仅仅是某个调用的变体时，一个系统调用会对应若干个库调用。



##### 1.6.1	用于进程管理的系统调用

图 1-18 中的第一组调用用于进程管理。将有关 fork（派生）的讨论作为本节的开始是较为合适的。在 UNIX 中，fork 是唯一可以在 POSIX 中创建进程的途径。它创建一个原有进程的精确副本，包括所有的文件描述符、寄存器等内容。在 fork 之后，原有的进程及其副本（父与子）就分开了。在 fork 时，所有的变量具有一样的值，虽然父进程的数据被复制用以创建子进程，但是其中一个的后续变化并不会影响到另一个。（由父进程和子进程共享的程序正文，是不可改变的。）fork 调用返回一个值，在子进程中该值为零，并且在父进程中等于子进程的**进程标识符**（Process IDentifier，PID）。使用返回的 PID，就可以在两个进程中看出哪一个是父进程，哪一个是子进程。

多数情形下，在 fork 之后，子进程需要执行与父进程不同的代码。这里考虑 shell 的情形。它从终端读取命令，创建一个子进程，等待该子进程执行命令，在该子进程终止时，读入下一条命令。为了等待子进程结束，父进程执行 waitpid 系统调用，它只是等待，直至子进程终止（若有多个子进程的话，则直至任何一个子进程终止）。waitpid 可以等待一个特定的子进程，或者通过将第一个参数设为 -1 的方式，等待任何一个老的子进程。在 waitpid 完成之后，将把第二个参数 statloc 所指向的地址设置为子进程的退出状态（正常或异常终止以及退出值）。有各种可使用的选项，它们由第三个参数确定。例如，如果没有已经退出的子进程则立即返回。

现在考虑 shell 如何使用 fork。在键入一条命令后，shell 调用 fork 创建一个新的进程。这个子进程必须执行用户的命令。通过使用 execve 系统调用可以实现这一点，这个系统调用会引起其整个核心映像被一个文件所替代，该文件由第一个参数给定。（实际上，该系统调用自身是 exec 系统调用，但是若干个不同的库过程使用不同的参数和稍有差别的名称调用该系统调用。在这里，我们把它们都视为系统调用。）在下列函数中，用一个高度简化的 shell 说明 fork、waitpid 以及 execve 的使用。

```c
#define	TRUE 1
												
while (TRUE) {							//一直循环下去
    type_prompt();						//在屏幕上显式提示符
    read_command(command, parameters);	//在终端读取输入
    
    if (fork() != 0) {					//派生子进程
        //父代码
        waitpid(-1, &status, 0);		//等待子进程退出
    } else {
        //子代码
        execve(command, parameters, 0);	//执行命令
    }
}
```



在最一般情形下，execve 有三个参数：将要执行的文件名称，一个指向变量数组的指针，以及一个指向环境数组的指针。这里对这些参数做一个简要的说明。各种库例程，包括 excel、ececv、execle 以及 execve，允许略掉参数或以各种不同的方式给定。在本书中，我们在所有涉及的地方使用 exec 描述系统调用。

下面考虑诸如

cp file1 file2

的命令，该命令将 file1 复制到 file2。在 shell 创建进程之后，该子进程定位和执行文件 cp，并将源文件名和目标文件名传递给它。

CP 主程序（以及多数其他 C 程序的主程序）都有声明

main(argc, argv, envp)

其中 argc 是该命令行有关参数数目的计数器，包括程序名称。例如，上面的例子中，argc 为 3。

第二个参数 argv 是一个指向数组的指针。该数组的元素 i 是指向该命令行第 i 个字符串的指针。在本例中，argv[0] 指向字符串 "cp"，argv[1] 指向字符串 "file1"，argv[2] 指向字符串 "file2"。

main 的第三个参数 envp 是一个指向环境的指针，该环境是一个数组，含有 name = value 的赋值形式，用以将诸如终端类型以及根目录等信息传送给程序。还有供程序调用的库过程，用来取得环境变量，这些变量通常用来确定用户希望如何完成特定的任务（例如，使用默认打印机）。在上列模拟 shell 的程序中，没有环境参数传递给子进程，所以 execve 的第三个参数为 0。

如果读者认为 exec 过于复杂，那么也不要失望。这是在 POSIX 的全部系统调用中最复杂的一个（语义中），其他的都非常简单。作为一个简单例子，考虑 exit，这是在进程完成执行后应执行的系统调用。这个系统调用有一个参数——退出状态（0 至 255），该参数通过 waitpd 系统调用中的 statloc 返回父进程。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE15.jpg"/>
</div>

在 UNIX 中的进程将其存储空间划分为三段：**正文段**（如程序代码）、**数据段**（如变量）以及**堆栈段**。数据向上增长而堆栈向下增长，如图 1-20 所示。夹在中间的是未使用的地址空间。堆栈在需要时自动地向中间的空闲区（gap）增长，不过数据段的扩展是显式地通过系统调用 brk（brk 是系统调用，主要工作是实现虚拟内存到内存的映射，可以让进程的堆指针增长一定的大小，逻辑上消耗掉一块虚拟地址空间） 进行的，在数据段扩充后，该系统调用指定一个数据段结束处的新地址。但是，这个调用不是 POSIX 标准中定义的，对于存储器的动态分配，鼓励程序员使用 malloc 库过程，而 malloc 的内部实现则不是一个适合标准化的主题，因为几乎没有程序员直接使用它，我们有理由怀疑是否有人会注意到 brk 实际不是属于 POSIX 的。



##### 1.6.2	用于文件管理的系统调用

许多系统调用与文件系统有关。本小节讨论在单个文件上的操作，1.6.3 将讨论与目录和整个文件系统有关的内容。

要读写要给文件，先要使用 open 打开该文件。这个系统调用通过绝对路径名或指向工作目录的相对路径名指定要打开文件的名称，而代码 O_RDONLY、O_WRONLY 或 Q_RDWR 的含义分别是只读、只写或两者都可以。为了创建一个新文件，使用 O_CREAT 参数。然后可使用返回的文件描述符进行读写操作。接着，可以用 close 关闭文件，这个调用可以释放该文件描述符，使得它在后续的 open 中能被再次使用。

毫无疑问，最常用的调用是 read 和 write。我们在前面已经讨论过 read。write 具有与 read 相同的参数。

尽管多数程序频繁地读写文件，但是仍有一些应用程序需要能够随机访问一个文件的任意部分。与每个文件相关的是一个指向文件当前位置的指针。在顺序读（写）时，该指针通常指向要读出（写入）的下一个字节。lseek 调用可以改变该位置指针的值，这样后续的 read 或 write 调用就可以在文件的任何地方开始。

lseek 有三个参数：第一个是文件的描述符，第二个是文件位置，第三个说明该文件位置是相对于文件起始位置、当前位置还是文件的结尾。在修改了指针之后，lseek 所返回的值是文件中的绝对位置。

UNIX 为每个文件保存了该文件的类型（普通文件、特殊文件、目录等）、大小、最后修改时间以及其他信息。程序可以通过 stat 系统调用查看这些信息。第一个参数指定了要被检查的文件；第二个参数是一个指针，该指针指向存放这些信息的结构。对于一个打开的文件而言，fstat 调用完成同样的工作。



##### 1.6.3	用于目录管理的系统调用

本小节我们讨论与目录或整个文件系统有关的某些系统调用，而不是 1.6.2 节中与一个特定文件有关的系统调用。mkdir 和 rmdir 分别用于创建和删除空目录。下一个调用是 link。它的作用是允许同一个文件以两个或多个名称出现，多数情形下是在不同的目录中这样做。它的典型应用是，在同一个开发团队中允许若干个成员共享一个共同的文件，他们每个人都在自己的目录中有该文件，但可能采用的是不同的名称。共享一个文件，与每个团队成员都有一个私用副本并不是同一件事，因为共享文件意味着任何成员所作的修改都立即为其他成员所见——只有一个文件存在。而在复制了一个文件的多个副本之后，对其中一个副本所进行的修改并不会影响到其他的副本。

为了考察 link 是如何工作的，考虑图 1-21a 中的情形。有两个用户 ast 和 jim，每个用户都有一些文件的目录。若 ast 现在执行一个含有系统调用的程序

link("/user/jim/memo", "usr/ast/note");

jim 目录中的文件 memo 以文件名 note 进入 ast 的目录。之后，/user/jim/memo 和 usr/ast/note 都引用相同的文件。

理解 link 是如何工作的也许有助于读者看清其作用。在 UNIX 中，每个文件都有唯一的编号，即 i- 编号，用以标识文件。该 i-编号是对 i-**节点**表格的一个引用，它们一一对应，说明该文件的拥有者、磁盘块的位置等。目录就是一个包含了（i-编号，ASCII 名称）对集合的文件。在 UNIX 的第一个版本中，每个目录项有 16 个字节——2 字节用于 i-编号，14 字节用于名称。现在为了支持长文件名，采用了更复杂的结构，但是，在概念上，目录仍然是（i-编号，ASCII 名称）对的一个集合。在图 1-21 中，mail 为 i-编号 16，等等。link 所做的只是利用某个已有文件的 i-编号，创建一个新目录项（也许用一个新名称）。在图 1-21b 中有两个目录项有相同的 i-编号（70），从而指向同一个文件。如果使用 unlink 系统调用将其中一个文件一走了，可以保留另一个。如果两个都被移走了，UNIX 00 看到尚且存在的文件没有目录项（i-节点中的一个域记录着指向该文件的目录项），就会把该文件从磁盘中移去。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE16.jpg"/>
</div>

正如我们已经叙述过的，mount 系统调用允许将两个文件系统合并成为一个。通常的情形是，在硬盘某个分区中的根文件系统含有常用命令的二进制（可执行）版和其他常用的文件，用户文件在另一个分区。并且，用户可插入包含需要读入的文件的 U 盘。

通过执行 mount 系统调用，可以将一个 USB 文件系统添加到根文件系统中，如图 1-22 所示。完成安装操作的典型 C 语句为

mount("/dev/sdb0", "/mnt", 0);

这里，第一个参数是 USB 驱动器 0 的块特殊文件名称，第二个参数是要被挂载在树中的位置，第三个参数说明将要挂载的文件系统是可读写的还是只读的。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE17.jpg"/>
</div>

在 mount 调用之后，驱动器 0 上的文件可以使用从根目录开始的路径或工作目录路径，而不用考虑文件在哪个驱动器上。事实上，第二个、第三个以及第四个驱动器也可安装在树上的任何地方。mount 调用使得把可移动介质都集中到一个文件层次中成为可能，而不用考虑文件在那个驱动器上。尽管这是个 CD-ROM 的例子，但是也可以用同样的方法安装硬盘或者硬盘的一部分（常称为**分区**或**次级设备**），外部硬盘和 USB 盘也一样。当不再需要一个文件系统时，可以用 unmount 系统调用卸载之。



##### 1.6.4	各种系统调用

有各种的系统调用。这里介绍系统调用中的一部分。chdir 调用改变当前的工作目录。在调用

chdir("/usr/ast/test");

之后，打开 xyz 文件，会打开 /usr/ast/test/xyz。工作目录的概念消除了总是键入（长）绝对路径名的需要。

在 UNIX 中，每个文件有一个保护模式。该模式包括针对所有者、组和其他用户的读-写-执行位。chmod 系统调用可以改变文件的模式。例如，要使一个文件对除了所有者之外的用户只读，可以执行

chmod("file", 0644);

kill 系统调用供用户或用户进程发送信号用。若一个进程准备好捕捉一个特定的信号，那么，在信号到来时，运行一个信号处理程序。如果该进程没有准备好，那么信号的到来会杀掉该进程（此调用名称的由来）。

POSIX 定义了若干处理时间的过程。例如，time 以秒为单位返回当前时间，0 对应着 1970 年 1 月 1 日午夜（从此日开始，没有结束）。



##### 1.6.5	Windows Win32 API

到目前为止，我们主要讨论的是 UNIX 系统。现在简要地考察 Windows。Windows 和 UNIX 的主要差别在于编程方式。UNIX 程序包括做各种处理的代码以及完成特定服务的系统调用 。Windows 程序通常是事件驱动程序。其中主程序等待某些事件发生，然后调用要给过程处理该事件。典型的时间包括被敲击的键、移动的鼠标、被按下的鼠标或插入的 U 盘。调用事件处理程序处理事件，刷新屏幕，并更新内部程序状态。总之，这是与 UNIX 不同的程序设计风格，由于本书专注于操作系统的功能和结构，这些程序设计方式上的差异就不过多涉及了。

当然，在 Windows 中也有系统调用。在 UNIX 中，系统调用（如 read）和系统调用所使用的库过程（如 read）之间几乎是一一对应的关系。换句话说，对于每个系统调用，差不过就涉及一个被调用的库过程，如图 1-17 所示。此外，POSIX 有约 100 个过程调用。

在 Windows 中，情况就大不相同了。首先，库调用和实际的系统调用几乎是不对应的。微软定义了一套过程，成为 **Win32应用编程接口**（Application Program Interface，API），程序员用这套过程获得操作系统的服务。从 Windows95 开始的所有 Windows 版本都（或部分）支持这个接口。由于接口与实际的系统调用不对应，微软保留了随着时间（甚至随着版本到版本）改变实际系统调用的能力，防止已有的程序失效。由于最新几版 Windows 中有许多过去没有的新调用，所以究竟 Win32 是由什么构成的，这个问题的答案仍然是含混不清的。在本小节中，Wind32 表示所有 Windows 版本都支持的接口。Win32 提供各 Windows 版本的兼容性。

Win32 API 调用的数量是非常大的，有数千个。此外，尽管其中许多确实涉及系统调用，但有一大批 Win32 API 完全是在用户空间进行的。结果，在 Windows 中，不可能了解哪一个是系统调用（如内核完成），哪一个只是用户空间中的库调用。事实上，某个版本中的一个系统调用，会在另一个不同版本的用户空间中执行，或者相反。当我们在本书中讨论 Windows 的系统调用时，将使用 Win32 过程（在合适之处），这是因为微软保证：随着时间流逝，Win32 过程将保持稳定。但是读者有必要记住，它们并不全都是系统调用（即陷入内核中）。

Windows 中没有类似 UNIX 中的进程层次，所以不存在父进程和子进程的概念。在进程创建之后，创建者和被创建者是平等的。





#### 1.7	操作系统结构

我们已经分析了操作系统的外部（如程序员接口），现在是分析其内部的时候了。在下面的小节中，为了对各种可能的方式有所了解，我们将考察已经尝试过的六种不同的结构设计。这样做并没有涵盖各种结构方式，但是至少给出了在实践中已经试验过的一些涉及思想。我们将讨论的这六种涉及包括单体系统、层次式系统、微内核、客户端-服务器模式、虚拟机和外核等。



##### 1.7.1	单体系统

到目前为止，在大多数常见的组织中，整个操作系统在内核态以单一程序的方式运行。整个操作系统以过程集合的方式编写，链接成一个大型可执行二进制程序。使用这种技术，系统中每个过程可以自由调用其他过程，只要后者提供了前者所需要的一些有用的计算工作。调用任何一个你所需要的过程或许会非常高效，但上千个可以不受限制地彼此调用的过程常常导致系统笨拙且难于理解。并且，任何一个过程的崩溃都会连累整个系统。

在使用这种处理方式构造实际的目标程序时，首先编译所有单个的过程，或者编译包含过程的文件，然后通过系统链接程序将它们链接成单一的目标文件。就信息隐藏来说，这里实际上是不存在的，每个过程对其他过程都是可见的（与包含模块或包的结构相反，在结构中，其中多数信息隐藏在模块之中，而且只能通过正式设计的入口点实现模块的外部调用）。

但是，即使在单体系统中，也可能有一些结构存在。可以将参数放置在良好定义的位置（如栈），通过这种格式，向操作系统请求所能提供的服务（系统调用），然后执行一个陷阱指令。这里指令将机器从用户态切换到内核态并把控制传递给操作系统，如图 1-17 中第 6 步所示。然后，操作系统取出参数并且确定应该执行哪一个系统调用。随后，它在一个表格中检索，在该表格的 k 槽中存放着指向执行系统调用 k 过程的指针（图 1-17 中第 7 步）。

对于这类操作系统的基本结构，有者如下结构上的建议：

1. 需要一个主程序，用来处理服务过程请求。
2. 需要一套服务过程，用来执行系统调用。
3. 需要一套实用过程，用来辅助服务过程。

在该模型中，每一个系统调用都通过一个服务过程为其工作并运行之。要有一组实用程序来完成一些服务过程所需要用到的功能，如从用户程序取数据等。可将各种过程划分为一个三层的模型，如图 1-24 所示。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE18.jpg"/>
</div>

除了在计算机初启时所装载的核心操作系统外，许多操作系统支持可装载的扩展，诸如 I/O 设备驱动和文件系统。这些部件可以按照需要载入。在 UNIX 中它们被叫作**共享库**（shared library），在 Windows 中则被称为**动态链接库**（Dynamic Link Library，DLL）。它们的扩展类型为 .dll，在 C:\Windows\system32 目录下存在 1000 多个 DDL 文件。



##### 1.7.2	层次式系统

把图 1-24 中的系统进一步通用化，就变成一个层次式结构的操作系统，它的上层软件都是在下一层软件的基础之上构建的。THE 系统是按此模型构造的第一个操作系统（1968）。THE 系统是为荷兰的一种计算机 Electrologica X8 配备的一个简单的批处理系统，其内存只有 32K 个字，每字 27 位（那时二进制位是很昂贵的）。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE19.jpg"/>
</div>

该系统共分为六层，如图 1-25 所示。处理器分配在第 0 层中进行，当中断发生或定时器到期时，由该层进行进程切换。在第 0 层之上，系统由一些连续的进程所组成，编写这些进程时不用再考虑在单处理器上多进程运行的细节。也就是说，在第 0 层中提供了基本的 CPU 多道程序设计功能。

内存管理在第 1 层中进行，它分配进程的主存空间，当内存用完时则在一个 512K 字的磁鼓上保留进程的一部分（页面）。在第 1 层上，进程不用考虑它是在磁鼓上还是在内存中运行。第 1 层软件保证一旦需要访问某一页面，该页面必定已在内存中，并在页面不再需要时将其移出。

第 2 层处理进程与操作员控制台（即用户）之间的通信。在这层的上部，可以认为每个进程都有自己的操作员控制台。第 3 层管理 I/O 设备和相关的信息流缓冲区。在第 3 层上，每个进程都与有良好特性的抽象 I/O 设备打交道，而不必考虑外部设备的而无力细节。第 4 层是用户程序层。用户程序不用考虑进程、内存、控制台或 I/O 设备管理等细节。系统操作员进程位于第 5 层中。

在 MULTICS 系统中采用了更进一步的通用层次化概念。MULTICS 由许多的同心环构造而成，而不是采用层次化构造，内环比外环有更高的级别（它们实际上是一样的）。当外环的过程欲调用内环的过程时，它必须执行一条等价于系统调用的 TRAP 指令。在执行该 TRAP 指令前，要进行严格的参数合法性检查。在 MULTICS 中，尽管整个操作系统是各个用户进程的地址空间的一部分。但是硬件仍能对单个过程（实际是内存中的一个段）的读、写和执行进行保护。

实际上，THE 分层方案只是为设计提供了一些方便，因为该系统的各个部分最终仍然呗链接成了完整的单个目标程序。而在 MULTICS 里，环形机制在运行中是实际存在的，而且是由硬件实现的。环形机制的一个有点是很容易扩展，可用以构造用户子系统。例如，在一个 MULTICS 系统中，教授可以写一个程序检查学生编写的程序并给他们打分，在第 n 个环中运行教授的程序，而在第 n+1 个环中运行学生的程序，这样学生就无法篡改教授所给出的成绩。



##### 1.7.3	微内核

在分层方式中，设计者要确定在哪里划分内核-用户的边界。传统上，所有的层都在内核中，但是这样做没有必要。事实上，尽可能减少内核态中功能的做法更好，因为内核中的错误会快速拖累系统。相反，可以把用户进程设置为具有较小的权限，这样，某个错误的后果就不会是致命的。

有不少研究人员对每千行代码中错误的数量进行了分析。代码错误的密度取决于模块大小、模块寿命等，不过对一个实际工业系统而言，每千行代码中会有 2~10 个错误。这意味着在有 500 万行代码的单体操作系统中，大约有 10000~50000 个内核错误。当然，并不是所有的错误都是致命的，诸如给出了不正确的故障信息之类的某些错误，实际是很少发生的。无论怎样看，操作系统中充满了错误，所以计算机制造商设置了复位按钮（通常在前面板上），而电视机、立体音响以及汽车的制造商则不这样做，尽管在这些装置中也有大量的软件。

而微内核设计背后的思想是，为了实现高可靠性，将操作系统划分成小的、良好定义的模块，只有其中一个模块——微内核——运行在内核态，其余的模块由于功能相对弱些，则作为普通用户进程运行。特别地，由于把每个设备驱动和文件系统分别作为普通用户进程，这些模块中的错误虽然会使这些模块崩溃，但是不会使整个系统死机。所以，音频驱动中的错误会使声音断续或停止，但是不会使整个计算机垮掉。相反，在单体系统中，由于所有的设备驱动都在内核中，一个有故障的音频驱动很容易引起对无效地址的引用，从而造成恼人的系统立即停机。

有许多微内核已经被实现并应用了数十年。除了基于 Mach 微内核的 OS X 外，通常的桌面操作系统并不使用微内核。然而，微内核在实时、工业、航空以及军事应用中特别流行，这些领域都是关键任务，需要有高度的可靠性。

一个与小内核相关联的思想是内核中的**机制**与**策略**分离的原则。为了更清晰地说明这一点，我们考虑进程调度。一个比较简单的调度算法是，对每个进程赋予一个优先级，并让内核执行具有最高优先级的进程。这里，机制（在内核中）就是寻找最高优先级的进程并运行之。而策略（赋予进程优先级）可以由用户态中的进程完成。在这种方式中，机制和策略是分离的，从而使系统内核变得更小。



##### 1.7.4	客户端—服务器模式

一个微内核思想的略微变体是将进程划分为两类：**服务器**，每个服务器提供某种服务；**客户端**，使用这些服务。这个模式就是所谓的**客户端—服务器**模式。通常，在系统最底层是微内核，但并不是必须这样。这个模式的本质是存在客户端进程和服务器进程。

一般来说，客户端和服务器之间的通信是消息传递。为了获得一个服务，客户端进程构造一段消息，说明所需要的服务，并将其发给合适的服务器。该服务器完成工作，发送回应。如果客户端和服务器恰巧运行在同一个机器上，则有可能进行某种优化，但是从概念上看，这里讨论的是消息传递。

这个思想的一个显然的普遍方式是，客户端和服务器运行在不同的计算机上，它们通过局域网或广域网连接，如图 1-27 所示。由于客户端通过发送消息与服务器通信，客户端并不需要知道这些消息是在本地机器上处理，还是通过网络被送到远程机器上处理。对于客户端而言，这两种情形是一样的：都是发送请求并得到回应。所以，客户端—服务器模式是一种可以应用在单机或者网络机器上的抽象。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE20.jpg"/>
</div>





##### 1.7.5	虚拟机

OS／360 的最早版本是纯粹的批处理系统。然而，有许多 360 用户希望能够在终端上交互工作，于是 IBM 公司内外的一些研究小组决定为它编写一个分时系统。后来推出了正式的 IBM 分时系统 TSS／360。但是它非常庞大，运行缓慢，于是在花费了约 5000 万美元的研制费用后，该系统最后被弃之不用（Graham，1970）。但是在位于麻省剑桥的 IBM 研究中心开发了另一个完全不同的系统，这个系统最终被 IBM 用作产品。它的直接后代，称为 z/VM，目前在 IBM 的大型机上广泛使用，zSeries 则在大型公司的数据中心广泛使用，例如，作为电子商务服务器，它们每秒可以处理成百上千个事务，并使用规模达数百万 GB 的数据库。



**1.VM/370**

这个系统最初被命名为 CP/CMS，后来改名为 VM/370。它是源于如下机敏的观察，即分时系统应该提供这些功能：（1）多道程序，（2）一个比裸机更方便的、有扩展界面的计算机。VM／370 存在的目的是将二者彻底地隔离开来。

这个系统的核心称为**虚拟机监控程序**（virtual machine monitor），它在裸机上运行并且具备了多道程序功能。该系统向上层提供了若干台虚拟机，如图 1-28 所示。它不同于其他操作系统的地方是：这些虚拟机不是那种具有文件等优良特征的扩展计算机。与之相反，它们仅仅是裸机硬件的精确复制品。这个复制品包含了内核态/用户态、I/O 功能、中断及其他真实硬件所应该具有的全部内容。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE21.jpg"/>
</div>

由于每台虚拟机都与裸机相同，所以在每台虚拟机上都可以运行一台裸机所能够运行的任何类型的操作系统。不同的虚拟机可以运行不同的操作系统，而且实际上往往就是如此。在早期的 VM/370 系统上，有一些系统运行 OS／360 或者其他大型批处理或事务处理操作系统，而另一些虚拟机运行单用户、交互式系统供分时用户使用，这个系统称为**会话监控系统**（Conversational Monitor System，CMS）。后者在程序员中很流行。

当一个 CMS 程序执行系统调用时，该调用被陷入到其虚拟机的操作系统上，而不是 VM/370 上，似乎它运行在实际的机器上，而不是在虚拟机上。CMS 然后发出普通的硬件 I/O 指令读出虚拟磁盘或其他需要执行的调用。这些 I/O 指令由 VM/370 陷入，然后，作为对实际硬件模拟的一部分，VM/370 完成指令。通过对多道程序功能和提供扩展机器二者的完全分离，每个部分都变得非常简单、非常灵活且容易维护。

虚拟机的现代化身 z/VM 通常用于运行多个完整的操作系统，而不是简化成如 CMS 一样的单用户系统。例如，zSeries 有能力与传统的 IBM 操作系统一起，运行一个或多个 Linux 虚拟机。



**2.虚拟机的再次发现**

IBM 拥有虚拟机产品已经有 40 年了，而少数公司，包括 Oracle 公司和 Hewlett-Packard 公司等，近来也在其高端企业服务器上增加对虚拟机的支持，在 PC 上，直到最近之前，虚拟化的思想在很大程度上被忽略了。不过近年来，新的需求、新的软件和新的技术已经使得虚拟机成为热点。

首先看需求。传统上，许多公司在不同的计算机上，有时还在不同的操作系统上，运行其邮件服务器、Web 服务器、FTP 服务器以及其他服务器。他们看到可以在同一台机器上实现虚拟化来运行所有的服务器，而不会由于一个服务器崩溃影响其他系统。

虚拟化在 Web 托管世界里也很流行。没有虚拟化，Web 托管客户端只能**共享托管**（在 Web 服务器上给客户端一个账号，但是不能控制整个服务器软件）以及独占托管（提供给客户端整个机器，这样虽然很灵活，但是对于小型或中型 Web 站点而言，成本效益比不高）。当 Web 托管公司提供租用虚拟机时，一台物理机器就可以运行许多虚拟机，每个虚拟机看起来都是一台完全的机器。租用虚拟机的客户端可以运行自己想使用的操作系统和软件，但是只需支付独占一台机器的几分之一的费用（因为一台物理机器可以同时支持多台虚拟机）。

虚拟化的另外一个用途是，为希望同时运行两个或多个操作系统（比如 Windows 和 Linux）的最终用户服务，某个偏好的应用程序可运行在一个操作系统上，而其他的应用程序可运行在另一个操作系统上。如图1-29a所示，在这里术语 “虚拟机监控程序” 已经被重命名为第一类虚拟机管理程序（type 1 hypervisor），后者现在更常用，因为输入前者的英文 “virtual machine monitor” 超出了人们所能接受的按键次数。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE22.jpg"/>
</div>

虚拟机的吸引力是没有争议的，问题在于实现。为了在一台计算机上运行虚拟机软件，其 CPU 必须被虚拟化。简言之，存在一个问题。当运行虚拟机（在用户态）的操作系统执行某个特权指令时，比如修改 PSW 或进行 I/O 操作，硬件实际上陷入到了虚拟机中，这样有关指令就可以在软件中模拟。在某些 CPU 上（特别是 Pentium 和它的后继者及其克隆版中）试图在用户态执行特权指令时，会被忽略掉。这种特性使得在这类硬件中无法实现虚拟机，这也解释了 PC 世界对虚拟机不感兴趣的原因。当然，对于 Pentium 而言，还有解释器可以运行在 Pentium 上，例如 Bochs 但是其性能丧失了 1～2 数量级，这样对于要求高的工作来说就没有意义了。

由于 20 世纪 90 年代和本世纪这些年来若干学术研究小组的努力，特别是斯坦福大学的Disco（Bugnion 等人，1997）和剑桥大学的 Xen（Barham 等人，2003）实现了商业化产品（例如 VMware 工作站和 Xen），使得人们对虚拟机的热情得以复燃。除了 VMware 和 Xen 外，现在流行的虚拟机管理程序还有 KVM（针对 Linux 内核）、Oracle 公司的 VirtualBox 以及微软公司的 Hyper-V。

一些早期研究项目通过即时翻译大块代码、将其存储到内部高速缓存并在其再次执行时复用的方式，提高了 Bochs 等翻译器的性能。这种手段大幅提高了性能，也推动了模拟器（machine simulator）的出现，如图 1-29b 所示。这项被称为二进制翻译（binary translation）的技术对性能的提升有所帮助，不过，生成的系统虽然优秀到足以在学术会议上发表论文，但仍没有快到可以在极其注重性能的商业环境下使用。

改善性能的下一步在于添加分担重担的内核模块，如图 1-29c 所示。事实上，现在所有商业可用的虚拟机管理程序都使用这种混合策略（并且也有很多其他改进），如 VMware 工作站。它们被称为第二类虚拟机管理程序，本书中我们也延续使用这个名称（虽然有些不太情愿），即使我们更愿意用类型 1.7 虚拟机管理程序来反映它们并不完全是用户态程序。在第 7 章中，我们将详细描述 VMware 工作站的工作原理及其各部分的作用。

实际上，第一类和第二类虚拟机管理程序的真正区别在于，后者利用**宿主操作系统**（host operating system）并通过其文件系统创建进程、存储文件等。第一类虚拟机管理程序没有底层支持，所以必须自行实现所有功能。

当第二类虚拟机管理程序启动时，它从 CD-ROM 安装盘中读入供选择的**客户操作系统**（guest operating system），并安装在一个虚拟盘上，该盘实际上只是宿主操作系统的文件系统中的一个大文件。由于没有可以存储文件的宿主操作系统，因此第一类虚拟机管理程序不能采用这种方式。它们必须在原始的硬盘分区上自行管理存储。

在客户操作系统启动时，它完成的工作与在真实硬件上相同，如启动一些后台进程，然后是 GUI。对用户而言，客户操作系统与在裸机上运行时表现出相同的行为，虽然事实并非如此。

处理控制指令的一种不同方式是，修改操作系统，删掉它们。这种方式不是真正的虚拟化，而是**半虚拟化**（paravirtualization）。我们将在第 7 章具体讨论虚拟化。



**3.Java 虚拟机**

另一个使用虚拟机的领域，是为了运行 Java 程序，但方式有些不同。在 Sun 公司发明 Java 程序设计语言时，也同时发明了称为 **JVM**（Java Virtual Machine）的虚拟机（一种体系结构）。Java 编译器为 JVM 生成代码，这些代码以后可以由一个软件 JVM 解释器执行。这种处理方式的优点在于，JVM 代码可以通过 Internet 传送到任何有 JVM 解释器的计算机上，并在该机器上执行。举例来说，如果编译器生成了 SPARC 或 Pentium 二进制代码，这种代码不可能轻易地送到任何地方并执行。（当然，Sun 可以生产一种生成 SPARC 二进制代码地编译器，并且发布一种 SPARC 解释器，但是 JVM 具有非常简单的、只需要解释的体系结构。）使用 JVM 的另一种优点是，如果解释器正确地完成，并不意味着就结束了，还要对所输入的 JVM 程序进行安全性检查，然后在一种保护环境下执行，这样，这些程序就不能偷窃数据或进行其他任何有害的操作。



##### 1.7.6	外核

与虚拟机克隆真实机器不同，另一种策略是对机器进行分区，换句话说，给每个用户整个资源的一个子集。这样，某个虚拟机可能得到磁盘的 0 至 1023 盘块，而另一台虚拟机会得到 1024 至 2047 盘块，等等。

在底层中，一种称为外核（exokernel，Engler 等人，1995）的程序在内核态运行。它的任务是为虚拟机分配资源，并检查使用这些资源的企图，以确保没有机器会使用他人的资源。每个用户层的虚拟机可以运行自己的操作系统，如 VM/370 和 Pentium 虚拟 8086 等，但限制只能使用已经申请并且获得分配的那部分资源。

外核机制的优点是，它减少了映像层。在其他的设计中，每个虚拟机都认为它有自己的磁盘，其盘块号从 0 到最大编号，这样虚拟机监控程序必须维护一张表格以重映像磁盘地址（以及其他资源）。有了外核，这个重映像处理就不需要了。外核只需要记录已经分配给各个虚拟机的有关资源即可。这个方法还有一个优点，它将多道程序（在外核内）与用户操作系统代码（在用户空间内）加以分离，而且相应负载并不重，这是因为外核所做的只是保持多个虚拟机彼此不发生冲突。



#### 1.8	依靠 C 的世界

操作系统通常是由许多程序员写成的，包括很多部分的大型 C（有时是 C++）程序。用于开发操作系统的环境，与个人（如学生）用于编写小型 Java 程序的环境是非常不同的。本节试图为那些有时编写Java或者Python程序的程序员简要地介绍编写操作系统的环境。

**1.8.1   C语言**

这里不是 C 语言的指南，而是简要介绍 C 与类 **Python** 语言特别是 Java 之间的关键差别。Java 是基于 C 的，所以两者之间有许多类似之处。Python 有一点不同，但仍然十分相似。为方便起见，我们将注意力放在 Java 上。Java、Python 和 C 都是命令式的语言，例如，有数据类型、变量和控制语句等。在 C 中基本数据类型是整数（包括短整数和长整数）、字符和浮点数等。使用数组、结构体和联合，可以构造组合数据类型。C 语言中的控制语句与 Java 类似，包括 if、switch、for 以及 while 等语句。在这两个语言中，函数和参数大致相同。

一项 C 语言中有而 Java 和 Python 中没有的特点是显式指针（explicit pointer）。指针是一种指向（即包含对象的地址）一个变量或数据结构的变量。考虑下面的语句：

```c
char c1，c2，*p； 
c1 = 'c'； 
p = &c1；  
c2 = *p； 
```



这些语句声明 c1 和 c2 是字符变量，而 p 是指向一个字符的变量（即包含字符的地址）。第一个个赋值语句将字符 c 的 ASCII 代码存到变量 c1 中。第二个语句将 c1 的地址赋给指针变量 p。第三个语句将由 p 指向变量的内容赋给变量 c2，这样，在这些语句执行之后，c2 也含有 c 的 ASCII 代码。在理论上，指针是输入类型，所以不能将浮点数地址赋给一个字符指针，但是在实践中，编译器接受这种赋值，尽管有时给出一个警告。指针是一种非常强大的结构，但是如果不仔细使用，也会是造成大量错误的一个原因。

C 语言中没有包括内建字符串、线程、包、类、对象、类型安全（type safety）以及垃圾回收（garbage collection）等。最后一个是操作系统的 “淋浴器塞子”。在 C 中分配的存储空间或者是静态的，或者是程序员明确分配和释放的，通常使用 malloc 以及 free 库函数。正是由于后面这个性质—由程序员控制所有内存—而且是用明确的指针，使得 C 语言对编写操作系统而言非常有吸引力。从一定程度上来说，操作系统实际上是个实时系统，甚至通用系统也是实时系统。当中断发生时，操作系统可能只有若干微秒去完成特定的操作，否则就会丢失关键的信息。在任意时刻启动垃圾回收功能是不可接受的。



**1.8.2   头文件**

一个操作系统项目通常包括多个目录，每个目录都含有许多 .c 文件，这些文件中存有系统某个部分的代码，而一些 .h 头文件则包含供一个或多个代码文件使用的声明以及定义。头文件还可以包括简单的宏，如

```c
#define BUFFER_SIZE 4096 
```

宏允许程序员命名常数，这样代码中出现的 BUFFER_SIZE 在编译时就被数值 4096 所替代。良好的 C 程序设计实践是命名除了 0，1 和 -1 之外的所有常数，有时甚至也命名这三个数。宏可以附带参数，例如

```c
#define max(a, b)(a > b ? a: b) 
```



这个宏允许程序员编写

```c
i = max(j，k+1) 
```



从而得到

```c
i= (j > k+1 ? j : k+1) 
```



将 j 与 k+1 之间的较大者存储在 i 中。头文件还可以包含条件编译，例如

```c
#ifdef X86 
intel_int_ack();  
#endif 
```



如果宏 x86 有定义，而不是其他，则编译进对 intel_int_ack 函数的调用。为了分隔与结构有关的代码，大量使用了条件编译，这样只有当系统在 x86 上编译时，一些特定的代码才会被插入，其他的代码仅当系统在 SPARC 等机器上编译时才会插入。通过使用 #include 指令，一个 .c 文件体可以含有零个或多个头文件。



**1.8.3   大型编程项目**

为了构建操作系统，每个 .c 被 C 编译器编译成一个**目标文件**。目标文件使用后缀 .o，含有目标机器的二进制代码。随后它们可以直接在 CPU 上运行。在 C 的世界里，没有类似于 Java 字节代码的东西。

C 编译器的第一道处理称为 C **预处理器**。在它读入每个 .c 文件时，每当遇到一个 #include 指令，就取来该名称的头文件，并加以处理、扩展宏、处理条件编译（以及其他事务），然后将结果传递给编译器的下一道，仿佛它们原先就包含在该文件中一样。

由于操作系统非常大（500 万行代码是很寻常的），每当文件修改后就重新编译是无法忍受的。另一方面，改变了用在成千上万个文件中的一个关键头文件，确实需要重新编译这些文件。没有一定的协助，要想记录哪个目标文件与哪个头文件相关是完全不可行的。

幸运的是，计算机非常善于处理事物分类。在 UNIX 系统中，有个名为 make 的程序（其大量的变体如 gmake、pmak e等），它读入 Makefile，该 Makefile 说明哪个文件与哪个文件相关。make 的作用是，在构建操作系统二进制码时，检查此刻需要哪个目标文件，而且对于每个文件，检查自从上次目标文件创建之后是否有任何它依赖的文件（代码和头文件）已经被修改了。如果有，目标文件需要重新编译。在 make 确定了哪个 .o 文件需要重新编译之后，它调用 C 编译器重新编译这些文件，这样，就把编译的次数降到最低限度。在大型项目中，创建 Makefile 是一件容易出错的工作，所以出现了一些工具使该工作能够自动完成。

一旦所有的 .o 文件就绪，这些文件被传递给称为 linker 的程序，将其组合成一个可执行的二进制文件。此时，任何被调用的库函数都已经包含在内，函数之间的引用都已经解决，而机器地址也都按需要分配完毕。在 linker 完成之后，得到一个可执行程序，在 UNIX 中传统上称为 a.out 文件。这个过程中的各个部分如图 1-30 所示，图中的程序包含三个 C 文件和两个头文件。这里虽然讨论的是有关操作系统的开发，但是所有内容对开发任何大型程序而言都是适用的。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE23.jpg"/>
</div>





**1.8.4   运行模型**

在操作系统二进制代码链接完成后，计算机就可以重新启动，新的操作系统开始运行。一旦运行，系统会动态调入那些没有静态包括在二进制代码中的模块，如设备驱动和文件系统。在运行过程中，操作系统可能由若干段组成，有文本段（程序代码）、数据段和堆栈段。文本段通常是不可改变的，在运行过程中不可修改。数据段开始时有一定的大小，并用确定的值进行初始化，但是随后就被修改了，其大小随需要增长。堆栈段被初始化为空，但是随着对函数的调用和从函数返回，堆栈段时时刻刻在增长和缩小。通常文本段放置在接近内存底部的位置，数据段在其上面，这样可以向上增长。而堆栈段处于高位的虚拟地址，具有向下增长的能力，不过不同系统的工作方式各有差别。

在所有情形下，操作系统代码都是直接在硬件上执行的，不用解释器，也不是即时编译，如 Java 通常做的那样。



##### 1.9~1.11

略



##### 1.12	小结

考察操作系统有两种观点：资源管理观点和扩展的机器观点。在资源管理观点中，操作系统的任务是有效地管理系统的各个部分。在扩展的机器观点中，系统的任务是为用户提供比实际机器更便于运用的抽象。这些抽象包括进程、地址空间以及文件。

操作系统的历史很长，从操作系统开始替代操作人员的那天开始到现代多道程序系统，主要包括早期批处理系统、多道程序系统以及个人计算机系统。

由于操作系统同硬件的交互密切，掌握一些硬件知识对于理解它们是有益的。计算机由处理器、存储器以及 I/O 设备组成。这些部件通过总线连接。

所有操作系统构建所依赖的基本概念是进程、存储管理、I/O 管理、文件管理和安全。这些内容都将在后续用一章来讲述。

任何操作系统的核心是它可处理的系统调用集。这些系统调用真实地说明了操作系统所做的工作。对于 UNIX，我们已经考察了四组系统调用。第一组系统调用同进程的创建和终止有关；第二组用于读写文件；第三组用于目录管理；第四组包括各种杂项调用。

操作系统构建方式有多种。最常见的有单体系统、层次化系统、微内核系统、客户端-服务器系统、虚拟机系统和外核系统。





### 第 2 章	进程与线程

从本章开始，我们将深入考察操作系统是如何设计和构造的。操作系统中最核心的概念是**进程**：这是对正在运行程序的一个抽象。操作系统的其他所有内容都是围绕着进程的概念展开的，所以，让操作系统的设计者（及学生）尽快并透彻地理解进程是非常重要的。

进程是操作系统提供的最古老的也是最重要的抽象概念之一。即使可以使用的 CPU 只有一个，但它们也具有支持（伪）并发操作的能力，它们将一个单独的 CPU 变换成多个虚拟的 CPU。没有进程的抽象，现代计算将不复存在。本章会通过大量的细节去探究进程，以及它们的第一个亲戚——线程。



#### 2.1	进程

所有现代的计算机经常会在同一时间做许多件事。习惯于在个人计算机上工作的人们也许不会十分注意这个事实，因此列举一些例子可以更清楚地说明这一问题。先考虑一个网络服务器，一些网页请求从各处进入。当一个请求进入时，服务器检查其需要的网页是否在缓存中。如果是，则把网页发送回去；如果不是，则启动一个键盘请求以获取网页。然而，从 CPU 的角度来看，磁盘请求需要漫长的时间，当等待磁盘请求完成时，其他更多的请求将会进入。如果有多个磁盘存在，可以在满足第一个请求之前就接二连三地对其他的磁盘发出部分或全部请求。很明显，需要一些方法去模拟并控制这种并发。进程（特别是线程）在这里就可以发挥作用。

现在考虑只有一个用户的 PC。一般用户不知道，当启动系统时，会秘密启动许多进程。例如，启动一个进程来等待进入的电子邮件；或者启动另一个防病毒进程周期性地检查是否有病毒库更新。另外，某个用户进程可能会在所有用户上网地时候打印文件以及刻录 CD-ROM。这些活动都需要管理，于是一个支持多进程地多道程序系统在这里就显得很有用了。

在任何多道程序设计系统中，CPU 由一个进程快速切换至另一个进程，使每个进程各运行几十或几百毫秒。严格地说，在某一个瞬间，CPU 只能运行一个进程。但在 1 秒钟内，它可能运行多个进程，这样就产生并行的错觉。有时人们所说的**伪并行**就是指这种情形，以此来区分**多处理器系统**（该系统有两个或多个 CPU 共享同一个物理内存）的真正硬件并行。人们很难对多个并行活动进行跟踪，因此，经过多年的努力，操作系统的设计者开发了用于描述并行的一种概念模型（顺序进程），使得并行更容易处理。有关该模型、它的使用以及它的影响正是本章的主题。



##### 2.1.1	进程模型

在进程模型中，计算机上所有可运行的软件，通常也包括操作系统，被组织成若干**顺序进程**（sequential process），简称**进程**（process）。一个进程就是一个正在运行程序的示例，包括顺序计数器、寄存器和变量的当前值。从概念上说，每个进程拥有它自己的虚拟 CPU。当然，实际上真正的 CPU 在各进程之间来回切换。但为了理解这种系统，考虑在（伪）并行情况下运行的进程集，要比试图跟踪 CPU 如何在程序间来回切换简单得多。正在在第 1 章所看到的，这种快速的切换称作**多道程序设计**。

在图 2-1a 中可以看到，在一台多道程序计算机的内存中有 4 道程序。在图 2-1b 中，这 4 道程序被抽象为 4 个各自拥有自己控制流程（即每个程序自己的逻辑程序计数器）的进程，并且每个程序都独立地运行。当然，实际上只有一个物理程序计数器，所以在每个程序运行时，它的逻辑程序计数器被装入实际的程序计数器中。当该程序执行结束（或暂停执行）时，物理程序计数器被保存在内存中该进程的逻辑程序计数器中。在图 2-1c 中可以看到，在观察足够长的一段时间后，所有的进程都运行了，但在任何一个给定的瞬间仅有一个进程真正在运行。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE24.jpg"/>
</div>

在本章中，我们假设只有一个 CPU。当然，逐渐这个假设就不为真了，因为新的芯片经常是多核的，包含 2 个、4 个或更多的 CPU。第 8 章将会介绍多核芯片以及多处理器，但是现在，一次只考虑一个 CPU 会更简单一些。因此，当我们说一个 CPU 只能真正运行一个进程的时候，即使有 2 个核（或 CPU），每一个核也只能一次运行一个进程。

由于 CPU 在各进程之间来回快速切换，所以每个进程执行其运算的速度是不确定的。而且当同一进程再次运行时，其运算速度通常也不可再现。所以，在对进程编程时决不能对时序做任何想当然的假设。例如，考虑一个 I/O 进程，它用流式磁带机恢复备份的文件，它执行一个 10 000 次的空循环以等待磁带机达到正常速度，然后发出命令读取第一个记录。如果 CPU 决定在空循环期间切换到其他进程，则磁带机进程可能在第一条记录通过磁头之后还未被再次运行。当一个进程具有此类严格的实时要求时，也就是一些特定事件一定要在所指定的若干毫秒内发生，那么必须采取特殊措施以保证它们一定在这段时间中发生。然而，通常大多数进程并不受 CPU 多道程序设计或其他进程相对速度的影响。

进程和程序间的区别是很微妙的，但非常重要。用一个比喻可以更容易理解这一点。想象一位有一手好厨艺的计算机科学家正在为他的女儿烘制生日蛋糕。他有做生日蛋糕的食谱，厨房里有所需的原料：面粉、鸡蛋、糖、香草汁等。在这个比喻中，做蛋糕的食谱就是程序（即用适当形式描述的算法），计算机科学家就是处理器（CPU），而做蛋糕的各种原料就是输入数据。进程就是厨师阅读食谱、取来各种原料以及烘制蛋糕等一系列动作的总和。

现在假设计算机科学家的儿子哭着跑了进来，说他的头被一只蜜蜂蛰了。计算机科学家就记录下他照着食谱做到哪儿了（保存进程的当前状态），然后拿出一本急救手册，按照其中的指示处理蛰伤。这里，处理机从一个进程（做蛋糕）切换到另一个高优先级的进程（实施医疗救治），每个进程拥有各自的程序（食谱和急救手册）。当蜜蜂蛰伤处理完之后，这位计算机科学家又回来做蛋糕，从他离开时的那一步继续做下去。

这里的关键思想是：一个进程是某种类型的一个活动，它有程序、输入、输出以及状态。单个处理器可以被若干进程共享，它使用某种调度算法决定何时停止一个进程的工作，并转而为另一个进程提供服务。

值得注意的是，如果一个程序运行了两遍，则算作两个进程。例如，人们可能经常两次启动同一个字处理软件，或在有两个可用的打印机的情况下同时打印两个文件。像“两个进程恰好运行同一个程序”这样的事实其实无关紧要，因为它们是不同的进程。操作系统能够使它们共享代码，因此只有一个副本放在内存中，但那只是一个技术性的细节，不会改变有两个进程正在运行的概念。



##### 2.1.2	进程的创建

操作系统需要有一种方式来创建进程。一些非常简单的系统，即那种只为运行一个应用程序设计的系统（例如，微波炉中的控制器），可能在系统启动之时，以后所需要的所有进程都已存在。然而，在通用系统中，需要有某种方法在运行时按需要创建或撤销进程，现在开始考察这个问题。

4 种主要事件会导致进程的创建：

1. 系统初始化。

2. 正在运行的程序执行了创建进程的系统调用。

3. 用户请求创建一个新进程。

4. 一个批处理作业的初始化。

   

启动操作系统时，通常会创建若干个进程。其中有些是前台进程，也就是同用户（人类）交互并且替他们完成工作的那些进程。其他的是后台进程，这些进程与特定的用户没有关系，相反，却具有某些专门的功能。例如，设计一个后台进程来接收发来的电子邮件，这个进程在一天的大部分时间都在睡眠，但是当电子邮件到达时就突然被唤醒了。也可以设计另一个后台进程来接收对该机器中 Web 页面的访问请求，在请求到达时唤醒该进程以便服务该请求。停留在后台处理诸如电子邮件、Web 页面、新闻、打印之类活动的进程称为**守护进程**（daemon）。在大型系统中通常有很多守护进程。在 UNIX 中，可以用 ps 程序列出正在运行的进程；在 Windows 中，可使用任务管理器。

除了在启动阶段创建进程之外，新的进程也可以以后创建。一个正在运行的进程经常发出系统调用，以便创建一个或多个新进程协助其工作。在所要从事的工作可以容易地划分成若干相关的但没有相互作用的进程时，创建新的进程就特别有效果。例如，如果有大量的数据要通过网络调取并进行顺序处理，那么创建一个进程取数据，并把数据放入共享缓冲区中，而让第二个进程取走数据项并处理之，应该比较容易。在多处理机中，让每个进程在不同的CPU上运行会使整个作业运行得更快。

在交互式系统中，键入一个命令或者点（双）击一个图标就可以启动一个程序。这两个动作中的任何一个都会开始一个新的进程，并在其中运行所选择的程序。在基于命令行的 UNIX 系统中运行程序 X，新的进程会从该进程接管开启它的窗口。在 Microsoft Windows 中，多数情形都是这样的，在一个进程开始时，它并没有窗口，但是它可以创建一个（或多个）窗口。在 UNIX 和 Windows 系统中，用户可以同时打开多个窗口，每个窗口都运行一个进程。通过鼠标用户可以选择一个窗口并且与该进程交互，例如，在需要时提供输入。

最后一种创建进程的情形仅在大型机的批处理系统中应用。用户在这种系统中（可能是远程地）提交批处理作业。在操作系统认为有资源可运行另一个作业时，它创建一个新的进程，并运行其输入队列中的下一个作业。

从技术上看，在所有这些情形中，新进程都是由于一个已存在的进程执行了一个用于创建进程的系统调用而创建的。这个进程可以是一个运行的用户进程、一个由键盘或鼠标启动的系统进程或者一个批处理管理进程。这个进程所做的工作是，执行一个用来创建新进程的系统调用。这个系统调用通知操作系统创建一个新进程，并且直接或间接地指定在该进程中运行的程序。

在 UNIX 系统中，只有一个系统调用可以用来创建新进程：fork。这个系统调用会创建一个与调用进程相同的副本。在调用了 fork 后，这两个进程（父进程和子进程）拥有相同的内存映像、同样的环境字符串和同样的打开文件。这就是全部情形。通常，子进程接着执行 execve 或一个类似的系统调用，以修改其内存映像并运行一个新的程序。例如，当一个用户在 shell 中键入命令 sort 时，shell 就创建一个子进程，然后，这个子进程执行 sort。之所以要安排两步建立进程，是为了在 fork 之后但在 execve 之前允许该子进程处理其文件描述符，这样可以完成对标准输入文件、标准输出文件和标准错误文件的重定向。

在 Windows 中，情形正相反，一个 Win32 函数调用 CreateProcess 既处理进程的创建，也负责把正确的程序装入新的进程。该调用有 10 个参数，其中包括要执行的程序、输入给该程序的命令行参数、各种安全属性、有关打开的文件是否继承的控制位、优先级信息、该进程（若有的话）所需要创建的窗口规格以及指向一个结构的指针，在该结构中新创建进程的信息被返回给调用者。除了 CreateProcess，Win32 中有大约 100 个其他的函数用于处理进程的管理、同步以及相关的事务。

在 UNIX 和 Windows 中，进程创建之后，父进程和子进程有各自不同的地址空间。如果其中某个进程在其地址空间中修改了一个字，这个修改对其他进程而言是不可见的。在 UNIX 中，子进程的初始地址空间是父进程的一个副本，但是这里涉及两个不同的地址空间，不可写的内存区是共享的。某些 UNIX 的实现使程序正文在两者间共享，因为它不能被修改。或者子进程共享父进程的所有内存，但这种情况下内存通过**写时复制**（copy-on-write）共享，这意味着一旦两者之一想要修改部分内存，则这块内存首先被明确地复制，以确保修改发生在私有内存区域。再次强调，可写的内存是不可以共享的。但是，对于一个新创建的进程而言，确实有可能共享其创建者的其他资源，诸如打开的文件等。在 Windows 中，从一开始父进程和子进程的地址空间就是不同的。



##### 2.1.3	进程的终止

进程在创建之后，它开始运行，完成其工作。但永恒是不存在的，进程也一样。迟早这个新的进程会终止，通常由下列条件引起：

1. 正常退出（自愿的）。
2. 出错退出（自愿的）。
3. 严重错误（非自愿）。
4. 被其他进程杀死（非自愿）。

多数进程是由于完成了它们的工作而终止。当编译器完成了所给定程序的编译之后，编译器执行一个系统调用，通知操作系统它的工作已经完成。在 UNIX 中该调用是 exit，而在 Windows 中，相关的调用是 ExitProcess。面向屏幕的程序也支持自愿终止。字处理软件、Internet 浏览器和类似的程序中总有一个供用户点击的图标或菜单项，用来通知进程删除它所打开的任何临时文件，然后终止。

进程种植的第二个原因是进程发现了严重操作。例如，如果用户键入命令

cc foo.c

要编译程序 foo.c，但是该程序并不存在，于是编译器就会退出。在给出了错误参数时，面向屏幕的交互式进程通常并不退出。相反，这些程序会弹出要给对话框，并要求用户再试一次。

进程终止的第三个原因是由进程引起的错误，通常是由于程序中的错误所致。例如，执行了一条非法指令、引用不存在的内存，或除数是零等。有些系统中（如 UNIX），进程可以通知操作系统，它希望自行处理某些类型的错误，在这类错误中，进程会收到信号（被中断），而不是在这类错误出现时终止。

第四种终止进程的原因是，某个进程执行一个系统调用通知操作系统杀死某个其他进程。在 UNIX 中，这个系统调用是 kill。在 Win32 中对应的函数是 TerminateProcess。在这两种情形中，“杀手” 都必须获得确定的授权以便进行动作。在有些系统中，当一个进程终止时，不论是自愿的还是其他原因，由该进程所创建的所有进程也一律立即被杀死。不过，UNIX 和 Windows 都不是这种工作方式。



##### 2.1.4	进程的层次结构

某些系统中，当进程创建了另一个进程后，父进程和子进程就以某种形式继续保持关联。子进程自身可以创建更多的进程，组成一个进程的层次结构。请注意，这与植物和动物的有性繁殖不同，进程只有一个父进程（但是可以有零到多个子进程）。

在 UNIX 中，进程和它的所有子进程以及后裔共同组成一个进程组。当用户从键盘发出一个信号时，该信号被送给当前与键盘相关的进程组中的所有成员（它们通常是在当前窗口创建的所有活动进程）。每个进程可以分别捕获该信号、忽略该信号或采取默认的动作，即被该信号杀死。

这里有另一个例子，可以用来说明进程层次的作用，考虑 UNIX 在启动时如何初始化自己。一个称为 init 的特殊进程出现在启动映像中。当它开始运行时，读入一个说明终端数量的文件。接着，为每个终端创建一个新进程。这些进程等待用户登录。如果有一个用户登录成功，该登录进程就执行一个 shell 准备接收命令。所接收的这些命令会启动更多的进程，以此类推。这样，在整个系统中，所有的进程都属于以 init 为根的一棵树。

相反，Windows 中没有进程层次的概念，所有的进程都是地位相同的。唯一类似于进程层次的暗示是在创建进程的时候，父进程得到一个特别的令牌（称为**句柄**），该句柄可以用来控制子进程。但是，它有权把这个令牌传送给某个其他进程，这样就不存在进程层次了。在 UNIX 中，进程就不能剥夺其子继承的 “继承权”。



##### 2.1.5	进程的状态

尽管每个进程是一个独立的实体，有其自己的程序计数器和内部状态，但是，进程之间经常需要相互作用。一个进程的输出结构可能作为另一个进程的输入。在 shell 命令

cat chapter1 chapter2 chapter3 | grep tree

中，第一个进程运行 cat，将三个文件连接并输出。第二个进程运行 grep，它从输入中选择所有包含单词 “tree” 的那些行。根据这两个进程的相对速度（这取决于这两个程序的相对复杂度和各自所分配到的 CPU 时间），可能发生这种情况：grep 准备就绪可以运行，但输入还没有完成。于是必须阻塞 grep，直到输入到来。

当一个进程在逻辑上不能继续运行时，它就会被阻塞，典型的例子是它在等待可以使用的输入。还可能有这样的情况：一个概念上能够运行的进程被迫停止，因为操作系统调度另一个进程占用了 CPU。这两种情况是完全不同的。在第一种情况下，进程被迫挂起是程序自身固有的原因（在键入用户命令行之前，无法执行命令）。第二种情况则是由系统技术上的原因引起的（由于没有足够的 CPU，所以不能使每个进程都有一台私用的处理器）。在图 2-2 中可以看到显示进程的三种状态的状态图，这三种状态是：

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE25.jpg"/>
</div>



1. 运行态（该时刻进程实际占用 CPU）。
2. 就绪态（可运行，但因为其他进程正在运行而暂时停止）。
3. 阻塞态（除非某种外部事件发生，否则进程不能运行）。

前两种状态在逻辑上类似的。处于这两种状态的进程都可以运行，只是对于第二种状态暂时没有 CPU 分配给它。第三种状态与前两种状态不同，处于该状态的进程不能运行，即使 CPU 空闲也不行。

进程的三种状态之间有四种可能的转换关系。如图 2-2 所示。在操作系统发现进程不能继续运行下去时，发生转换 1。在某些系统中，进程可以执行一个诸如 pause 的系统调用来进入阻塞状态。在其他系统中，包括 UNIX，当一个进程从管道或设备文件（例如终端）读取数据时，如果没有有效的输入存在，则进程会被自动阻塞。

转换 2 和 3 是由进程调度程序引起的，进程调度程序是操作系统的一部分，进程甚至感觉不到调度程序的存在。系统认为一个运行进程占用处理器的时间已经过长，决定让其他进程使用 CPU 时间时，会发生转换 2。在系统已经让所有其他进程享有了它们应有的公平待遇而重新轮到第一个进程再次占用 CPU 时，会发生转换 3。调度程序的主要工作就是决定应当运行哪个进程、何时运行及它应该运行多长时间，这是很重要的一点，我们将在本章的后面部分进行讨论。明确已经提出了许多算法，这些算法力图在整体效率和进程的竞争公平性之间取得平衡。我们将在本章稍后部分研究其中的一些问题。

当进程等待的一个外部事件发生时（如一些输入到达），则发生转换 4。如果此时没有其他进程运行，则立即触发转换 3，该进程便开始运行。否则该进程将处于就绪态，等待 CPU 空闲并且轮到它运行。

使用进程模型使得我们易于想象系统内部的操作状况。一些进程正在运行执行用户键入命令所对应的程序。另一些进程是系统的一部分，它们的任务是完成下列一些工作：比如，执行文件服务请求、管理磁盘驱动器和磁带机的执行细节等。当发生一个磁盘中断时，系统会做出决定，停止运行当前进程，转而运行磁盘进程，该进程在此之前因等待中断而处于阻塞态。这样就可以不再考虑中断，而只是考虑用户进程、磁盘进程、终端进程等。这些进程在等待时总是处于阻塞整体。在已经读入磁盘或键入字符后，等待它们的进程就被接触阻塞，并成为可调度运行的进程。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE26.jpg"/>
</div>

从这个观点引出了图 2-3 所示的模型。在图 2-3 中，操作系统的最底层是调度程序，在它上面有许多进程。所有关于中断处理、启动进程和停止进程的具体细节都隐藏在调度程序中。实际上，调度程序是一段非常短小的程序。操作系统的其他部分被简单地组织成进程的形式。不过，很少有真实的系统是以这样的理想方式构造的。





##### 2.1.6	进程的实现

为了实现进程模型，操作系统维护着一张表格（一个结构数组），即**进程表**（process table）。每个进程占用一个进程表项。（有些作者称这些表项为**进程控制块**。）该表项包含了进程状态的重要信息，包括程序计数器、堆栈指针、内存分配状况、所打开文件的状态、账号和调度信息，以及其他在进程由运行态转换到就绪态或阻塞态时必须保存的信息，从而保证该进程随后能再次启动，就像从未被中断过一样。

图 2-4 中展示了在一个典型系统中的关键字段。第一列中的字段与进程管理有关。其他两列分别与存储管理和文件管理有关。应该注意到进程表中的字段是与系统密切相关的，不过该组给出了所需要信息的大致介绍。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE27.jpg"/>
</div>

在了解进程表后，就可以对在单个（或每一个）CPU 上如何维持多个顺序进程的错觉做更多的阐述。与每一 I/O 类关联的时一个称作**中断向量**（interrupt ）的位置（靠近内存底部的固定区域）。它包含中断服务程序的入口地址。假设当一个磁盘中断发生时，用户进程 3 正在运行，则中断硬件将程序计数器、程序状态字、有时还有一个或多个寄存器压入堆栈，计算机随即跳转到中断向量所指示的地址。这些是硬件完成的所有操作，然后软件，特别是中断服务例程就接管一切剩余的工作。

所有的中断都从保存寄存器开始，对于当前进程而言，通常是保存在进程表项中。随后，会从堆栈中删除由中断硬件机制存入堆栈的那部分信息，并将堆栈指针指向一个由进程处理程序所使用的临时堆栈。一些诸如保存寄存器值和设置堆栈指针等操作，无法用 C 语言这一类高级语言描述，所以这些操作通过一个短小的汇编语言例程来完成，通常该例程可以供所有的中断使用，因为无论中断是怎样引起的，有关保存寄存器的工作则是完全一样的。

当该例程结束后，它调用一个 C 过程处理某个特定的中断类型剩下的工作。（假定操作系统由 C 语言编写，通常这是所有真实操作系统的选择）。在完成有关工作之后，大概就会使某些进程就绪，接着调用调度程序，决定随后该运行哪个进程。随后将控制转给一段汇编语言代码，为当前的进程装入寄存器值以及内存映射并启动该进程运行。图 2-5 中总结了中断处理和调度的过程。值得注意的是，各种系统之间某些细节会有所不同。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE28.jpg"/>
</div>

一个进程在执行过程中可能被中断数千次，关键是每次中断后，被中断的进程都返回到与中断发生前完全相同的状态。



##### 2.1.7	多道程序设计模型

采用多道程序设计可以提高 CPU 的利用率。严格地说，如果进程用于计算的平均时间是进程在内存中停留时间的 20%，且内存中同时有 5 个进程，则 CPU 将一直满负载运行。然而，这个模型在现实中过于乐观，因为它假设这 5 个进程不会同时等待 I/O。

更好的模型是从概率的角度来看 CPU 的利用率。假设一个进程等待 I/O 操作的时间与其停留在内存中时间的比为 p。当内存中同时有 n 个进程时，则所有 n 个进程都在等待 I/O（此时 CPU 空转）的概率时 P^n^。CPU 的利用率由下面的公式给出：

CPU 利用率 = 1- P^n^

图 2-6 以 n 为变量的函数表示了 CPU 的利用率，n 称为**多道程序设计的道数**（degree of multiprogramming）。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE29.jpg"/>
</div>

从图 2-6 中可以清楚地看到，如果进程花费 80% 的时间等待 I/O，为使 CPU 的浪费低于 10%，至少要有 10 个进程同时在内存中。当读者认识到一个等待用户从终端输入的交互式进程是处于 I/O 等待状态时，那么很明显，80% 甚至更多的 I/O 等待时间是普遍的。即使是在服务器中，做大量磁盘 I/O 操作的进程也会花费同样或更多的等待时间。

从完全精确的角度考虑，应该指出此概率模型只是描述了一个大致的状况。它暗中假设了所有 n 个进程是独立的，即对某个系统来说，内存中的 5 个进程中，3 个运行，2 个等待，是完全可接受的（上面模型没有考虑进程间有关联会互相影响，相互依赖的情况）。但在单 CPU 中，不能同时运行 3 个进程，所以当 CPU 忙时，已就绪的进程也必须等待 CPU（就绪状态就是进程互相影响的情况）。因而，进程不是独立的。更精确的模型应该用排队论构建，但我们的模型（当进程就绪时，给进程分配 CPU，否则让 CPU 空转）仍然是有效的，即使真实曲线会与图 2-6 中所画的略有不同。

虽然图 2-6 的模型很简单、很粗略，它仍然对预测 CPU 的性能很有效。例如，假设计算机有 8GB 内存，操作系统及相关表格占用 2GB，每个用户程序也占用 2GB。这些内存空间允许 3 个用户程序同时驻留在内存中。若 80% 的时间用于 I/O 等待，则 CPU 的利用率（忽略操作系统开销）大约是 1 - 0.8^3^，即大约 49%。在增加 8GB 字节的内存后，可从 3 道程序设计提高到 7 道程序设计，因而 CPU 利用率提高到 79%，换言之，第二个 8GB 内存提高了 30% 的吞吐量。

增加第三个 8GB 内存只能将 CPU 利用率从 79% 提高到 91%，吞吐量的提高仅为 12%。通过这一模型，计算机用户可以确定，第一次增加内存是一个划算的投资，而第二个则不是。



#### 2.2	线程

在传统操作系统中，每个进程有一个地址空间和一个控制线程。事实上，这几乎就是进程的定义。不过，经常存在同一个地址空间中准并行运行多个控制线程的情形（准并行：几乎并行，
具有并行系统或设备的一些特性），这些线程就像（差不多）分离的进程（共享地址空间除外）。在下面各节中，我们将讨论这些情形及其实现。



##### 2.2.1	线程的使用

为什么人们需要在一个进程中再有一类进程？有若干理由说明产生这些迷你进程（称为**线程**）的必要性。下面我们来讨论其中一些理由。人们需要多线程的主要原因是，在许多应用中同时发生着多种活动。其中某些活动随着时间的推移会被阻塞。通过将这些应用程序分解成可以准并行运行的多个顺序线程，程序设计模型会变得更简单。

前面已经进行了有关讨论。准确地说，这正是之前关于进程模型的讨论。有了这样的抽象，我们才不必考虑中断、定时器和上下文切换，而只需考虑并行进程。类似地，只是在有了多线程概念之后，我们才加入了一种新的元素：并行实体拥有共享同一个地址空间和所有可用数据的能力。对于某些应用而言，这种能力是必需的，而这正是多进程模型（它们具有不同的地址空间）所无法表达的。

第二个关于需要多线程的理由是，由于线程比进程更轻量级，所以它们比进程更容易（即更快）创建，也更容易撤销。在许多系统中，创建一个线程较创建一个进程要快 10~100 倍。在有大量线程需要动态和快速修改时，具有这一特性是很有用的。

需要多线程的第三个原因涉及性能方面的讨论。若多个线程都是 CPU 密集型的，那么并不能获得性能上的增强，但是如果存在着大量的计算和大量的 I/O 处理，拥有多个线程允许这些活动彼此重叠进行，从而会加快应用程序执行的速度。

最后，在多 CPU 系统中，多线程是有益的，在这样的系统中，真正的并行有了实现的可能，第 8 章将讨论这个主题。

通过考察一些实际的例子，我们可以更清楚地看出引出多线程的好处。作为第一个例子，考察一个字处理软件。字处理软件通常按照出现在打印页上的格式在屏幕上精准显示文档。特别地，所有的行分隔符和页分隔符都在正确的最终位置上，这样在需要时用户可以检查和修改文档（比如，消除孤行—在一页上不完整的顶部行和底部行，因为这些行不甚美观）。

假设用户正在写一本书。从作者的观点来看，最容易的方法是把整本书作为一个文件，这样一来，查询内容、完成全局替换等都非常容易。另一种方法是，把每一章都处理成单独一个文件。但是，在把每个小节和子小节都分成单个的文件之后，若必须对全书进行全局的修改时，那就真是麻烦了，因为有成百个文件必须一个个地编辑。例如，如果所建议的某个标准××××正好在书付印之前被批准了，于是“标准草案××××”一类的字眼就必须改为“标准××××”。如果整本书是一个文件，那么只要一个命令就可以完成全部的替换处理。相反，如果一本书分成了300个文件，那么就必须分别对每个文件进行编辑。

现在考虑，如果有一个用户突然在一个有 800 页的文件的第一页上删掉了一个语句之后，会发生什么情形。在检查了所修改的页面并确认正确后，这个用户现在打算接着在第 600 页上进行另一个修改，并键入一条命令通知字处理软件转到该页面（可能要查阅只在那里出现的一个短语）。于是字处理软件被强制对整本书的前 600 页重新进行格式处理，这是因为在排列该页前面的所有页面之前，字处理软件并不知道第 600 页的第一行应该在哪里。而在第 600 页的页面可以真正在屏幕上显示出来之前，计算机可能要拖延相当一段时间，从而令用户不甚满意。

多线程可以在这里发挥作用。假设字处理软件倍编写成含有两个线程的程序。一个线程与用户交互，而另一个在后台重新进行格式处理。一旦在第 1 页中的语句被删除掉，交互线程就立即通知格式化线程对整本书重新进行处理。同时，交互线程继续监控键盘和鼠标，并响应诸如滚动第 1 页之类的简单命令，此可，另一个线程正在后台疯狂地运算。如果有点运气的话，重新格式化会在用户请求查看第 600 页之前完成，这样，第 600 页页面就立即可以在屏幕上显示出来。

如果已经做到了这一步，那么为什么不再进一步增加一个线程呢？许多字处理软件都有每隔若干分钟自动在磁盘上保存整个文件的特点，用于避免由于程序崩溃、系统崩溃或电源故障而造成用户一整天的工作丢失的情况。第三个线程可以处理磁盘备份，而不必干扰其他两个线程。拥有三个线程的情形，如图 2-7 所示。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE30.jpg"/>
</div>

如果程序是单线程的，那么在进行磁盘备份时，来自磁盘和鼠标的命令就会被忽略，直到备份工作完成为止。用户读入会认为性能很差。另一个方法是，为了获得好的性能，可以让键盘和鼠标事件中断磁盘备份，但这样却引入了复杂的中断驱动程序设计模型。如果使用三个线程，程序设计模型就很简单了。第一个线程只是和用户交互；第二个线程在得到通知时进行文档的重新格式化；第三个线程周期性地将 RAM 中的内容写道磁盘上。

很显然，在这里用三个不同地进程是不能工作地，这是因为这三个线程都需要对同一个文件进行操作。由于多个线程可以共享公共内存，所以通过用三个线程替换三个进程，使得它们可以访问同一个正在编辑的文件，而三个进程是做不到的。

许多其他的交互式程序中也存在类似的情形。例如，电子表格是允许用户维护矩阵的一种程序，矩阵中的一些元素是用户提供的数据；另一些元素是通过所输入的数据运用可能比较复杂的公式而得出的计算结果。当用户改变一个元素时，许多其他元素就必须重新计算。通过一个后台线程进行重新计算的方式，交互式线程就能够在进行计算的时候，让用户从事更多的工作。类似地，第三个线程可以在磁盘上进行周期性的备份工作。

现在考虑另一个多线程发挥作用的例子：一个万维网服务器。对页面的请求发给服务器，而所请求的页面发回给客户机。在多数 Web 站点上，某些页面较其他页面相比，有更多的访问。例如，对 Sony 主页的访问就远远超过对深藏在页面树里的任何特定摄像机的技术说明书页面的访问。利用这一事实，Web 服务器可以把获得大量访问的页面集合保存在内存中，避免到磁盘去调入这些页面，从而改善性能。这样的一种页面集合称为**高速缓存**（cache），高速缓存也运用在其他许多场合中。例如在第 1 章中介绍的 CPU 缓存。

一种组织 Web 服务器的方式如图 2-8 所示。在这里，一个称为**分派程序**（dispatcher）的线程从网络中读入工作请求。在检查请求之后，分派线程挑选一个空转的（即被阻塞的）**工作线程**（worker thread），提交该请求，通常是在每个线程所配有的某个专门字中写入一个消息指针。接着分派线程唤醒睡眠的工作线程，将它从阻塞状态转为就绪状态。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE39.jpg"/>
</div>

在工作线程被唤醒之后，它检查有关的请求是否在 Web 页面高速缓存之中，这个高速缓存是所有线程都可以访问的。如果没有，该线程开始一个从磁盘调入页面的 read 操作，并且阻塞直到该磁盘操作完成。当上述线程阻塞在磁盘操作上时，为了完成更多的工作，分派线程可能挑选另一个线程运行，也可能把另一个当前就绪的工作线程投入运行。

这种模型允许把服务器编写为顺序线程的一个集合。在分派线程的程序中包含一个无限循环，该循环用来获得工作请求并且把工作请求派给工作线程。每个工作线程的代码包含一个从分派线程接收请求，并且检查 Web 高速缓存中是否存在所需页面的无限循环。如果存在，就将该页面返回给客户机，接着该工作线程阻塞，等待一个新的请求。如果没有，工作线程就从磁盘调入该页面，将该页面返回给客户机，然后该工作线程阻塞，等待一个新的请求。

图 2-9 给出了有关代码的大致框架。如同本书的其他部分一样，这里假设 TRUE 为常数 1。另外，buf 和 page 分别是保存工作请求和 Web 页面的相应结构。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE31.jpg"/>
</div>

现在考虑在没有多线程的情形下，如何编写 Web 服务器。一种可能的方式是，使其像一个线程一样运行。Web 服务器的主循环获得请求，检查请求，并且在取下一个请求之前完成整个工作。在等待磁盘操作时，服务器就空转，并且不处理任何到来的其他请求。如果该 Web 服务器运行在唯一的机器上，通常情形都是这样，那么在等待磁盘操作时 CPU 只能空转。结果导致每秒钟只有很少的请求被处理。可见线程较好地改善了 Web 服务器的性能，而且每个线程都是按通常方式顺序编程的。

到现在为止，我们有了两个可能的设计方案：多线程Web服务器和单线程Web服务器。假设没有多线程可用，而系统设计者又认为由于单线程所造成的性能降低是不能接受的，那么如果可以使用read系统调用的非阻塞版本，还存在第三种可能的设计。在请求到来时，这个唯一的线程对请求进行考察。如果该请求能够在高速缓存中得到满足，那么一切都好，如果不能，则启动一个非阻塞的磁盘操作。

服务器在表格中记录当前请求的状态，然后去处理下一个事件。下一个事件可能是一个新工作的请求，或是磁盘对先前操作的回答。如果是新工作的请求，就开始该工作。如果是磁盘的回答，就从表格中取出对应的信息，并处理该回答。对于非阻塞磁盘I/O而言，这种回答多数会以信号或中断的形式出现。

在这一设计中，前面两个例子中的“顺序进程”模型消失了。每次服务器从为某个请求工作的状态切换到另一个状态时，都必须显式地保存或重新装入相应的计算状态。事实上，我们以一种困难的方式模拟了线程及其堆栈。这里，每个计算都有一个被保存的状态，存在一个会发生且使得相关状态发生改变的事件集合，我们把这类设计称为有限状态机（finite-state machine）。有限状态机这一概念广泛地应用在计算机科学中。

现在很清楚多线程必须提供的是什么了。多线程使得顺序进程的思想得以保留下来，这种顺序进程阻塞了系统调用（如磁盘 I/O），但是仍旧实现了并行性。对系统调用进行阻塞使程序设计变的较为简单，而且并行性改善了性能。单线程服务器虽然保留了阻塞系统调用的简易性，但是却放弃了性能。第三种处理方法运用了非阻塞调用和中断，通过并行性实现了高性能，但是给编程增加了困难。在图 2-10 中给出了上述模式的总结。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE32.jpg"/>
</div>

有关多线程作用的第三个例子是那些必须处理极大量数据的应用。通常的处理方式是，读进一块数据，对其处理，然后再写出数据。这里的问题是，如果只能使用阻塞系统调用，那么在数据进入和数据输出时，会阻塞进程。在有大量计算需要处理的时候，让 CPU 空转显然是浪费，应该尽可能避免。

多线程提供了一种解决方案，有关的进程可以用一个输入线程、一个处理线程和一个输出线程构造。输入线程把数据读入到输入缓冲区中；处理线程从输入缓冲区中取出数据，处理数据，并把结果放到输出缓冲区中；输出线程把这些结果写到磁盘上。按照这种工作方式，输入、处理和输出可以全部同时进行。当然，这种模型只有当系统调用只阻塞调用线程而不是阻塞整个进程时，才能正常工作。



##### 2.2.2	经典的线程模型

既然已经清楚为什么线程会有用以及如何使用它们，不如让我们用更进一步的眼光来审查一下上面的想法。进程模型基于两种独立的概念：资源分组处理与执行。有时，将这两种概念区分开来会更好，这就引入了 “线程” 这一概念。下面先介绍经典的线程模型；之后我们会来研究 “模糊进程与线程分界线” 的 Linux 线程模型。

理解进程的另一个角度是，用某种方法把相关的资源集中在一起。进程有存放程序正文和数据以及其他资源的地址空间。这些资源中包括打开的文件、子进程、即将发生的定时器、信号处理程序、账号信息等。把它们都放到进程中可以更容易管理。

另一个概念是，进程拥有一个执行的线程，通常简写为**线程**（thread）。在线程中有一个程序计数器，用来记录接着要执行哪一条指令。线程拥有寄存器，用来保存线程当前的工作变量。线程还拥有一个堆栈，用来记录执行历史，其中每一帧保存了一个已调用的但是还没有从中返回的过程。尽管线程必须在某个进程中执行，但是线程和它的进程是不同的概念，并且可以分别处理。进程用于把资源集中到一起，而线程则是在 CPU 上被调度执行的实体。

线程给进程模型增加了一项内容，即在同一个进程环境中，允许彼此之间有较大独立性的多个线程执行。在同一个进程中并行运行多个线程，是对在同一台计算机上并行运行多个进程的模拟。在前一种情形下，多个线程共享同一个地址空间和其他资源。而在后一种情形中，多个进程共享物理内存、磁盘、打印机和其他资源。由于线程具有进程的某些性质，所以有时被称为**轻量级进程**（lightweight process）。**多线程**这个术语，也用来描述在同一个进程中允许多个线程的情形。正如在第 1 章中看到的，一些 CPU 已经有直接硬件支持多线程，并允许线程切换在纳秒级完成。

在图 2-11a 中，可以看到三个传统的进程。每个进程有自己的地址空间和单个控制线程。相反，在图 2-11b 中，可以看到一个进程带有三个控制线程。尽管在两种情形中都有三个先后从，但是在图 2-11a 中，每一个线程都在不同的地址空间中允许，而在图 2-11b 中，这三个线程全部在相同的地址空间中运行。

当多线程进程在单 CPU 系统中运行时，线程轮流运行。从图 2-1 中，我们已经看到了进程的多道程序设计是如何工作的。通过在多个进程之间来回切换，系统制造了不同的顺序进程并行运行的假象，好似它们在一个比实际 CPU 慢一些的 CPU 上同时运行。在一个有三个计算密集型线程的进程中，线程以并行方式运行，每个线程在一个 CPU 上得到了真实 CPU 速度的三分之一。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE33.jpg"/>
</div>

进程中的不同线程不像不同进程之间那样存在很大的独立性。所有的线程都有完全一样的地址空间，这意味着它们也共享同样的全局变量。由于各个线程都可以访问进程地址空间中的每一个内存地址，所以一个线程可以读、写或甚至清除另一个线程的堆栈。线程之间是没有保护的，原因是：1）不可能，2）也没有必要。这与不同进程是有差别的。不同的进程会来自不同的用户，它们彼此之间可能有敌意，一个进程总是由某个用户所拥有，该用户创建多个线程应该是为了它们之间的合作而不是彼此间争斗。 除了共享地址空间之外，所有线程还共享同一个打开文件集、子进程、定时器以及相关信号等，如图 2-12 所示。这样，对于三个没有关系的线程而言，应该使用图 2-11a 的结构，而在三个线程实际完成同一个作业，并彼此积极密切合作的情形中，图 2-11b 则比较合适。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE34.jpg"/>
</div>

图 2-12 中，第一列表项是进程的属性，而不是线程的属性。例如，如果一个线程打开了一个文件，该文件对该进程中的其他线程都可见，这些线程可以对该文件进行读写。由于资源管理的单位是进程而非线程，所以这种情形是合理的。如果每个线程都有其自己的地址空间、打开文件、即将发生的定时器等，那么它们就应该是不同的进程了。线程概念试图实现的是，共享一组资源的多个线程的执行能力，以便这些线程可以为完成某一任务而共同工作。

和传统进程一样（即只有一个线程的进程），线程可以处于若干种状态的任何一个：运行、阻塞、就绪或终止。正在运行的线程拥有CPU并且是活跃的。被阻塞的线程正在等待某个释放它的事件。例如，当一个线程执行从键盘读入数据的系统调用时，该线程就被阻塞直到键入了输入为止。线程可以被阻塞，以便等待某个外部事件的发生或者等待其他线程来释放它。就绪线程可被调度运行，并且只要轮到它就很快可以运行。线程状态之间的转换和进程状态之间的转换是一样的，如图 2-2 所示。

认识到每个线程有其自己的堆栈很重要，如图 2-13 所示。每个线程的堆栈有一帧，供各个被调用但是还没有从中返回的过程使用。在该栈帧中存放了相应过程的局部变量以及过程调用完成之后使用的返回地址。例如，如果过程 X 调用过程 Y，而 Y 又调用 Z，那么当 Z 执行时，供 X、Y 和 Z 使用的栈帧会全部存在堆栈中。通常每个线程会调用不同的过程，从而有一个各自不同的执行历史，这就是为什么每个线程需要有自己的堆栈的原因。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE35.jpg"/>
</div>

在多线程的情况下，进程通常会从当前的单个线程开始。这个线程有能力通过调用一个库函数（如 thread_create）创建新的线程。thread_create 的参数专门指定了新线程要运行的过程名。这里，没有必要对新线程的地址空间加以规定，因为新线程会自动在创建线程的地址空间中运行。有时，线程是有层次的，它们具有一种父子关系，但是，通常不存在这样一种关系，所有的线程都是平等的。不论有无层次关系，创建线程通常都返回一个线程标识符，该标识符就是新线程的名字。

当一个线程完成工作后，可以通过调用一个库过程（如 thread_exit）退出。该线程接着消失，不再可调度。在某些线程系统中，通过调用一个过程，例如 thread_join，一个线程可以等待一个（特定）线程退出。这个过程阻塞调用线程直到那个（特定）线程退出。 在这种情况下，线程的创建和终止非常类似于进程的创建和终止，并且也有着同样的选项。

另一个常见的线程调用是 thread_yield，它允许线程自动放弃 CPU 从而让另一个线程运行。这样一个调用是很重要的，因为不同于进程，（线程库）无法利用时钟中断强制线程让出 CPU。所以设法使线程行为 “高尚” 起来，并且随着时间的推移自动交出 CPU，以便让其他线程有机会运行，就变得非常重要。有的调用允许某个线程等待另一个线程完成某些任务，或等待一个线程宣称它已经完成了有关的工作等。

通常而言，线程是有益的，但是线程也在程序设计模式中引入了某种程度的复杂性。考虑一下 UNIX 中的 fork 系统调用。如果父进程有多个线程，那么它的子进程也应该拥有这些线程吗？如果不是，则该子进程可能会工作不正常，因为这些线程可能是必不可少的。

然而，如果子进程拥有了与父进程一样的多个线程，如果父进程在 read 系统调用（比如键盘）上被阻塞了会发生什么情况？是两个线程被阻塞在键盘上（一个属于父进程，另一个属于子进程）吗？在键入一行输入之后，这两个线程都得到该输入的副本吗？还是仅有父进程得到该输入的副本？或是仅有子进程得到？类似的问题在进行网络连接时也会出现。

另一类问题和线程共享许多数据结构的事实有关。如果一个线程关闭了某个文件，而另一个线程还在该文件上进行读操作时会怎样？假设有一个线程注意到几乎没有内存了，并开始分配更多的内存。在工作一半的时候，发生线程切换，新线程也注意到几乎没有内存了，并且也开始分配更多的内存。这样，内存可能会被分配两次。不过这些问题通过努力是可以解决的。总之，要使多线程的程序正确工作，就需要仔细思考和设计。



##### 2.2.3	POSIX 线程

为实现可移植的线程程序，IEEE 在 IEEE 标准 1003.1c 中定义了线程的标准。它定义的线程包叫作 pthread。大部分 UNIX 系统都支持该标准。这个标准定义了超过 60 个函数调用，如果在这里列举一遍就太多了。这里仅描述一些主要的函数，以说明它是如何工作的。图 2-14 中列举了这些函数调用。

所有 pthread 线程都有某些特性。每一个都含有一个标识符、一组寄存器（包括程序计数器）和一组存储在结构中的属性。这些属性包括堆栈大小、调度参数以及其他线程需要的项目。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE36.jpg"/>
</div>

创建一个新线程需要使用 pthread_create 调用。新创建的线程的线程标识符会作为函数值返回。这种调用有意看起来很像 fork 系统调用，其中线程标识符起着 PID 的作用，而这么做的目的主要是为了标识在其他调用中引用的线程。

当一个线程完成分配给它的工作时，可以通过调用 pthread_exit 来终止。这个调用终止该线程并释放它的栈。

一般一个线程在继续运行前需要等待另一个线程完成它的工作并退出。可以通过 pthread_join 线程调用来等待别的特定线程的终止。而要等待线程的线程标识符作为一个参数给出。

有时会出现这种情况：一个线程逻辑上没有阻塞，但感觉上它已经运行了足够长时间并且希望给另外一个线程机会去运行。这时可以通过调用 pthread_yield 完成这一目标。而进程中没有这种调用，因为假设进程间会有激烈的竞争性，并且每一个进程都希望获得它所能得到的所有的CPU时间。但是，由于同一进程中的线程可以同时工作，并且它们的代码总是由同一个程序员编写的，因此，有时程序员希望它们能互相给对方一些机会去运行。

下面两个线程调用是处理属性的。pthread_attr_init 建立关联一个线程的属性结构并初始化成默认值。这些值（例如优先级）可以通过修改属性结构中的域值来改变。

最后，pthread_attr_destroy 删除一个线程的属性结构，释放它占用的内存。它不会影响调用它的线程。这些线程会继续存在。

为了更好地了解 pthread 是如何工作的，考虑图 2-15 提供的简单例子。这里主程序在宣布它的意图之后，循环 NUMBER_OF_THREADS 次，每次创建一个新的线程。如果线程创建失败，会打印出一条错误信息然后退出。在创建完所有线程之后，主程序退出。

当创建一个线程时，它打印一条一行的发布信息，然后退出。这些不同信息交错的顺序是不确定的，并且可能在连续运行程序的情况下发生变化。

pthread 调用不只是前面介绍的这几个，还有许多的pthread调用会在讨论“进程与线程同步”之后再介绍。



##### 2.2.4	在用户空间中实现线程

有两种主要的方法实现线程包：在用户空间中和在内核中。这两种方法的选择有点争议，混合实现也是可能的。我们现在介绍这些方法，并分析它们的优点和缺点。

第一种方法是把整个线程包放在用户空间中，内核对线程包一无所知。从内核角度考虑，就是按正常的方式管理，即单线程进程。这种方法第一个也是最明显的优点是，用户级线程包可以在不支持线程的操作系统上实现。过去所有的操作系统都属于这个范围，即使现在也有一些操作系统还是不支持线程。通过这一方法，可以用函数库实现线程。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE37.jpg"/>
</div>

所有的这类实现都有同样的通过结构，如图 2-16a 所示。线程在一个运行时系统的上层运行，该运行系统是一个管理线程的过程的集合。前面已经介绍过其中的四个过程：pthread_create，pthread_exit，pthread_join和pthread_yield。不过，一般还会有更多的过程。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE38.jpg"/>
</div>

在用户空间管理线程时，每个进程需要有其专用的**线程表**（thread table），用来跟踪该进程中的线程。这些表和内核中的进程表类似，不过它仅仅记录各个线程的属性，如每个线程的程序计数器、堆栈指针、寄存器和状态等。该线程表由运行时系统管理。当一个线程转换到就绪状态或阻塞状态时，在该线程表中存放重新启动该线程所需的信息，与内核在进程表中存放进程的信息完全一样。

当某个线程做了一些会引起在本地阻塞的事情之后，例如，等待进程中另一个线程完成某项工作，它调用一个**运行时系统**的过程，这个过程检查该线程是否必须进入阻塞状态。如果是，它在线程表中保存该线程的寄存器（即它本身的），查看表中可运行的就绪线程，并把新线程的保存值重新装入机器的寄存器中。只要堆栈指针和程序计数器（program
counter，IP）一被切换，新的线程就又自动投入运行。如果机器有一条保存所有寄存器的指令和另一条装入全部寄存器的指令，那么整个线程的切换可以在几条指令内完成。进行类似于这样的线程切换至少比陷入内核要快一个数量级（或许更多），这是使用用户级线程包的一个强有力的理由。

不过，线程与进程有一个关键的差别。在线程完成运行时，例如，在它调用 thread_yield 时，thread_yield 代码可以把该线程的信息保存在线程表中，进而，它可以调用线程调度程序来选择另一个要运行的线程。保存该线程状态的过程和使用的调度程序都只是本地过程，所以启动它们比进行内核调用效率更高。另一方面，不需要陷入内核，不需要上下文切换，也不需要对内存高速缓存进行刷新，这就使得线程调度非常快捷。

用户级线程还有其他优点。它允许每个进程都有自己定制的调度算法。例如，在某些应用程序中，那些有垃圾收集线程的应用程序就不用担心线程会在不合适的时刻停止，这是一个长处。用户级线程还具有较好的可扩展性，这是因为在内核空间中内核线程始终需要一些固定表格空间和堆栈空间，如果内核线程的数量非常大，就会出现问题（线程能够利用的表空间和堆栈空间比内核级线程多）。

尽管用户级线程包有更好的性能，但它也存在一些明显的问题。其中第一个问题是如何实现阻塞系统调用。假设在还没有任何击键之前，一个线程读取键盘。让该线程实际进行该系统调用是不可接受的，因为这会停止所有的线程。使用线程的一个主要目标是，首先要允许每个线程使用阻塞调用，但是还要避免被阻塞的线程影响其他的线程。通过阻塞系统调用，这个目标不是轻易地能够实现的。

系统调用可以全部改成非阻塞的（例如，如果没有被缓冲的字符，对键盘的 read 操作可以只返回 0 字节），但是这需要修改操作系统，所以这个办法也不吸引人。而且，用户级线程的一个长处就是它可以在现有的操作系统上运行。另外，改变 read 操作的语义需要修改许多用户程序。

在这个过程中，还有一种可能的替代方案，就是如果某个调用会阻塞，就提前通知。在某些 UNIX 版本中，有一个系统调用 select 可以允许调用者通知预期的 read 是否会阻塞。若有这个调用，那么库过程 read 就可以被新的操作替代，首先进行 select 调用，然后只有在安全的情形下（即不会阻塞）才进行 read 调用。如果 read 调用会被阻塞，有关的调用就不进行，代之以运行另一个线程。到了下次有关的运行系统取得控制权之后，就可以再次检查看看现在进行read调用是否安全。这个处理方法需要重写部分系统调用库，所以效率不高也不优雅，不过没有其他的可选方案了。在系统调用周围从事检查的这类代码称为**包装器**（**jacket** 或 **wrapper**）。

与阻塞系统调用问题有些类似的是断页中断问题，我们将在第 3 章讨论这些问题。此刻可以认为，把计算机设置成这样一种工作方式，即并不是所有的程序都一次性放在内存中共。如果某个程序调用或者跳转到了一条不在内存的指令上，就会发生页面故障，而操作系统将到磁盘上取回这个丢失的指令（和该指令的“邻居们”），这就称为页面故障。在对所需的指令进行定位和读入时，相关的进程就被阻塞。如果有一个线程引起页面故障，内核由于甚至不知道有线程存在，通常会把整个进程阻塞直到磁盘 I/O 完成为止，尽管其他的线程是可以运行的。

用户级线程包的另一个问题是，如果一个线程开始运行，那么在该进程中的其他线程就不能运行，除非第一个线程自动放弃 CPU。在一个单独的进程内部，没有时钟中断，所以不可能用轮转调度（轮流）的方式调度线程。除非某个线程能够按照自己的意志进入运行时系统，否则调度程序就没有任何机会。

对线程永久运行问题的一个可能的解决方案是让运行时系统每秒请求一次时钟信号（中断）以对其进行控制，但是这样也很生硬且难以编写程序。不可能总是高频率地发生周期性的时钟中断，即使可能，总的开销也是可观的。而且，线程可能也需要时钟中断，这就会扰乱运行时系统使用的时钟。

再者，也许针对用户级线程的最大负面争论意见是，程序员通常在经常发生线程阻塞的应用中才希望使用多个线程。例如，在多线程 Web 服务器里。这些线程持续地进行系统调用，而一旦发生内核陷阱进行系统调用，如果原有的线程已经阻塞，就很难让内核进行线程的切换，如果要让内核消除这种情形，就要持续进行 select 系统调用，以便检查 read 系统调用是否安全。对于那些基本上是 CPU 密集型而且极少有阻塞的应用程序而言，使用多线程的目的又何在呢？由于这样的做法并不能得到任何益处，所以没有人会真正提出使用多线程来计算前 n 个素数或者下象棋等一类工作。



##### 2.2.5	在内核中实现线程

现在考虑内核支持和管理线程的情形。如图 2-16b 所示，此时不再需要运行时系统了。另外，每个进程中也没有线程表。相反，在内核中有用来记录系统中所有线程的线程表。当某个线程希望创建一个新线程或者撤销一个已有线程时，它进行一个系统调用，这个系统调用通过对线程表的更新完成线程创建或撤销工作。

内核的线程表保存了每个线程的寄存器、状态和其他信息。这些信息和在用户空间中（在运行时系统中）的线程是一样的，但是现在保存在内核中。这些信息是传统内核所维护的每个单线程进程信息（即进程状态）的子集。另外，内核还维护了传统的进程表，以便跟踪进程的状态。

所有能够阻塞线程的调用都以系统调用的形式实现，这与调用一个运行时系统的过程相比，代价是相当可观的。当一个线程阻塞时，内核根据其选择，可以运行同一个进程中的另一个线程（若有一个就绪线程）或者运行另一个进程中的线程。而在用户级线程中，运行时系统始终运行自己进程中的线程，直到内核剥夺它的 CPU（或者没有可运行的线程存在了）为止。

由于在内核中创建或撤销线程的代价比较大，某些系统采取 “环保” 的处理方式，回收其线程。当某个线程被撤销时，就把它标志为不可运行的，但是其内核数据结构没有受到影响。稍后，在必须创建一个新线程时，就重新启动某个旧线程，从而节省了一些开销。在用户级线程中线程回收也是可能的，但是由于其线程管理的代价很小，所以没有必要进行这项工作。

内核线程不需要任何新的、非阻塞系统调用。另外，如果某个进程中的线程引起了页面故障，内核可以很方便地检查该进程是否有任何其他可运行的线程，如果有，在等待所需要的页面从磁盘读入时，就选择一个可运行的线程运行。这样做的主要缺点是系统调用的代价比较大，所以如果线程的操作（创建、终止等）比较多，就会带来很大的开销。

虽然使用内核线程可以解决很多问题，但是也不会解决所有的问题。例如，当一个多线程进程创建新的进程时，会发生什么？新进程是拥有与原进程相同数量的线程，还是只有一个线程？在很多情况下，最好的选择取决于进程计划下一步做什么。如果它要调用 exec 来启动一个新的程序，或许一个线程是正确的选择；但是如果它继续执行，则最好复制所有的线程。



##### 2.2.6	混合实现

人们已经研究了各种试图将用户级线程的优点和内核级线程的优点结合起来的方法。一种方法是使用内核级线程，然后将用户级线程与某些或者全部内核线程多路复用起来，如图 2-17 所示。如果采用这种方法，编程人员可以决定有多少个内核级线程和多少个用户级线程彼此多路复用。这一模型带来最大的灵活度。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE40.jpg"/>
</div>

采用这种方法，内核只识别内核级线程，并对这些线程进行调度。这些线程中的某些线程可能具有多个在它们之上复用的用户级线程。 这些用户级线程的创建，销毁和调度就像在没有多线程功能的操作系统上运行的进程中的用户级线程一样。 在此模型中，每个内核级线程都有一组轮流使用它的用户级线程。



##### 2.2.7	调度程序激活机制

尽管内核级线程在一些关键点上优于用户级线程，但无可争议的是内核级线程的速度慢。因此，研究人员一直在寻找在保持其优良特性的前提下改进其速度的方法。下面将介绍 Anderson 等人（1992）设计的一种方法，称为**调度程序激活**（scheduler activation）机制。Edler 等人（1988）以及 Scott 等人（1990）就相关的工作进行了深入讨论。

调度程序激活工作的目标是模拟内核线程的功能，但是为线程包提供通常在用户空间中才能实现的更好的性能和更大的灵活性。特别地，如果用户线程从事某种系统调用时是安全的，那就不应该进行专门的非阻塞调用或者进行提前检查。无论如何，如果线程阻塞在某个系统调用或页面故障上，只要在同一个进程中有任何就绪的其他线程，就应该可以运行这些其他线程。

由于避免了在用户空间和内核空间之间的不必要转换，从而提高了效率。例如，如果某个线程由于等待另一个线程的工作而阻塞，此时没有理由请求内核，这样就减少了内核-用户转换的开销。用户空间的运行时系统可以阻塞同步的线程而另外调度一个新线程。

当使用调度程序激活机制时，内核给每个进程安排一定数量的虚拟处理器，并且让（用户空间）运行时系统将线程分配到处理器上。这一机制也可以用在多处理器中，此时虚拟处理器可能成为真实的 CPU。分配给一个进程的虚拟处理器的初始数量是一个，但是该进程可以申请更多的处理器并且在不用时退回。内核也可以取回已经分配出去的虚拟处理器，以便把它们分给需要更多处理器的进程。

使该机制工作的基本思路是，当内核了解到一个线程被阻塞之后（例如，由于执行了一个阻塞系统调用或者产生了一个页面故障），内核通知该进程的运行时系统，并且在堆栈中以参数形式传递有问题的线程编号和所发生事件的一个描述。内核通过在一个已知的起始地址启动运行时系统，从而发出了通知，这是对 UNIX 中信号的一种粗略模拟。这个机制称为**上行调用**（upcall）。

一旦如此激活，运行时系统就重新调度其线程，这个过程通常是这样的：把当前线程标记为阻塞并从就绪表中取出另一个线程，设置其寄存器，然后再启动之。稍后，当内核知道原来的线程又可运行时（例如，原先试图读取的管道中有了数据，或者已经从磁盘中读入了故障的页面），内核就又一次上行调用运行时系统，通知它这一事件。此时该运行时系统按照自己的判断，或者立即重启动被阻塞的线程，或者把它放入就绪表中稍后运行。

在某个用户线程运行的同时发生一个硬件中断时，被中断的 CPU 切换进内核态。如果被中断的进程对引起该中断的事件不感兴趣，比如，是另一个进程的 I/O 完成了，那么在中断处理程序结束之后，就把被中断的线程恢复到中断之前的状态。不过，如果该进程对中断感兴趣，比如，是该进程中的某个线程所需要的页面到达了，那么被中断的线程就不再启动，代之为挂起被中断的线程。而运行时系统则启动对应的虚拟 CPU，此时被中断线程的状态保存在堆栈中。随后，运行时系统决定在该 CPU 上调度哪个线程：被中断的线程、新就绪的线程还是某个第三种选择。

调度程序激活机制的一个目标是作为上行调用的信赖基础，这是一种违反分层次系统内在结构的概念。通常，n 层提供 n + 1 层可调用的特定服务，但是 n 层不能调用 n + 1 层中的过程。上行调用并不遵守这个基本原理。



##### 2.2.8	弹出式线程

在分布式系统中经常使用线程。一个有意义的例子是如何处理到来的消息，例如服务请求。传统的方法是将进程或线程阻塞在一个 recieve 系统调用上，等待消息到来。当消息到达时，该系统调用接收消息，并打开消息检查其内容，然后进行处理。

不过，也可能有另一种完全不同的处理方式，在该处理方式中，一个消息的到达导致系统创建一个处理该消息的线程，这种线程称为**弹出式线程**，如图 2-18 所示。弹出式线程的关键好处是，由于这种线程相当新，没有历史——没有必须存储的寄存器、堆栈诸如此类的内容，每个线程从全新开始，每一个线程彼此之间都完全一样。这样，就有可能快速创建这类线程。对该新线程指定所要处理的消息。使用弹出式线程的结果是，消息到达与处理开始之间的时间非常短。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE41.jpg"/>
</div>

在使用弹出式线程之前，需要提前进行计划。例如，线程在哪个进程中运行？如果系统支持在内核上下文中运行线程，线程就有可能在那里运行（这是图 2-18 中没有画出内核的原因）。在内核空间中运行弹出式线程通常比在用户空间中容易且快捷，而且内核空间中的弹出式线程可以很容易访问所有的内核表格和 I/O 设备，这些也许在中断处理时有用。而另一方面，出错的内核线程会比出错的用户线程造成更大的损害。例如，如果某个线程运行时间太长，又没有办法抢占它，就可能造成进来的信息永久丢失。



##### 2.2.9	使单线程代码多线程化

许多已有的程序是为单线程进行编写的。把这些改写成多线程需要比直接写多线程程序更高的技巧。下面考察一些其中易犯的错误。

先考察代码，一个线程的代码就像进程一样，通常包含多个过程，会有局部变量、全局变量和过程参数。局部变量和参数不会引起任何问题，但是有一个问题是，对线程而言是全局变量，并不是对整个程序也是全局的。有许多变量之所以是全局的，是因为线程中的许多过程都使用它们（如同它们也可能使用任何全局变量一样），但是其他线程在逻辑上和这些变量无关。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE42.jpg"/>
</div>

作为一个例子，考虑由 UNIX 维护的 errno 变量。当进程（或线程）进行系统调用失败时，错误码会放入 errno。在图 2-19 中，线程 1 执行系统调用 access 以确定是否允许它访问某个特定文件。操作系统把返回值放到全局变量 errno 里。当控制权返回到线程 1 之后，并在线程 1 读取 errno 之前，调度程序确认线程 1 此刻已用完 CPU 时间，并决定切换到线程 2。线程 2 执行一个 open 调用，结果失败，导致重写 errno，于是给线程 1 的返回值会永远丢失。随后在线程 1 执行时，它将读取错误的返回值并导致错误操作。

对于这个问题有各种解决方案。一种解决方案是全面禁止全局变量。不过这个想法不一定合适，因为它同许多已有的软件冲突。另一种解决方案是为每个线程赋予其私有的全局变量，如图 2-20 所示。在这个方案中，每个线程有自己的 errno 以及其他全局变量的私有副本，这样就避免了冲突。在效果上，这个方案创建了新的作用域层，这些变量对一个线程中所有过程都是可见的。而在原先的作用域层里，变量只对一个过程可见，并在程序中处处可见。

访问私有的全局变量需要有些技巧，不过，多数程序设计语言具有表示局部变量和全局变量的方式，而没有中间的形式。有可能为全局变量分配一块内存，并将它转送给线程中的每个过程作为额外的参数。尽管这不是一个漂亮的方案，但却是一个可用的方案。

还有另一种方案，可以引入新的库过程，以便创建、设置和读取这些线程范围的全局变量。首先一个调用也许是这样的：

```c
create_global("bufptr"); 
```



该调用在堆上或在专门为调用线程所保留的特殊存储区上替一个名为 bufptr 的指针分配存储空间。无论该存储空间分配在何处，只有调用线程才可访问其全局变量。如果另一个线程创建了同名的全局变量，由于它在不同的存储单元上，所以不会与已有的那个变量产生冲突。

访问全局变量需要两个调用：一个用于写入全局变量，另一个用于读取全局变量。对于写入，类似有

```c
set_global("bufptr", &buf); 
```



它把指针的值保存在先前通过调用 create_global 创建的存储单元中。如果要读出一个全局变量，调用的形式类似于

```c
bufptr = read_global("bufptr"); 
```



这个调用返回一个存储在全局变量中的地址，这样就可以访问其中的数据了。

试图将单一线程程序转化为多线程程序的另一个问题是，有许多库过程并不是可重入的。也就是说，它们不是被设计成下列工作坊式的：对于任何给定的过程，当前面的调用尚没有结束之前，可以进行第二次调用。例如，可以将通过网络发送消息恰当地设计为，在库内部地一个固定缓冲区中进行消息组合，然后陷入内核将其发送。但是，如果一个线程在缓冲区中编好了消息，然后被时钟中断强迫切换到第二个线程，而第二个线程立即用它自己的消息重写了该缓冲区，那会怎样呢？

类似的还有内存分配过程，例如 UNIX 中的 malloc，它维护着内存使用情况的关键表格，如可用内存块链表。在 malloc 忙于更新表格时，有可能暂时处于一种不一致的状态，指针的指向不定。如果在表格处于一种不一致的状态时发生了线程切换，并且从一个不同的线程中来了一个新的调用，就可能会由于使用了一个无效指针而导致程序崩溃。要有效解决这些问题意味着重写整个库，而这有可能引入一些微妙的错误，所以这么做是一件很复杂的事情。

另一种解决方案是，为每个过程提供一个包装器，该包装器设置一个二进制位从而标志某个库处于使用中。在先前的调用还没有完成之前，任何试图使用该库的其他线程都会被阻塞。尽管这个方式可以工作，但是它会极大地降低系统潜在的并行性。

接着考虑信号。有些信号逻辑上是线程专用的，但是另一些却不是。例如，如果某个线程调用 alarm，信号送往进行该调用的线程是有意义的。但是，当线程完全在用户空间实现时，内核根本不知道有线程存在，因此很难将信号发送给正确的线程。如果一个进程一次仅有一个警报信号等待处理，而其中的多个线程又独立地调用 alarm，那么情况就更加复杂了。

有些信号，如键盘中断，则不是线程专用的。谁应该捕捉它们？一个指定的线程？所有的线程？还是新创建的弹出式线程？进而，如果某个线程修改了信号处理程序，而没有通知其他线程，会出现什么情况？如果某个线程想捕捉一个特定的信号（比如，用户击键 CTRL+C），而另一个线程却想用这个信号终止进程，又会发生什么情况？如果有一个或多个线程运行标准的库过程以及其他用户编写的过程，那么情况还会更复杂。很显然，这些想法是不兼容的。一般而言，在单线程环境中信号已经是很难管理的了，到了多线程环境中并不会使这一情况变得容易处理。

由多线程引入的最后一个问题是堆栈的管理。在很多系统中，当一个进程的堆栈溢出时，内核只是自动为该进程提供更多的堆栈。当一个进程有多个线程时，就必须有多个堆栈。如果内核不了解所有的堆栈，就不能使它们自动增长，直到造成堆栈出错。事实上，内核有可能还没有意识到内存错误是和某个线程栈的增长有关系的。

这些问题当然不是不可克服的，但是却说明了给已有的系统引入线程而不进行实质性的重新设计系统是根本不行的。至少可能需要重新定义系统调用的语义，并且不得不重写库。而且所有这些工作必须与在一个进程中有一个线程的原有程序向后兼容。



##### 2.3	进程间通信

进程经常需要与其他进程通信。例如，在一个 shell 管道中，第一个进程的输出必须传送给第二个进程，这样沿着管道传递下去。因此在进程之间需要通信，而且最好使用一种结构良好的方式而不要使用中断。在下面几节中，我们就来讨论一些有关**进程间通信**（Inter Process Communication，IPC）的问题。

简要地说，有三个问题。第一个问题与上面的叙述有关，即一个进程如何把信息传递给另一个。第二个问题是确保两个或多个进程不会互相干扰，例如，在飞机订票系统中的两个进程为不同的客户试图争夺飞机上的最后一个座位。第三个问题与正确的顺序有关（如果该顺序是有关联的话），比如，如果进程 A 产生数据而进程 B 打印数据，那么 B 在打印之前必须等待，直到 A 已经产生一些数据。我们将从下一节开始考察所有这三个问题。

有必要说明，这三个问题中的两个问题对于线程来说同样是适用的。第一个问题（即传递信息）对线程而言比较容易，因为他们共享一个地址空间（在不同地址空间需要通信的线程属于不同进程之间通信的情形）。但是另外两个问题（两个进程需要梳理清楚使其不相互干扰并保持恰当的顺序）同样适用于线程。同样的问题可用同样的方法解决。下面开始讨论进程间通信问题，不过请记住，同样的问题和解决方法也适用于线程。



##### 2.3.1	竞争条件

在一些操作系统中，协作的进程可能共享一些彼此都能读写的公用存储区。这个公用存储区可能在内存中（可能是在内核的数据结构中），也可能是一个共享文件。这里共享存储区的位置并不影响通信的本质及其带来的问题。为了理解实际中进程间通信如何工作，我们考虑一个简单但很普遍的例子：一个假脱机打印程序。当一个进程需要打印一个文件时，它将文件名放在一个特殊的**假脱机目录**（spooler directory）下。下一个进程（**打印机守护进程**）则周期性地检查是否有文件需要打印，若有就打印并将该文件名从目录下删掉。

设想假脱机目录中有许多槽位，编号依次为 0，1，2，…，每个槽位存放一个文件名。同时假设有两个共享变量：out，指向下一个要打印的文件；in，指向目录中下一个空闲槽位。可以把这两个变量保存在一个所有进程都能访问的文件中，该文件的长度为两个字。在某一时刻，0 号至 3 号槽位空（其中的文件已经打印完毕），4 号至 6 号槽位被占用（其中存有排好队列的要打印的文件名）。几乎在同一时刻，进程 A 和进程 B 都决定将一个文件排队打印，这种情况如图 2-21 所示。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE43.jpg"/>
</div>

在 Murphy 法则（任何可能出错的地方终奖出错）失效时，可能发生以下的情况。进程 A 读到 in 的值为 7，将 7 存在一个局部变量 next_free_slot 中。此时发生一次时钟中断，CPU 认为进程 A 已运行了足够长的时间，决定切换到进程 B。进程 B 也读取 in，同样得到值为 7，于是将 7 存在 B 的局部变量 next_free_slot 中。在这一时刻两个进程都认为下一个可用槽位是 7。

进程 B 现在继续运行，它将其文件名存在槽位 7 中并将 in 的值更新为 8。然后它离开，继续执行其他操作。

最后进程 A 接着从上次中断的地方再次运行。它检查变量 next_free_slot，发现其值为 7，于是将打印文件名存入 7 号槽位，这样就把进程 B 存在那里的文件名覆盖掉。然后它将 next_free_slot 加 1，得到值为 8，就将 8 存到 in 中。此时，假脱机目录内部是一致的，所以打印机守护进程发现不了任何错误，但进程 B 却永远得不到任何打印输出。类似这样的情况，即两个或多个进程读写某些共享数据，而最后的结果取决于进程运行的精确时序，称为**竞争条件**（race condition）。调试包含有竞争条件的程序是一件很头痛的事。大多数的测试运行结果都很好，但在极少数情况下会发生一些无法解释的奇怪现象。不幸的是，多核增长带来的并行使得竞争条件越来越普遍。



##### 2.3.2	临界区

怎样避免竞争条件？实际上凡涉及共享内存、共享文件以及共享任何资源的情况都会引发与前面类似的错误，要避免这种错误，关键是要找出某种途径来阻止多个进程同时读写共享的数据。换言之，我们需要的是**互斥**（mutual exclusion），即以某种手段确保当一个进程在使用一个共享变量或文件时，其他进程不能做同样的操作。前述问题的症结就在于，在进程 A 对共享变量的使用未结束之前进程 B 就使用它。为实现互斥而选择适当的原语是任何操作系统的主要设计内容之一，也是后面几节中要详细讨论的主题。

避免竞争条件的问题也可以用一种抽象的方式进行描述。在一部分时间里，一个进程忙于做内部计算或另外一些不会引发竞争条件的操作。然而，在某些时候进程可能需要访问共享内存或共享文件，或执行另外一些会导致竞争的操作。我们把程序中访问共享内存的程序片段称作**临界区域**（critical region）或**临界区**（critical section）。如果我们能够适当地安排，使得两个进程不可能同时处于临界区中，就能够避免竞争条件。

尽管这样的要求避免了竞争条件，但它还不能保证使用共享数据的并发进程能够正确和高效地进行协作。对于一个好的解决方案，需要满足以下 4 个条件：

1) 任何两个进程不能同时处于其临界区。

2) 不应对 CPU 的速度和数量做任何假设。

3) 临界区外运行的进程不得阻塞其他进程。

4) 不得使进程无限期等待进入临界区。

从抽象的角度看，人们所希望的进程行为如图 2-22 所示。图 2-22 中进程 A 在 T~1~ 时刻进入临界区。稍后，在 T~2~ 时刻进程 B 试图进入临界区，但是失败了，因为另一个进程已经在该临界区内，而一个时刻只允许一个进程在临界区内。随后，B 被暂时挂起直到 T~3~ 时刻 A 离开临界区为止，从而允许 B 立即进入。最后，B 离开（在时刻 T~4~），回到了在临界区中没有进程的原始状态。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE44.jpg"/>
</div>





##### 2.3.3	忙等待的互斥

本节将讨论几种互斥的方案。在这些方案中，当一个进程在临界区中更新共享内存时，其他进程将不会进入其临界区，也不会带来任何麻烦。



**1.屏蔽中断**

在单处理器系统中，最简单的方法是使每个进程在刚刚进入临界区后立即屏蔽所有中断，并在就要离开之前再打开中断。屏蔽中断后，时钟中断也被屏蔽。CPU 只有发生时钟中断或其他中断时才会进行进程切换，这样，在屏蔽中断之后 CPU 将不会被切换到其他进程。于是，一旦某个进程屏蔽中断之后，它就可以检查和修改共享内存，而不必担心其他进程介入。

这个方案并不好，因为把屏蔽中断的权利交给用户进程是不明智的。设想一下，若个进程屏蔽中断之后不再打开中断，其结果将会如何？整个系统可能会因此终止。而且，如果系统是多处理器（有两个或更多的处理器），则屏蔽中断仅仅对执行 disable 指令的那个 CPU 有效。其他 CPU 仍将继续运行，并可以访问共享内存。

另一方面，对内核来说，当它在更新变量或列表的几条指令期间将中断屏蔽是很方便的。当就绪进程队列之类的数据状态不一致时发生中断，则可能导致竞争条件。所以结论是：屏蔽中断对于操作系统本身而言是一项很有用的技术，但对于用户进程则不是一种合适的通用互斥机制。

由于多核芯片的数量越来越多，即使在低端 PC 上也是如此。因此，通过屏蔽中断来达到互斥的可能性——甚至在内核中——变得日益减少了。双核现在已经相当普遍，四核当前在高端机器中存在，而且离八或十六（核）也不久远了。在一个多核系统中（例如，多处理器系统），屏蔽一个 CPU 的中断不会阻止其他 CPU 干预第一个 CPU 所做的操作。结果是人们需要更加复杂的计划。



**2.锁变量**

作为第二种尝试，可以寻找一种软件坚决方案。设想有一个共享（锁）变量，其初始值为 0。当一个进程想进入其临界区，它首先测试这把锁。如果该锁的值为 0，则该进程将其设置为 1 并进入临界区。若这把锁的值已经为 1，则该进程将等待直到其值变为 0。于是，0 就表示临界区内没有进程，1 表示已经有某个进程进入临界区。

但是，这种想法也包含了与假脱机目录一样的疏漏。假设一个进程读出锁变量的值并发现它为 0，而恰好在它将其值设置为 1 之前，另一个进程被调度运行，将该锁变量设置为 1。当第一个进程再次运行时，它同样也将该锁设置为 1，则此时同时有两个进程进入临界区中。

可能读者会想，先读出锁变量，紧接着在其改变其值之前再检查一遍它的值，这样便可以解决问题。但这实际上无济于事，如果第二个进程恰好在第一个进程完成第二次检查之后修改了锁变量的值，则同样还会发生竞争条件。



**3.严格轮换法**

第三种互斥的方法如图 2-23 所示。几乎与本书中所有其他程序一样，这里的程序段用 C 语言编写。之所以选择 C 语言是由于实际的操作系统普遍用 C 语言编写（或偶尔用 C++），而基本上不用像 Java、Modula3 或 Pascal 这样的语言。对于编写操作系统而言，C 语言是强大、有效、可预知和有特性的语言。而对于 Java，它就不是可预知的，因为它在关键时刻会用完存储器，而在不合适的时候会调用垃圾收集程序回收内存。在 C 语言中，这种情形就不可能发生，因为 C 语言中不需要进行空间回收。有关 C、C++、Java 和其他四种语言的定量比较可参阅（Prechelt，2000）。

在图 2-23 中，整型变量 turn，初始值为 0，用于记录轮到哪个进程进入临界区，并检查或更新共享内存。开始时，进程 0 检查 turn，发现其值为 0，于是进入临界区。进程 1 也发现其值为 0，所以在一个等待循环中不停地测试 turn，看其值何时变为 1。连续测试一个变量直到某个值出现为止，称为**忙等待**（busy waiting）。由于这种方式浪费 CPU 时间，所以通常应该避免。只有在有理由认为等待时间是非常短的情形下，才使用忙等待。用于忙等待的锁，称为**自旋锁**（spin lock）。







进程 0 离开临界区时，它将 turn 的值设置为 1，以便允许进程 1 进入其临界区。假设进程 1 很快便离开了临界区，则此时两个进程都处于临界区之外，turn 的值又被设置为 0。现在进程 0 很快就执行完其整个循环，它退出临界区，并将 turn 的值设置为 1。此时，turn 的值为 1，两个进程都在其临界区外执行。

突然，进程 0 结束了非临界区的操作并且返回到循环的开始。但是，这时它不能进入临界区，因为 turn 的当前值为 1，而此时进程 1 还在忙于非临界区的操作，进程 0 只有继续 while 循环，直到进程 1 把 turn 的值改为 0。这说明，在一个进程比另一个慢了很多的情况下，轮流进入临界区并不是一个好办法。

这种情况违反了前面叙述的条件 3：进程 0 被一个临界区之外的进程阻塞。再回到前面假脱机目录的问题，如果现在将临界区与读写假脱机目录相联系，则进程 0 有可能因为进程 1 在做其他事情而被禁止打印另一个文件。

实际上，该方案要求两个进程严格地轮流进入它们的临界区，如假脱机文件等。任何一个进程都不可能在一轮中打印两个文件。尽管该算法的确避免了所有的竞争条件，但由于它违反了条件 3，所以不能作为一个很好的备选方案。



**4.Peterson 解法**

荷兰数学家 T. Dekker 通过将锁变量与警告变量的思想相结合，最早提出了一个不需要严格轮换的软件互斥算法。关于 Dekker 的算法，请参阅（Dijkstra，1965）。

1981年，G. L. Peterson 发现了一种简单得多的互斥算法，这使得 Dekker 的方法不再有任何新意。Peterson 的算法如图 2-24 所示。该算法由两个用 ANSI C 编写的过程组成。ANSI C 要求为所定义和使用的所有函数提供函数原型。不过，为了节省篇幅，这里和后续的例子中我们都不会给出函数原型。









在使用共享变量（即进入其临界区）之前，各个进程使用其进程号 0 或 1 作为参数来调用 enter_region。该调用在需要时将使进程等待，直到能安全地进入临界区。在完成对共享变量的操作之后，进程将调用 leave_region，表示操作已完成，若其他的进程希望进入临界区。则现在就可以进入。

现在来看看这个方案是如何工作的。一开始，没有任何进程处于临界区中，现在进程 0 调用 enter_region。它通过设置其数组元素和将 turn 置为 0 来标识它希望进入临界区。由于进程 1 并不想进入临界区，所以 enter_region 很快便返回。如果进程 1 现在调用 enter_region，进程 1 将在此处挂起直到 interested[0] 变成 FALSE，该事件只有在进程 0 调用 leave_region 退出临界区时才会发生。

现在考虑两个进程几乎同时调用 enter_region 的情况。它们都将自己的进程号存入 turn，但只有后被保存进去的进程号才有效，前一个因被重写而丢失。假设进程 1 是后存入的，则 turn 为 1。当两个进程都运行到 while 语句时，进程 0 将循环 0 次并进入临界区，而进程 1 则将不停地循环且不能进入临界区，直到进程 0 退出临界区为止。





**5.TSL 指令**

现在来看需要硬件支持的一种方案。某些计算机中，特别是那些设计为多处理器的计算机，都有下面一条指令：

TSL RX, LOCK

称为**测试并加锁**（test and set lock），它将一个内存字 lock 读到寄存器 RX 中，然后在 lock 的内存地址上存一个非零值。读字和写字操作保证是不可分割的，即该指令结束之前其他处理器均不允许访问该内存字。执行 TSL 指令的 CPU 将锁住内存总线，以禁止其他 CPU 在本指令结束之前访问内存。

着重说明一下，锁住存储总线不同于屏蔽中断。屏蔽中断，然后在读内存字之后跟着写操作并不能阻止总线上的第二个处理器在读操作和写操作之间访问该内存字。事实上，在处理器 1 上屏蔽中断对处理器 2 根本没有任何影响。让处理器 2 原理内存直到处理器 1 完成的唯一方法就是锁住总线，这需要一个特殊的硬件设施（基本上，一根总线就可以确保总线由锁住它的处理器使用，而其他的处理器不能用）。

为了使用 TSL 指令，要使用一个共享变量 lock 来协调对共享内存的访问。当 lock 为 0 时，任何进程都可以使用 TSL 指令将其设置为 1，并读写共享内存。当操作结束时，进程用一条普通的 move 指令将 lock 的值重新设置为 0。

这条指令如何防止两个进程同时进入临界区呢？解决方案如图 2-25 所示。假定（但很典型）存在如下共 4 条指令的汇编语言子程序。第一条指令将 lock 原来的值复制到寄存器中并将 lock 设置为 1，随后这个原来的值与 0 相比较。如果它非零，则说明以前已被加锁，则程序将回到开始并再次测试。经过或长或短的一段时间后，该值将变为 0（当前处于临界区中的进程退出临界区时），于是过程返回，此时已加锁。要清除这个锁非常简单，程序只需将 0 存入 lock 即可，不需要特殊的同步指令。









现在有一种很明确的解法了。进程在进入临界区之前先调用 enter_region，这将导致忙等待，直到锁空闲为止，随后它获得该锁并返回。在进程从临界区返回时它调用 leave_region，这将把 lock 设置为 0。与基于临界区问题的所有解法一样，进程必须在正确的时间调用 enter_region 和 leave_region，解法才能奏效。如果一个进程有欺诈行为，则互斥将会失败。换言之，只有进程合作，临界区才能工作。

一个可替代 TSL 的指令是 XCHG，它原子性地交换了两个位置的内容，例如，一个寄存器与一个存储器字。代码如图 2-26 所示，而且就像可以看到的那样，它本质上与 TSL 的解决办法一样。所有的 Intel x86 CPU 在低层同步中使用 XCHG 指令。







##### 2.3.4	睡眠与唤醒

Peterson 解法和 TSL 或 XCHG 解法都是正确的，但它们都有忙等待的缺点。这些解法在本质上是这样的：当一个进程想进入临界区时，先检查是否允许进入，若不允许，则该进程将原地等待，直到允许为止。

这种方法不仅浪费了 CPU 时间，而且还可能引起预想不到的结果。考虑一台计算机有两个进程，H 优先级较高，L 优先级较低。调度规则规定，只要 H 处于就绪态它就可以运行。在某一时刻，L 处于临界区中，此时 H 变到就绪态，准备运行（例如，一条 I/O 操作结束）。现在 H 开始忙等待，但由于当 H 就绪时 L 不会被调度，也就无法离开临界区，所以 H 将永远忙等待下去。这种情况有时被称作**优先级反转问题**（priority inversion problem）。

现在来考察几条进程间通信原语，它们在无法进入临界区时将阻塞，而不是忙等待。最简单的是 sleep 和 wakeup。sleep 是一个将引起调用进程阻塞的系统调用，即被挂起，直到另外一个进程将其唤醒。wakeup 调用有一个参数，即要被唤醒的进程。另一种方法是让 sleep 和 wakeup 各有一个参数，即有一个用于匹配 sleep 和 wakeup 的内存地址。

**生产者-消费者问题**

作为使用这些原语的一个例子，我们考虑**生产者-消费者**（producer-consumer）问题，也称作**有界缓冲区**（bounded-buffer）问题。两个进程共享一个公共的固定大小的缓冲区。其中一个是生产者，将信息放入缓冲区；另一个是消费者，从缓冲区中取出信息。（也可以把这个问题一般化为 m 个生产者和 n 个消费者问题，但是这里只讨论一个生产者和一个消费者的情况，这样可以简化解决方案。）

问题在于当缓冲区已满，而此时生产者还想向其中放入一个新的数据项的情况。其解决办法是让生产者睡眠，待消费者从缓冲区中取出一个或多个数据项时再唤醒它。同样地，当消费者试图从缓冲区中取数据而发现缓冲区为空时，消费者就睡眠，直到生产者向其中放入一些数据时再将其唤醒。

这个方法听起来很简单，但它包含与前边假脱机目录问题一样的竞争条件。为了跟踪缓冲区中的数据项数，需要一个变量 count。如果缓冲区最多存放 N 个数据项，则生产者代码将首先检查 count 是否达到 N，若是，则生产者睡眠；否则生产者向缓冲区中放入一个数据项并增量 count 的值。

消费者的代码与此类似：首先测试 count 是否为0，若是，则睡眠；否则从中取走一个数据项并递减 count 的值。每个进程同时也检测另一个进程是否应被唤醒，若是则唤醒之。生产者和消费者的代码如图 2-27 所示。







为了在 C 语言中表示 sleep 和 wakeup 这样的系统调用。我们将以库函数调用的形式来表示。尽管它们不是标准 C 库的一部分，但在实际上任何系统中都具有这些库函数。未列出的过程 insert_item 和 remove_item 用来记录将数据项放入缓冲区和从缓冲区取出数据等事项。

现在回到竞争条件的问题。这里有可能会出现竞争条件，其原因是对 count 的访问未加限制。有可能出现以下情况：缓冲区为空，消费者刚刚读取 count 的值发现它为 0。此时调度程序决定暂停消费者并启动运行生产者。生产者向缓冲区中加入一个数据项，count 加 1。现在 count 的值变成了 1。它推断认为由于 count 刚才为 0，所以消费者此时一定在睡眠，于是生产者调用 wakeup 来唤醒消费者。

但是，消费者此时在逻辑上并未睡眠，所以 wakeup 信号丢失。当消费者下次运行时，它将测试先前读到的 count 值，发现它为 0，于是睡眠。生产者迟早会填满整个缓冲区，然后睡眠。这样一来，两个进程都将永远睡眠下去。

问题的实质在于发给一个（尚）未睡眠进程的 wakeup 信号丢失了。如果它没有丢失，则一切都很正常。一种快速的弥补方法是修改规则，加上一个**唤醒等待位**。当一个 wakeup 信号发送给一个清醒的进程信号时，将该位置 1。随后，当该进程要睡眠时，如果唤醒等待位为 1，则将该位清除，而该进程仍然保持清醒。唤醒等待位实际上就是 wakeup 信号的一个小仓库。

尽管在这个简单例子中用唤醒等待位的方法解决了问题，但是我们可以很容易就构造出一些例子，其中有三个或更多的进程，这时一个唤醒等待位就不够使用了。于是我们可以再打一个补丁，加入第二个唤醒等待位，甚至是 8 个、32 个等，但原则上讲，这并没有从根本上解决问题。



##### 2.3.5	信号量

信号量是 E. W. Dijkstra 在 1965 年提出的一种方法，它使用一个整型变量来累计唤醒次数，供以后使用。在他的建议中引入了一个新的变量类型，称作**信号量**（semaphore）。一个信号量的取值可以为 0（表示没有保存下来的唤醒操作）或者为正值（表示有一个或多个唤醒操作）。

Dijkstra 建议设立两种操作：down 和 up（分别为一般化后的 sleep 和 wakeup）。对一信号量执行 down 操作，则是检查其值是否大于 0。若该值大于 0，则将其值减 1（即用掉一个保存的唤醒信号）并继续；若该值为 0，则进程将睡眠，而且此时 down 操作并未结束。检查数值、修改变量值以及可能发生的睡眠操作均作为一个单一的、不可分割的**原子操作**完成。保证一旦一个信号量操作开始，则在该操作完成或阻塞之前，其他进程均不允许访问该信号量。这种原子性对于解决同步问题和避免竞争条件是绝对必要的。**所谓原子操作，是指一组相关联的操作要么都不间断地执行，要么都不执行**。原子操作在计算机科学的其他领域也是非常重要的。

up 操作对信号量的值增 1。如果一个或多个进程在该信号量上睡眠，无法完成一个先前的 down 操作，则由系统选择其中的一个（如随机挑选）并允许该进程完成它的 down 操作。于是，对一个有进程在其上睡眠的信号量执行一次 up 操作之后，该信号量的值仍旧是 0，但在其上睡眠的进程却少了一个。信号量的值增 1 和唤醒一个进程同样也是不可分割的。不会有某个进程因执行 up 而阻塞，正如在前面的模型中不会有进程因执行 wakeup 而阻塞一样。

顺便提一下，在 Dijkstra 原来的论文中，他分别使用名称 P 和 V 而不是 down 和 up，荷兰语中，Proberen 的意思是尝试，Verhogen 的含义是增加或升高。由于对于不讲荷兰语的读者来说采用什么记号并无大的干系，所以，这里将使用 down 和 up 名称。它们在程序设计语言 Algol 68 中首次引入。 



**用信号量解决生产者—消费者问题**

用信号量解决丢失的 wakeup 问题，如图 2-28 所示。为确保信号量能正确工作，最重要的是要采用一种不可分割的方式来实现它。通常是将 up 和 down 作为系统调用实现，而且操作系统只需在执行以下操作时暂时屏蔽全部中断：测试信号量、更新信号量以及在需要时使某个进程睡眠。由于这些动作只需要几条指令，所以屏蔽中断不会带来什么副作用。如果使用多个 CPU，则每个信号量应由一个锁变量进行保护。通过 TSL 或 XCHG 指令来确保同一时刻只有一个 CPU 在对信号量进行操作。

读者必须搞清楚，使用 TSL 或 XCHG 指令来防止几个 CPU 同时访问一个信号量，这与生产者或消费者使用忙等待来等待对方腾出或填充缓冲区是完全不同的。信号量操作仅需几个毫秒，而生产者或消费者可能需要任意长的时间。







该解决方案使用了三个信号量：一个称为 full，用来记录充满的缓冲槽数目；一个称为 empty，记录空的缓冲槽数目；一个称为 mutex，用来确保生产者和消费者不会同时访问缓冲区。full 的初值为 0，empty 的初值为缓冲区中槽的数目，mutex 初值为 1。供两个或多个进程使用的信号量，其初值为 1，保证同时只有一个进程可以进入临界区，称作**二元信号量**（binary semaphore）。如果每个进程在进入临界区前都执行一个 down 操作，并在刚刚退出时执行一个 up 操作，就能够实现互斥。



















