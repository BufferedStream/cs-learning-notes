## 现代操作系统读书笔记

### 第 1 章	引论

现代计算机系统由一个或多个处理器、主存、磁盘、打印机、键盘、鼠标、显示器、网络接口以及各种其它输入/输出设备组成。一般而言，现代计算机系统是一个复杂的系统。如果每位语言程序员都不得不掌握系统的所有细节，那就不可能再编写代码了。而且，管理这些部件并加以优化实验，是一件挑战性极强的工作。所以，计算机安装了一层软件，称为**操作系统**，它的任务是为用户程序提供一个更好、更简单、更清晰的计算机模型，并管理刚才提到的所有设备。本书的主体就是操作系统。

多数读者都会对诸如 Windows、Linux、FreeBSD 或 OS X 等ss's's某个操作系统有些体验，但表面现象是会骗人的。用户与之交互的程序，基于文本的通常称为 **shell**，而基于图标的则称为**图形用户界面**（Graphical User Interface，GUI），它们实际上并不是操作系统的一部分，尽管这些程序使用操作系统来完成工作。

图 1-1 给出了这里所讨论的主要部件的一个简化视图。图的底部是硬件。硬件包括芯片、电路板、磁盘、键盘、显示器以及类似的设备。在硬件的顶部是软件。多数计算机有两种运行模式：内核态和用户态。软件中最基础的部分是操作系统，它运行在**内核态**（也称为**管态**、**核心态**）。在这个模式中，操作系统具有对所有硬件的完全访问权，可以执行机器能够运行的任何指令。软件的其余部分运行在**用户态**下。在用户态下，只使用了机器指令中的一个子集。特别地，那些会影响机器的控制或可进行 **I/O**（输入/输出）操作的指令，在用户态中的程序里是禁止的。在本书中，我们会不断地讨论内核态和用户态之间的差别，这些差别在操作系统的运作中扮演着极其重要的角色。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE1.jpg"/>
</div>

用户接口程序（shell 或者 GUI）处于用户态程序中的最低层次，允许用户运行其他程序，诸如 Web 浏览器、电子邮件阅读器或音乐播放器等。这些程序也大量使用操作系统。

操作系统所在的位置如图 1-1 所示。它运行在裸机之上，为所有其他软件提供基础的运行环境。

操作系统和普通软件（用户态）之间的主要区别是，如果用户不喜欢某个特定的电子邮件阅读器，他可以自由选择另一个，或者自己写一个，但是不能自行写一个属于操作系统一部分的时钟中断处理程序。这个程序由硬件保护，防止用户试图对其进行修改。

然而，有时在嵌入式系统（该系统没有内核态）或解释系统（如基于 Java 的操作系统，它采用解释方式而非硬件方式区分组件）中，上述区别是模糊的。

另外，在许多系统中，一些在用户态下运行的程序协助操作系统完成特权功能。例如，经常有一个程序供用户修改其口令之用。但是这个程序不是操作系统的一部分，也不在内核态下运行，不过它明显地带有敏感的功能，并且必须以某种方式给予保护。在某些系统中，这种想法被推向了极致，一些传统上被认为是操作系统的部分（诸如文件系统）在用户空间中运行。在这类系统中，很难划分出一条明显的界限。在内核态中运行的当然是操作系统的一部分，但是一些在内核外运行的程序也有争议地被认为是操作系统地一部分，或者至少与操作系统密切相关。



#### 1.1	什么是操作系统

很难给出操作系统的准确定义。操作系统是一种运行在内核态的软件——尽管这个说法并不总是符合事实。部分原因是操作系统有两个基本上独立的任务，即为应用程序员（实际上是应用程序）提供一个资源集的清晰抽象，并管理这些硬件资源，而不仅仅是一堆硬件。另外，还取决于从什么角度看待操作系统。读者多半听说过其中一个或另一个的功能。下面我们逐项进行讨论。



##### 1.1.1	作为扩展机器的操作系统

在机器语言一级上，多数计算机的体系结构（指令集、存储组织、I/O 和总线结构）是很原始的，而且编程是很困难的，尤其是对输入/输出操作而言。为了更细致地考察这一点。我们以大多数电脑使用的更现代的 **SATA**（Serial ATA）硬盘为例。曾有一本描述早期版本硬盘接口（程序员为了使用硬盘而需要了解的东西）的书，它的页数超过 450 页。自 2007 年起，接口又被修改过很多次，因而比当时更加复杂。显然，没有任何理智的程序员想要在硬件层面上和硬盘打交道。相反，他们使用一些叫做**硬盘驱动**（disk driver）的软件来和硬件交互。这类软件提供了读写硬盘块的接口，而不用深入细节。操作系统包含很多用于控制输入/输出设备的驱动。

但就算是在这个层面，对于大多数应用来说还是太底层了。因此，所有的操作系统都提供使用硬盘的又一层抽象：文件。使用该抽象，程序能创建、读写文件，而不用处理硬件实际工作中那些恼人的细节。

抽象是管理复杂性的一个关键。好的抽象可以把一个几乎不可能管理的任务划分成为两个可管理的部分。其第一部分是有关抽象的定义和实现，第二部分是随时用这些抽象解决问题。几乎每个计算机用户都理解的一个抽象是文件，正如上文所提到的。文件是一种有效的信息片段，诸如数码照片、保存的电子邮件、歌曲或 Web 页面等。处理数码照片、电子邮件、歌曲以及 Web 页面等，要比处理 SATA（或者其他）硬盘的细节容易，这些磁盘的具体细节与前面叙述过的软盘一样。操作系统的任务是创建好的抽象，并实现和管理它所创建的抽象对象。本书中，我们将研究许多关于抽象的内容，因为这是理解操作系统的关键。

上述观点是非常重要的，所以值得用不同的表达方式来再次叙述。即使怀着如此小心翼翼对设计 Macintosh 机器的工业设计师的尊重，还是不得不说，硬件是丑陋的。真实的处理起、内存条、磁盘和其他装置都是非常复杂的，对于那些为使用某个硬件而不得不编写软件的人们而言，他们使用的是困难、特殊和不一致的接口。有时这是由于需要兼容旧的硬件，有时是为了节省成本，但是，有时硬件设计师们并没有意识到（或在意）他们给软件设计带来了多大的麻烦。操作系统的一个主要任务是隐藏硬件，呈现给程序（以及程序员）良好、清晰、优雅、一致的抽象。如图 1-2 所示，操作系统将丑陋转变为美丽。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE7.jpg"/>
</div>

需要指出的是，操作系统的实际客户是应用程序（当然是通过应用程序员）。它们直接与操作系统及其抽象打交道。相反，最终用户与用户接口所提供的抽象打交道，或者是命令行 shell 或者是图形接口。而用户接口的抽象可以与操作系统提供的抽象类似，但也不总是这样。为了更清晰地说明这一点，请读者考虑普通的 Windows 桌面以及面向行的命令提示符。两者都是运行在 Windows 操作系统上的程序，并使用了 Windows 提供的抽象，但是它们提供了非常不同的用户接口。类似地，运行 Gnome 或者 KDE 的 Linux 用户与直接在 X Window 系统（面向文本）顶部工作的 Linux 用户看到的是非常不同的界面，但是在这两种情形中，操作系统下面的抽象是相同的。

在本书中，我们将具体讨论提供给应用程序的抽象，不过很少涉及用户界面。尽管用户界面是一个巨大和重要的课题，但是它们毕竟只和操作系统的外围相关。



##### 1.1.2	作为资源管理者的操作系统

把操作系统看做向应用程序提供基本抽象的概念，是一种自顶向下的观点。按照另一种自底向上的观点，操作系统则用来管理一个复杂系统的各个部分。现代计算机包含处理器、存储器、时钟、磁盘、鼠标、网络接口、打印机以及许多其他设备。从这个角度看，操作系统的任务是在相互竞争的程序之间有序地控制对处理器、存储器以及其他 I/O 接口设备的分配。

现代操作系统允许同时在内存中运行多道程序。假设在一台计算机上运行的三个程序试图同时在同一台打印机上输出计算结果，那么开始的几行可能是程序 1 的输出，接着几行是程序 2 的输出，然后又是程序 3 的输出等，最终结果将是一团糟。采用将打印结果送到磁盘上缓冲区的方法，操作系统可以把潜在的混乱有序化。在一个程序结束后，操作系统可以将暂存在磁盘上的文件送到打印机输出，同时其他程序可以继续产生更多的输出结果，很明显，这些程序的输出还没有真正送至打印机。

当一个计算机（或网络）有多个用户时，管理和保护存储器、I/O 设备以及其他资源的需求变得强烈起来，因为用户间可能会互相干扰。另外，用户通常不仅共享硬件，还要共享信息（文件、数据库等）。简而言之，操作系统的这种观点认为，操作系统的主要任务是记录哪个程序在使用什么资源，对资源请求进行分配，评估使用代价，并且为不同的程序和用户调解互相冲突的资源请求。

资源管理包括用以下两种不同方式实现**多路复用**（共享）资源：在时间上复用和在空间上复用。当一种资源在时间上复用时，不同的程序或用户轮流使用它。先是第一个获得资源的使用，然后下一个，以此类推。例如，若在系统中只有一个 CPU，而多个程序需要在该 CPU 上运行，操作系统则首先把该 CPU 分配给某个程序，在它运行了足够长的时间之后，另一个程序得到 CPU，然后是下一个，如此进行下去，最终，轮到第一个程序再次运行。至于资源是如何实现时间复用的——谁应该是下一个以及运行多长时间等——则是操作系统的任务。还有一个有关时间复用的例子是打印机的共享。当多个打印作业在一台打印机上排队等待打印时，必须决定将轮到打印的是哪个作业。

另一类复用是空间复用，每个客户都得到资源的一部分，从而取代了客户排队。例如，通常在若干运行程序之间分割内存，这样每一个运行程序都可同时入驻内存（例如，为了轮流使用 CPU）。假设有足够的内存可以存放多个程序，那么在内存中同时存放若干个程序的效率，比把所有内存都分给一个程序的效率要高得多，特别是，如果一个程序只需要整个内存的一小部分，结果更是这样。当然，如此的做法会引起公平、保护等问题，这有赖于操作系统解决它们。有关空间复用的其他资源还有磁盘。在许多系统中，一个磁盘同时为许多用户保存文件。分配磁盘空间并记录谁正在使用哪个磁盘块，是操作系统的典型任务。



#### 1.2	操作系统的历史

**批处理系统**（batch system）。其思想是：在输入室收集全部的作业，然后用一台相对便宜的计算机如 IBM 1401 计算机将它们读到磁带上。IBM 1401 计算机适用于读卡片、复制磁带和输出打印，但不适用于数值运算。另外用较昂贵的计算机如 IBM 7094 来完成真正的计算。这些情况如图 1-3 所示。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE2.jpg"/>
</div>

**多道程序设计**（multiprogramming）。在 7094 机上，若当前作业因等待磁盘或其他 I/O 操作而暂停，CPU 就只能简单地踏步直至该 I/O 完成。对于 CPU 操作密集的科学计算问题，I/O 操作较少，因而浪费的时间很少。然而，对于商业数据处理，I/O 操作等待的时间通常占到 80%~90%，所以必须采取某种措施减少（昂贵的）CPU 空闲时间的浪费。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE3.jpg"/>
</div>

解决方案是将内存分为几个部分，每一部分存放不同的作业，如图 1-5 所示。当一个作业等待 I/O 操作完成时，另一个作业可以使用 CPU。如果内存中可以同时存放足够多的作业，则 CPU 利用率可以接近 100%。在内存中同时驻留多个作业需要特殊的硬件来对其进行保护，以避免作业的信息被窃取或受到攻击。360 及其他第三代计算机都配有此类硬件。



**分时系统（timesharing）**：它实际上是多道程序的一个变体，每个用户都有一个联机终端。在分时系统中，假设有 20 个用户登录，其中 17 个在思考、讨论或喝咖啡，则 CPU 可分派给其他三个需要的作业轮流执行。由于调式程序的用户常常只发出简短的命令（如编译一个五页的源文件），而很少有长的费时命令（比如上百万条的文件排序），所以计算机能够为许多用户提供快速的交互时服务，同时在 CPU 空闲时还可能在后台运行一个大作业。第一个通用的分时系统——**兼容分时系统**（Compatible Time Sharing System，CTSS），是 MIT在一台改装过的 7094 机上开发成功的。但直到第三台计算机广泛采用了必需的保护硬件之后，分时系统才逐渐流行开来。



**POSIX**：IEEE 提出的 UNIX 的标准。posix 定义了一个凡是 UNIX 必须支持的小型系统调用接口。事实上，某些其他操作系统也支持 POSIX 接口。



**x86**：在本书中我们使用 **x86** 则会个术语代表所有使用指令集体系结构家族的现代处理器。



**网络操作系统**和**分布式操作系统**：在网络操作系统中，用户知道多台计算机的存在，能够登录到一台远程机器上并将文件从一台机器复制到另一台机器，每台计算机都运行自己本地的操作系统，并有自己的本地用户（或多个用户）。

网络操作系统与单处理器的操作系统没有本质区别。很明显，它们需要一个网络接口控制器以及一些底层软件来驱动它，同时还需要一些程序来运行远程登录和远程文件访问，但这些附加成分并未改变操作系统的本质。

相反，分布式操作系统是以一种传统单处理器操作系统的形式出现在用户面前的，尽管它实际上是由多处理器组成的。用户应该不知晓自己的程序在何处运行或者自己的文件存放于何处，这些应该由操作系统自动和有效地处理。

真正的分布式操作系统不仅仅是在单机操作系统上增添一小段代码，因为分布式系统与集中式系统有本质的区别。例如，分布式系统通常允许一个应用在多台处理器上同时运行，因此，需要更复杂的处理器调度算法来获得最大的并行度优化。

网络中的通信延迟往往导致分布式赛算法必须能适应信息不完备、信息过时甚至信息不正确的环境。这与单机系统完全不同，对于后者，操作系统掌握着整个系统的完备信息。





#### 1.3	计算机硬件简介

操作系统与运行该操作系统的计算机硬件联系密切。操作系统扩展了计算机指令并管理计算机的资源。为了能够工作，操作系统必须了解大量的硬件，至少需要了解硬件如何面对程序员。处于这个原因，这里我们先简要地介绍现代个人计算机中的计算机硬件，然后开始讨论操作系统的具体工作细节。

从概念上讲，一台简单的个人计算机可以抽象为类似于图 1.6 中的模型。CPU、内存以及 I/O 设备都由一条系统总线连接起来并通过总线与其他设备通信。现代个人计算机结构更加复杂，包含多重总线，我们将在后面讨论。目前，这一模式还是够用的。在下面葛小姐中，我们将简要地介绍这些部件，并且讨论一些操作系统设计师所考虑的硬件问题。毫无疑问，这是一个非常简要的概括介绍。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE4.jpg"/>
</div>





##### 1.3.1	处理器

计算机的 “大脑” 是 CPU，它从内存中取出指令并执行之。在每个 CPU 基本周期中，首先从内存中取出指令，解码以确定其类型和操作数，接着执行之，然后取值、解码并执行下一条指令。按照这一方式，程序被执行完成。

每个 CPU 都有一套可执行的专门指令集。所以，X86 处理器不能执行 ARM 程序，而 ARM 处理器也不能执行 x86 程序。**由于用来访问内存以得到指令或数据的时间要比执行指令花费的时间长得多，因此，所有的 CPU 内都有一些用来保存关键变量和临时数据的寄存器**。这与，通常在指令集中提供一些指令，用以将一个字从内存调入寄存器，以及将一个字从寄存器存入内存。其他得指令可以把来自寄存器、内存的操作数组合，或者用两者产生一个结果，如将两个字相加并把结果存在寄存器或内存中。

除了用来保存变量和临时结果的通用寄存器之外，多数计算机还有一些对程序员可见的专用寄存器，其中之一是**程序计数器**（IP），它保存了将要取出的下一条指令的内存地址。在指令取出之后，程序计数器就被更新以便指向后继的指令。

另一个寄存器是**堆栈指针**（SP），它指向内存中当前栈的顶端。该栈包含了每个执行过程的栈帧。一个过程的栈帧中保存了有关的输入参数、局部变量以及那些没有保存在寄存器中的临时变量。

当然还有**程序状态字**（Program Status Word，PSW）寄存器。这个寄存器包含了条件码位（由比较指令设置）、CPU 优先级、模式（用户态或内核态），以及各种其他控制位。用户程序通常读入整个 PSW，但是，只对其中的少量字段写入。在系统调用和 I/O 中，PSW 的作用很重要。

操作系统必须知晓所有的寄存器。在时间多路复用（time multiplexing）CPU 中，操作系统经常会中止正在运行的某个程序并启动（或再启动）另一个程序。每次停止一个运行着的程序时，操作系统必须保存所有的寄存器值，这样在稍后该程序被再次运行时，可以把这些寄存器重新装入。

为了改善性能，CPU 设计师早就放弃了同时读取、解码和执行一条指令的简单模型。许多现代 CPU 具有同时取出多条指令的机制。例如，一个 CPU 可以有单独的取指单元、解码单元和执行单元，于时当它执行指令 n 时，还可以同时对指令 n+1 解码，并且读取指令 n+2。这与的机制称为**流水线**（pipeline），图 1-7a 是一个有着三个阶段的流水线示意图。更长的流水线也是常见的。在多数的流水线设计中，一旦一条指令被取进流水线中，它就必须被执行完毕，即便前一条取出的指令是条件转移，它也必须被执行完毕。流水线使得编译器和操作系统的编写者很头疼，因为它造成了在机器中实现这些软件的复杂性问题，而机器必须处理这些问题。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE5.jpg"/>
</div>



比流水线更先进的设计是**超标量** CPU，如图 1-7b 所示。在这种设计中，有多个执行单元，例如，一个 CPU 用于整数算术运算，一个 CPU 用于浮点算术运算，一个 CPU 用于布尔运算。两个或更多的指令被同时取出、解码并装入暂存缓冲区中，直至它们执行完毕。只要有一个执行单元空闲，就检查保持缓冲区中是否还有可处理的指令，如果有，就把指令从缓冲区中移出并执行之。这种设计存在一种隐含的作用，即程序的指令经常不按顺序执行。在多数情况下，硬件负责保证这种运算的结果与顺序执行指令时的结果相同，但是，仍然有部分令人烦恼的复杂情形被强加给操作系统处理，我们在后面会讨论这种情况。

除了用在嵌入式系统中的非常简单的 CPU 之外，多数 CPU 都有两种模式，即前面已经提及的内核态和用户态。通常，在 PSW 中有一个二进制位控制这两种模式。当在内核态运行时，CPU 可以执行指令集中的每一条指令，并且使用硬件的每种功能。在台式机和服务器上，操作系统在内核态下运行，从而可以访问整个硬件。而在大多数嵌入式系统中，一部分操作系统运行在内核态，其余的部分则运行在用户态。

相反，用户程序在用户态下运行，仅允许执行整个指令集的一个子集和访问所有功能的一个子集。一般而言，在用户态中有关 I/O 和内存保护的所有指令是禁止的。当然，将 PSW 中的模式位设置成内核态也是禁止的。

为了从操作系统中获得服务，用户程序必须使用**系统调用**（system call）以陷入内核并调用操作系统。TRAP 指令把用户态切换成内核态，并启用操作系统。当有关工作完成之后，在系统调用后面的指令把控制权返回给用户程序。在本章的后面我们将具体解释系统调用过程，但是在这里，请读者把它看成是一个特别的过程调用指令，该指令具有从用户态切换到内核态的特别能力。

有必要指出的是，计算机使用陷阱而不是一条指令来执行系统调用。其他的多数陷阱是由硬件引起的，用于警告有异常情况发生，如试图被零除或浮点下溢等。在所有的情况下，操作系统都得到控制权并决定如何处理异常情况。有时，由于出错的原因，程序不得不停止。在其他情况下可以忽略出错（如下溢数可以被置为零）。最后，若程序已经提前宣布它希望处理某类条件，那么控制权还必须返回给该程序，让其处理相关的问题。



**多线程和多核芯片**

Intel Pentium 4 引入了被称为**多线程**（multithreading）或**超线程**（hyperthreading，这是 Intel 公司的命名）的特性，x86 处理器和其他一些 CPU 芯片就是这样做的，包括 SPARC、Power5、Intel Xeon 和 Intel Core 系列。近似地说，多线程允许 CPU 保持两个不同的线程状态，然后在纳秒级的时间尺度内来回切换。（线程是一种轻量级进程，即一个运行中的程序。我们将在第 2 章中具体讨论。）例如，如果某个进程需要从内存中读出一个字（需要花费多个时钟周期），多线程 CPU 则可以切换至另一个线程。多线程不提供真正的并行处理。在一个时刻只有一个进程在运行，但是线程的切换时间则减少到纳秒数量级。

多线程对操作系统而言是有意义的，因为每个线程在操作系统看来就像是单个的 CPU。考虑一个实际有两个 CPU 的系统，每个 CPU 有两个线程。这样操作系统将把它看成是 4 个 CPU。如果在某个特定时间点上，只有能够维持两个 CPU 忙碌的工作量，那么在同一个 CPU 上调度两个线程，而让另一个 CPU 完全空转，就没有优势了。这种选择远远不如在每个 CPU 上运行一个线程的效率高。



##### 1.3.2	存储器

在任何一种计算机中，第二种主要部件都是存储器。在理想情形下，存储器应该极为迅速（快于执行一条指令，这样 CPU 不会受到存储器的限制），充分大，而且非常便宜。但是目前的计数无法同时满足这三个目标，于是出现了不同的处理凡是。存储器系统采用一种分层次的机构，如图 1-9 所示。顶层的存储器速度较高，容量较小，与底层的存储器相比每位成本较高，其差别往往是十亿数量级。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE6.jpg"/>
</div>



存储器系统的顶层是 CPU 中的寄存器。它们用与 CPU 相同的材料制成，所以和 CPU 一样快。显然，访问它们是没有时延的。其典型的存储容量是，在 32 位 CPU 中为 32×32 位，而在 64 位 CPU 中为 64×64 位。在这两种情形下，其存储容量都小于 1KB。程序必须在软件中自行管理这些寄存器（即决定如何使用它们）。

下一层是高速缓存，它多数由硬件控制。主存被分割成**高速缓存行**（cache line），其典型大小为 64 字节，地址 0 至 63 对应高速缓存行 1，以此类推。最常用的高速缓存行放置在 CPU 内部或者非常接近 CPU 的高速缓存中。当某个程序需要读一个存储字时，高速缓存硬件检查所需要的高速缓存行是否在高速缓存中。如果是，称为**高速缓存命中**，缓存满足了请求，就不需要通过总线把请求送往内存。高速缓存命中通常需要两个时钟周期。高速缓存未命中就必须访问内存，这要付出大量的时间代价。由于高速缓存的价格昂贵，所以其大小有限。有些机器具有两级甚至三级高速缓存，每一级高速缓存比前一级慢且容量更大。

缓存在计算机科学的许多领域中起着重要的作用，并不仅仅是 RAM 的缓存行。只要存在大量的资源可以划分为小的部分，那么，这些资源中的某些部分就会比其他部分更频繁地得到使用，通常缓存的使用会带来性能上的改善。操作系统一直在使用缓存。例如，多数操作系统在内存中共保留频繁使用的文件（的一部分），以避免从磁盘中重复地调取这些文件。相似地，类似于

/home/ast/projects/minix3/src/kernel/clock.c

的长路径名转换成文件所在的磁盘地址的结果，也可以放入缓存，以避免重复寻找地址。还有，当一个 Web 页面（URL）的地址转换为网络地址（IP 地址）后，这个转换结果也可以缓存起来供将来使用。还有许多其他的类似应用。

在任何缓存系统中，都有若干需要尽快考虑的问题，包括：

1. 何时把一个新的内容放入缓存。
2. 把新内容放在缓存的哪一行上。
3. 在需要时，应该把哪个内容从缓存汇总移走。
4. 应该把新移走的内容放在某个较大存储器的何处。

并不是每个问题的解决方案都符合每种缓存处理。对于 CPU 缓存中的主存缓存行，每当有缓存未命中时，就会调入新的内容。通常通过所引用内存地址的高位计算应该使用的缓存行。例如，对于 64 字节的 4096 个缓存行以及 32 位地址，其中 6~17 位用来定位缓存行，而 0~5 位则用来确定缓存行中的字节。在这个例子中，被移走内容的位置就是新数据要进入的位置，但是在有的系统中未必是这样。最后，当将一个缓存行的内容重写进主存时（该内容被缓存后，可能会被修改），通过该地址来唯一确定需重写的主存位置。

在图 1-9 的层次结构中，再往下一层是主存。这是存储器系统的助力。主存通常称为**随机访问存储器（Ra**ndom Access Memory，RAM）。过去有时称之为**磁芯存储器**，因为在 20 世纪 50 年代和 60 年代，使用很小的可磁化的铁磁体制作主存。虽然它们已经绝迹了很多年，但名称还是传承了下来。目前，存储器的容量在几百兆字节到若干吉字节之间，并且其容量正在迅速增长。所有不能在高速缓存中得到满足的访问请求都会转往主存。

除了主存之外，许多计算机已经在使用少量的非易失性随机访问存储器。它们与 RAM 不同，在电源切断之后，非易失性随机访问存储器并不丢失其内容。**只读存储器**（Read Only Memory，ROM）在工厂中就被编程完毕，然后再也不能被修改。ROM 速度快且便宜。在有些计算机中，用于启动计算机的引导加载模块就存放在 ROM 中。另外，一些 I/O 卡也采用 ROM 处理底层设备控制。

**EEPROM**（Electrically Erasable PROM，电可擦除可编程 ROM）和**闪存**（flash memory）也是非易失性的，但是与 ROM 相反，它们可以擦除和重写。不过重写它们需要比写入 RAM 更高数量级的时间，所以它们的使用方式与 ROM 相同，而其与众不同的特点使它们有可能通过字段重写的方式纠正所保存程序中的错误。

在便携式电子设备中共，闪存通常作为存储媒介。闪存是数码相机中的胶卷，是便携式音乐播放器的磁盘，这仅仅是闪存用途中的两项。闪存在速度上介于 RAM 和磁盘之间。另外，与磁盘存储器不同，如果闪存擦除的次数过多，就被磨损了。

还有一类存储器是 CMOS，它是易失性的。许多计算机利用 CMOS 存储器保持当前时间和日期。CMOS 存储器和递增时间的时钟电路由一小块电池驱动，所以，即使计算机没有上电，时间也仍然可以正确地更新。CMOS 存储器还可以保存配置参数，如哪一个是启动磁盘等。之所以采用 CMOS 是因为它消耗的电能非常少。



##### 1.3.3	磁盘

下一个层次是磁盘（硬盘）。磁盘同 RAM 相比，每个二进制位的成本低了两个数量级，而且经常也有两个数量级大的容量。磁盘唯一的问题是随机访问数据时间大约慢了三个数量级。其低速的原因是因为磁盘是一种机械装置，如图 1-10 所示。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE8.jpg"/>
</div>

在一个磁盘中有一个或多个金属盘片，它们以 5400rpm、7200rpm、10800rpm 或更高的速度旋转。从边缘开始有一个机械臂悬横在盘面上，这类似于老式播放塑料唱片 33 转唱机上的拾音臂。信息写在磁盘的一系列同心圆上。在任意一个给定臂的位置，每个磁头可以读取一段环形区域，称为**磁道**（track）。把一个给定臂的位置上的所有磁道合并起来，组成了一个**柱面**（cylinder）。

每个磁道划分为若干扇区，扇区的典型值是 512 字节。在现代磁盘中，较外部的柱面比较内部的柱面有更多的扇区。机械臂从一个柱面移到相邻的柱面大约需要 1ms。而随机移到一个柱面的典型时间为 5ms 至 10ms，其具体时间取决于驱动器。一旦磁臂到达正确的磁道上，驱动器就必须等待所需的扇区旋转到磁头之下，这就增加了 5ms 至 10ms 的时延，其具体延时取决于驱动器的转速。一旦所需要的扇区移到磁头之下，就开始读写，低端磁盘的速率是 50MB/s，而高速磁盘的速率是 160MB/s。

有时，你会听到人们在讨论一些实际上根本不是磁盘的磁盘，比如**固态硬盘**（Solid State Disk，SSD）。固态硬盘并没有可以移动的部分，外形也不像唱片那样，并且数据是存储在存储器（闪存）中的。与磁盘唯一的相似之处就是它也存储了大量即使在电源关闭时也不会丢失的数据。

许多计算机支持一种著名的虚拟内存机制，这将在第 3 章中讨论。这种机制使得期望运行大于物理内存的程序称为可能，其方法是将程序放在磁盘上，而将主存作为一种缓存，用来保存最频繁使用的部分程序。这种机制需要快速地映像内存地址，以便把程序生成的地址转换为有关字节在 RAM 中的物理地址。这种映像由 CPU 中的一个称为**存储器管理单元**（Memory Management Unit，MMU）的部件来完成，如图 1-6 所示。

缓存和 MMU 的出现对系统的性能有着重要的影响。在多道程序系统中，从一个程序切换到另一个程序，有时称为**上下文切换**（context switch），有必要对来自缓存的所有修改过的块进行写回磁盘操作，并修改 MMU 中的映像寄存器。但是这两种操作的代价很昂贵，所以程序员努力避免使用这些操作。我们稍后将看到这些操作产生的影响。



##### 1.3.4	I/O 设备

CPU 和存储器不是操作系统唯一需要管理的资源。I/O 设备也与操作系统有密切的相互影响。如图 1-6 所示，I/O 设备一遍包括两个部分：设备控制器和设备本身。控制器事插在电路板上的一块芯片或一组芯片，这块电路板物理地控制设备。它从操作系统接受命令，例如，从设备读数据，并且完成数据的处理。

在许多情形下，对这些设备的控制事非常复杂和具体的，所以，控制器的任务是为操作系统提供一个简单的接口（不过还是很复杂）。例如，磁盘控制器可以接受一个命令从磁盘 2 读出 11206 号扇区，然后，控制器把这个线性扇区号转化为柱面、扇区和磁头。由于外柱面比内柱面有较多的扇区，而且一些坏扇区已经被映射到磁盘的其他地方，所以这种转换是很复杂的。磁盘控制器必须确定磁头臂应该在哪个柱面上，并对磁头臂发出指令以使其前后移动到所要求的柱面号上，接着必须等待对应的扇区转动到磁头下面并开始读出数据，随着数据从驱动器读出，要消去引导块并计算校验和。最后，还得把输入的二进制位组成字并存放到存储器中。为了完成这些工作，在控制器中经常安装一个小的嵌入式计算机，该嵌入式计算机运行为执行这些工作而专门编好的程序。

I/O 设备的另一个部分是实际设备的自身。设备本身有个相对简单的接口，这是一位内接口既不能做很多工作，又已经被标准化了。例如，标准化后任何一个 SATA 磁盘控制器就可以适配任一种 SATA 磁盘，所以标准化是必要的。**ATA** 代表**高级技术附件**（AT Attachment），而 **SATA** 表示**串行高级技术附件**（Serail ATA）。

现在 SATA 是很多计算机的标准硬盘接口。由于实际的标准接口隐藏在控制器中，所以，操作系统看到的是对控制器的接口，这个接口可能和设备接口有很大的差别。

每类设备控制器都是不同的，所以，需要不同的软件进行控制。专门与控制器对话，发出命令并接受响应的软件，称为**设备驱动程序**（device driver）。每个控制器厂家必须为所支持的操作系统提供相应的设备驱动程序。

为了能够使用设备驱动程序，必须把设备驱动程序装入操作系统中，这样它可在核心态运行。设备驱动程序可以在内核外运行，现代的 Linux 和 Windows 操作系统也的确对这种方式提供一些支持。绝大多数驱动程序仍然需要在内核态运行。只有很少一部分现代系统（如 MINIX 3）在用户态运行全部驱动程序。在用户态运行的驱动程序必须能够以某种受控的方式访问折别，然而这并不容易。

要将设备驱动程序装入操作系统，有三个途径。第一个途径是将内核与设备驱动程序重新链接，然后重启系统。许多 UNIX 系统以这种方式工作。第二个途径是在一个操作系统文件中设置一个入口，并通知该文件需要一个设备驱动程序，然后重启系统。在系统启动时，操作系统去找寻所需的设备驱动程序并装载之。Windows 就是以这种方式工作。第三种途径是，操作系统能够在运行时接受新的设备驱动程序并且立即将其安装好，无须重启系统。这种方式采用得较少，但是正在变得普及起来。热插拔设备，诸如 USB 和 IEEE 1394 设备都需要动态可装载设备驱动程序。

每个设备控制器都有少量用于通信的寄存器。例如，一个最小的磁盘控制器也会有用于指定磁盘地址、内存地址、扇区计数和方向（读或写）的寄存器。要激活控制器，设备驱动程序从操作系统获得一条命令，然后翻译成对应的值，并写进设备寄存器中。所有设备寄存器的集合构成了 **I/O 端口空间**，我们将在第 5 章讨论有关内容。

在有些计算机中，设备寄存器被映射到操作系统的地址空间（操作系统可使用的地址）。这样，它们就可以像普通存储字一样读出和写入。在这种计算机中，不需要专门的 I/O 指令，用户程序可以被硬件阻挡在外，防止其接触这些存储器地址（例如，采用基址和界限寄存器）。在另外一些计算机中，设备寄存器被放入一个专门的 I/O 端口空间中，每个寄存器都有一个端口地址。在这些机器中，提供在内核态中可使用的专门 IN 和 OUT 指令，供设备驱动程序读写这些寄存器用。前一种方式不需要专门的 I/O 指令，但是占用了一些地址空间。后者不占用地址空间，但是需要专门的指令。这两种方式的应用都很广泛。

实现输入和输出的方式有三种。在最简单的方式中，用户程序发出一个系统调用，内核将其翻译成一个对应设备驱动程序的过程调用。然后设备驱动程序启动 I/O 并在一个连续不断的循环中检查该设备，看该设备是否完成了工作（一般有一些二进制位用来指示设备仍在忙碌中）。当 I/O 结束后，设备驱动程序把数据送到指定的地方（若有此需要），并返回。然后操作系统将控制返回给调用者。这种方式称为**忙等待**（busy waiting），其缺点是要占据 CPU，CPU 一直轮询设备直到对应的 I/O 操作完成。

第二种方式是设备驱动程序启动设备并且让该设备在操作完成时发出一个中断。设备驱动程序在这个时刻返回。操作系统接着在需要时阻塞调用者并安排其他工作进行。当设备驱动程序监测到该设备的操作完毕时，它发出一个**中断**通知操作完成。

在操作系统中，中断是非常重要的，所以需要更具体地讨论。在图 1-11a 中，有一个 I/O 的三部三步过程。在第 1 步，设备驱动程序通过写设备寄存器通知设备控制器做什么。然后，设备控制器启动该设备。当设备控制器传送完毕被告知要进行读写的字节数量后，它在第 2 步中使用特定的总线发信号给中断控制器芯片。如果中断控制器已经准备接收中断（如果正忙于一个更高级的中断，也可能不接收），它会在 CPU 芯片的一个管脚上声明，这就是第 3 步。在第 4 步中，中断控制器把该设备的编号放到总线上，这样 CPU 可以读总线，并且知道哪个设备刚刚完成了操作（可能同时有许多设备在运行）。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE9.jpg"/>
</div>

一旦 CPU 决定取中断，通常程序计数器和 PSW 就被压入当前堆栈中，并且 CPU 被切换到用户态。设备编号可以成为部分内存的一个引用，用于寻找该设备中断处理程序的地址。这部分内存被称为**中断向量**（interrupt vector）。当中断处理程序（中断设备的设备驱动程序的一部分）开始后，它取走已入栈的程序计数器和 PSW，并保存之，然后查询设备的状态。在中断处理程序全部完成之后，它返回到先前运行的用户程序中尚未执行的头一条指令。这些步骤如图 1-11b 所示。

第三种方式是，为 I/O 使用一种特殊的**直接存储器访问**（Direct Memory Access，DMA）芯片，它可以控制在内存和某些控制器之间的位流，而无须持续的 CPU 干预。CPU 对 DMA 芯片进行设置，说明需要传送的字节数、有关的设备和内存地址以及操作方向，接着启动 DMA。当 DMA 芯片完成时，它引发一个中断，其处理方式如前所述。有关 DMA 和 I/O 硬件会在第 5 章中具体讨论。

中断会（并且经常会）在非常不合适的时刻发生，比如，在另一个中断程序正在运行时发生。正由于此，CPU 有办法关闭中断并在稍后再开启中断。在中断关闭时，任何已经发出中断的设备，可以继续保持其中断信号，但是 CPU 不会被中断，直至中断再次启用为止。如果在关闭中断时，已有多个设备发出了中断，中断控制器将决定先处理哪个中断，通常这取决于事先赋予每个设备的静态优先级。最高优先级的设备赢得竞争并且首先获得服务，其他设备则必须等待。



##### 1.3.5	总线

略



##### 1.3.6	启动计算机

简要启动过程如下。在每台计算机上有一块双亲板（在政治因素影响到计算机充业之前，它们曾称为 “母板”）。在双亲板上有一个称为**基本输入输出系统**（Basic Input Output System，BIOS）的程序。在 BIOS 内有底层 I/O 软件，包括读键盘、写屏幕、进行磁盘 I/O 以及其他过程。现在这个程序存放在一块闪速 RAM 中，它是非易失性的，但是在发现 BIOS 中有错时可以通过操作系统对它进行更新。

在计算机启动时，BIOS 开始运行。它首先检查所安装的 RAM 数量，键盘和其他设备是否已安装并正常响应。接着，它开始扫描 PCIe 和 PCI 总线并找出连在上面的所有设备。即插即用设备也被记录下来。如果现有的设备和系统上一次启动时的设备不同，则新的设备将被配置。

然后，BIOS 通过尝试存储在 CMOS 存储器中的设备清单决定启动设备。用户可以在系统刚启动之后进入一个 BIOS 配置程序，对设备清单进行修改。典型地，如果存在 CD-ROM（有时是 USB），则系统试图从中启动；如果失败，系统将从硬盘启动。启动设备上的第一个扇区被读入内存并执行。这个扇区包含一个对保存在启动扇区末尾的分区表检查的程序，以确定哪个分区是活动的。然后，从该分区读入第二个启动装载模块。来自活动分区的这个装载模块被读入操作系统，并启动之。

然后，操作系统询问 BIOS，以获得配置信息。对于每种设备，系统检查对应的设备驱动程序是否存在。如果没有，系统要求用户插入含有该设备驱动程序的 CD-ROM（由设备供应商提供）或者从网络上下载驱动程序。一旦有了全部的设备驱动程序，操作系统就将它们调入内核。然后初始化有关表格，创建需要的任何背景进程，并在每个终端上启动登录程序或 GUI。



#### 1.4	操作系统大观园

略



#### 1.5	操作系统该概念

多数操作系统都使用某些基本概念和抽象，如进程、地址空间以及文件等，它们是需要理解的核心内容。作为引论，在下面的几节中，我们将较为简单地考察这些基本概念中的一部分。在本书的后面，我们将详细地讨论它们。为了说明这些概念，我们有时使用示例，这些示例通常源自 UNIX。不过，类似的例子在其他操作系统中也明显地存在，我们将在之后深入了解其中的一些操作系统。



##### 1.5.1	进程

在所有操作系统中，一个重要的概念是**进程**（process）。进程本质上是正在执行的一个程序。与每个进程相关的是**地址空间**（address space），这是从某个最小值的存储位置（通常是零）到某个最大值的存储位置的列表。在这个地址空间中，进程可以进行读写。该地址空间中存放有可执行程序、程序的数据以及程序的堆栈。与每个进程相关的还有资源集，通常包括寄存器（含有程序计数器和堆栈指针）、打开文件的清单、突出的报警、有关进程清单，以及运行该程序所需要的所有其他信息。进程基本上是容纳运行一个程序所需要所有信息的容器。

进程的概念将在第 2 章详细讨论，不过，对进程建立一种直观感受的最便利方式是分析一个多道程序设计系统。用户启动一个视频编辑程序，指示它按照某个格式转换一小时的视频（有时会花费数小时），然后离开去浏览网页。同时，一个被周期性唤醒、用来检查进来的电子邮件的后台进程会开始运行。这样，我们就有了（至少）三个活动进程：视频编辑器、Web 浏览器以及电子邮件接收程序。操作系统周期性地挂起一个进程然后启动运行另一个进程，这可能是由于在过去的一两秒钟内，第一个进程已使用完分配给它的时间片。

一个进程暂时被挂起后，在随后的某个时刻里，该进程再次启动时的状态必须与先前暂停时完全相同，这就意味着在挂起时该进程的所有信息都要保存下来。例如，为了同时读入信息，进程打开了若干文件。与每个被打开文件有关的是指向当前位置的指针（即下一个将读出的字节或记录）。在一个进程暂时被挂起时，所有这些指针都必须保存起来，这样在该进程重新启动之后，所执行的读调用才能读到正确的数据。在许多操作系统中，与一个进程有关的所有信息，除了该进程自身地址空间的内容以外，均存放在操作系统的一张表中，称为**进程表**（process table），进程表是数组（或链表）结构，当前存在的每个进程都要占用其中一项。

所以，一个（挂起的）进程包括：进程的地址空间（往往称为**磁芯映像**，core image，纪念过去使用的磁芯存储器），以及对应的进程表项（其中包括寄存器以及稍后重启该进程所需要的许多其他信息）。

与进程管理有关的最关键的系统调用是那些进程创建和进程终止的系统调用。考虑一个典型的例子。有一个称为**命令解释器**（command interpreter）或 **shell** 的进程从终端中读命令。此时，用户刚键入一条命令要求编译一个程序。shell 必须先创建一个新进程来执行编译程序。当执行编译的进程结束时，它执行一个系统调用来终止自己。

若一个进程能够创建一个或多个进程（称为**子进程**），而且这些进程又可以创建子进程，则很容易得到进程树，如图 1-13 所示。合作完成某些作业的相关进程经常需要彼此通信以便同步它们的行为。这种通信称为**进程间通信**（interprocess communication），将在第 2 章中详细讨论。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE10.jpg"/>
</div>

其他可用的进程系统调用包括：申请更多的内容（或释放不再需要的内存）、等待一个子进程结束、用另一个程序覆盖该程序等。

有时，需要向一个正在运行的进程传送信息，而该进程并没有等待接收信息。例如，一个进程通过网络向另一台机器上的进程发送消息进行通信。为了保证一条消息或消息的应答不会丢失，发送者要求它所在的操作系统在指定的若干秒后给一个通知，这样如果对方尚未收到确认消息就可以进行重发。在设定该定时器后，程序可以继续做其他工作。

在限定的秒数流逝之后，操作系统向该进程发送一个**警告信号**（alarm signal）。此信号引起该进程暂时挂起，无论该进程正在做什么，系统将其寄存器的值保存到堆栈，并开始运行一个特别的信号处理过程，比如重新发送可能丢失的消息。这些信号是软件模拟的硬件中断，除了定时器到期之外，该信号可以由各种原因产生。许多由硬件检测出来的陷阱，如执行了非法指令或使用了无效地址等，也被转换成该信号并交给这个进程。

系统管理器授权每个进程使用一个给定的 **UID**（User IDentification）。每个被启动的进程都由一个启动该进程的用户 UID。子进程拥有与父进程一样的 UID。用户可以是某个组的成员，每个组也有一个 **GID**（Group IDentification）。

在 UNIX 中，有一个 UID 称为**超级用户**（superuser），或者 Windows 中的**管理员**（administrator），它具有特殊的权力，可以违背一些保护规则。在大型系统中，只有系统管理员掌握着成为超级用户的密码，但是许多普通用户（特别是学生）做出了可观的努力，试图找出系统的缺陷，从而使他们不用密码就可以成为超级用户。 

在第 2 章中，我们将讨论进程以及进程间通信的相关内容。



##### 1.5.2	地址空间

每台计算机都有一些主存，用来保存正在执行的程序。在非常简单的操作系统中，内存中一次只能有一个程序。如果要运行第二个程序，第一个程序就必须被移出内存，再把第二个程序装入内存。

较复杂的操作系统允许在内存中同时允许多道程序。为了避免它们互相干扰（包括操作系统），需要有某种保护机制。虽然这钟机制必须是以硬件形式的，但是由操作系统掌控。

上述的观点涉及对计算机主存的管理和保护。另一种不同但是同样重要并与存储器有关的内容，是管理进程的地址空间。通常，每个进程可以有一些可以使用的地址集合，典型值从 0 开始直到某个最大值。在最简单的情形下，一个进程可拥有的最大地址空间小于主存。在这种方式下，进程可以用满其地址空间，而且内存中也有足够的空间容纳该进程。

但是，在许多 32 位或 64 位地址的计算机中，分别有 2^32^ 或 2^64^ 字节的地址空间。若果一个进程有比计算机拥有的主存还大的地址空间，而且该进程希望使用全部的内存，那怎么办呢？在早期的计算机中，这个进程只好 “认命” 了。现在，有了一种称为虚拟内存的计数，正如前面已经介绍过的，操作系统可以把部分地址空间装入主存，部分留在磁盘上，并且在需要时来回交换它们。在本质上，操作系统创建了一个地址空间的抽象，作为进程可以引用地址的集合。该地址空间与机器的物理内存解耦，可能大于也可能小于该物理空间。对地址空间和物理空间的管理组成了操作系统功能的一个重要部分，整个第 3 章都与这个主题有关。



##### 1.5.3	文件

实际上，支持操作系统的另一个关键概念是文件系统。如前所述，操作系统的一项主要功能是隐藏磁盘和其他 I/O 设备的细节特性，提供给程序员一个良好、清晰的独立于设备的抽象文件模型。显然，创建文件、删除文件、读文件和写文件等都需要系统调用。在文件可以读取之前，必须先在磁盘上定位和打开文件，在文件读过之后应该关闭该文件，有关的系统调用则用于完成这类操作。

为了提供保存文件的地方，大多数操作系统支持**目录**（directory）的概念，从而可以把文件分类成组。比如，学生可给所选的每个课程创建一个目录（用于保存该课程所需的程序），另设一个目录存放电子邮件，再有一个目录用于保存万维网主页。这就需要系统调用创建和删除目录、将已有的文件放入目录中、从目录中删除文件等。目录项可以是文件或者目录，这样就产生了层次结构——文件系统，如图 1-14 所示。

进程和文件层次都可以组成树状结构，但这两种树状结构有不少不同之处。一般进程的树状结构层次不深（很少超过三层），而文件树树状结构的层次常常多达四层、五层或更多层。进程树层次结构是暂时的，通常最多存在几分钟，而目录层次则可能存在数年之久。进程和文件在所有权及保护方面也是有区别的。典型地，只有父进程能够控制和访问子进程，而在文件和目录中通常存在一种机制，使文件所有者之外的其他用户也可以访问该文件。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE11.jpg"/>
</div>

目录层结构中的每一个文件都可以通过从目录的顶部即**根目录**（root directory）开始的**路径名**（path name）来确定。绝对路径名包含了从根目录到该文件的所有目录清单，它们之间用正斜线 / 隔开。最开始的正斜线表示这是从根目录开始的绝对路径。由于历史原因，在 Windows 中用反斜线 \ 作为分隔符。在本书中，我们一般使用 UNIX 的路径惯例。

在实例中，每个进程有一个**工作目录**（working directory），对于没有以斜线开头给出绝对路径的路径，将在这个工作目录下寻找。进程可以通过使用系统调用指定新的工作目录，从而变更其工作目录。

在读写文件之前，首先要打开文件，检查其访问权限。若权限许可，系统将返回一个小整数，称为**文件描述符**（file descriptor），供后续操作使用。若禁止访问，系统则返回一个错误码。

UNIX 的一个重要概念是安装文件系统。大多数台式机都由一个或多个光盘驱动器，可以插入 CD-ROM、DVD 和蓝色光盘。它们几乎都有 USB 接口，可以插入 USB 存储棒（实际上是固态磁盘驱动器）。为了提供一个出色的方式处理可移动介质，UNIX 允许把光盘上的文件系统接到主文件树上。考虑图 1-15a 的情形。在 mount 调用之前，根文件系统在硬盘上，而第二个文件系统在 CD-ROM 上，它们是分离且无关的。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE12.jpg"/>
</div>

然而，不能使用 CD-ROM 上的文件系统，因为上面没有可指定的路径。UNIX 不允许在路径前面加上驱动器名称或代码，那样做就完全成了设备相关类型了，这是操作系统应该消除的。代替的方法是，mount 系统调用允许把在 CD-ROM 上的文件系统连接到程序所希望的**根文件系统**上。在图 1-15b 中，CS-ROM 上的文件系统安装到了目录 b 上，这样就允许访问文件 /b/x 以及 /b/y。如果 CD-ROM 已安装好，但目录 b 中有任何不能访问的文件，则是因为 /b 指向了 CS-ROM 的根目录。（在开始时，不能访问这些文件似乎并不是一个严重问题；文件系统几乎总是安装在空目录上。）如果系统有多个硬盘，它们可以都安装在单个树上。

在 UNIX 中，另一个重要的概念是**特殊文件**（special file）。提供特殊文件是为了使 I/O 设备看起来像文件一般。这样，就像使用系统调用读写文件一样，I/O 设备也可通过同样的系统调用进行读写。有两类特殊文件：**块特殊文件**（block special file）和**字符特殊文件**（character special file）。块特殊文件指那些由可随机存区的块组成的设备，如磁盘等。比如打开一个块特殊文件，然后读第 4 块，程序可以直接访问设备的第 4 块而不必考虑存放该文件的文件系统结构。类似地，字符特殊文件用于打印机、调制解调器和其他接收或输出字符流的设备。按照管理，特殊文件保存在 /dev 目录中。例如，/dev/lp 是打印机（曾经称为行式打印机）。

本小节中讨论的最后一个特性既与进程有关也与文件有关：管道。**管道**（pipe）是一种虚文件，它可连接两个基础你好，如图 1-16 所示。如果进程 A 和 B 希望通过管道通话，它们必须提前设置该管道。当进程 A 想对进程 B 发送数据时，它把数据写到管道上，仿佛管道就是输出文件一样。进程 B 可以通过读该管道而得到数据，仿佛该管道就是一个输入文件一样。这样，在 UNIX 中两个进程之间的通信就非常类似于普通文件的读写了。更为强大的是，若进程想发现它所写入的输出文件并不是真正的文件而是管道，则需要使用特殊的系统调用。文件系统是非常重要的。我们将在第 4、10、11 章中具体讨论它们。



##### 1.5.4	输入/输出

所有的计算机都有用来获取输入和产生输出的物理设备。毕竟，如果用户不能告诉计算机该做什么，而在计算机完成了所要求的工作之后竟不能得到结果，那么计算机还有什么用处呢？有各种类型的输入和输出设备，包括键盘、显示器、打印机等。对这些设备的管理全然依靠操作系统。

所以，每个操作系统都有管理器 I/O 设备的 I/O 子系统。某些 I/O 软件是设备独立的，即这些 I/O 软件部分可以同样应用于许多或者全部的 I/O 设备上。I/O 软件的其他部分，如设备驱动程序，是专门为特定的 I/O 设备设计的。在第 5 章中，我们将讨论 I/O 软件。



##### 1.5.5	保护

计算机中有大量的信息，用户经常希望对其进行保护，并保守秘密。这些信息包括电子邮件、商业计划、退税等诸多内容。管理系统的安全性完全依靠操作系统，例如，文件仅供授权用户访问。

作为一个简单的例子，以便读者对如何实现安全有一个概念，请考察 UNIX。UNIX 操作系统通过对每个文件赋予一个 9 位的二进制保护代码，对 UNIX 中的文件实现保护。该保护代码有三个 3 位字段，一个用于所有者，一个用户与所有者同组（用户被系统管理原划分成组）的其他成员，一个用于其他人。每个字段中有一位用于读访问，一位用于写访问，一位用于执行访问。这些位就是知名的 **rwx位**。对一个文件而言，x 的含义是允许执行该文件。对一个目录而言，x 的含义是允许查询。一条短横线的含义是，不存在对应的许可。

除了文件保护之外，还有很多有关安全的问题。保护系统不被人类或非人类（如病毒）入侵，则是其中之一。我们将在第 9 章中研究各种安全性问题。



##### 1.5.6	shell

操作系统是进行系统调用的代码。编辑器、编译器、汇编程序、链接程序、效用程序以及命令解释器等，尽管非常重要，也非常有用，但是它们确实不是操作系统的组成部分。为了避免可能发生的混淆，本小节将大致介绍一下 UNIX 的命令解释器，称为 shell。尽管 shell 本身不是操作系统的一部分，但它体现了许多操作系统的特性，并很好地说明了系统调用的具体用法。shell 同时也是终端用户与操作系统之间的接口，除非用户使用的是图形用户界面。有许多种 shell，如 sh、csh、ksh 以及 bash 等。它们全部支持下面所介绍的功能，这些功能可追溯到早期的 shell（即 sh）。

用户登录时，同时启动了一个 shell。它终端作为标准输入和标准输出。首先显示**提示符**（prompt），它可能是一个美元符号，提示用户 shell 正在等待接收命令。加入用户键入

data

shell 创建一个子进程，并运行 date 程序作为子进程。在该子进程运行期间，shell 等待它结束。在子进程结束后，shell 再次显示提示符，并等待下一行输入。

用户可以将标准输出重定向到一个文件，如键入

date > file

同样，也可以将标准输入重定向，如：

sort < file1 > file2

该命令调用 sort 程序，从 file1 中取得输入，输出送到 file2.

可以将一个程序的输出通过管道作为另一程序的输入，因此有

cat file1 file2 file3 | sort > /dev/lp

所调用的 cat 程序将这三个文件合并，其结果送到 sort 程序并按字典序排序。sort 的输出又被重定向到文件 /dev/lp 中，显然，这是打印机。

如果用户在命令后加上一个 "&" 符号，则 shell 将不等待其结束，而直接显示出提示符。所以

cat file1 file2 file3 | sort > /dev/lp &

将启动 sort 程序作为后台任务执行，这样就运行用户继续工作，而 sort 命令页继续进行。shell 还有许多其他有用的特性，由于篇幅有限而不能在这里讨论。

现在，许多个人计算机使用 GUI。事实上，GUI 与 shell 类似，GUI 只是一个运行在操作系统顶部的程序。在 Linux 系统中，这个事实更加明显，因为用户（至少）可以在两个 GUI 中选择要给：Gnome 和 KDE，或者干脆不用。



##### 1.5.7	个体重复系统发育

略





#### 1.6	系统调用

我们已经看到操作系统具有两种功能：**为用户程序提供抽象和管理计算机资源**。在多数情形下。用户程序和操作系统之间的交互处理的是前者，例如，创建、写入、读出和删除文件。对用户而言，资源管理部分主要是透明和自动完成的。这样，用户程序和操作系统之间的交互主要就是处理抽象。为了真正理解操作系统的行为，我们必须仔细地分析这个接口。接口中所提供的调用随着操作系统的不同而变化（尽管基于的概念是类似的）。

这样我们不得不在如下的可能方式中进行选择：（1）含混不清的一般性描述（“操作系统提供读取文件的系统调用”）；（2）某个特定的系统（“UNIX 提供一个有三个参数的 read 系统调用：一个参数指定文件，一个说明数据应存放的位置，另一个说明应读出多少字节”）。

我们选择后一种方式。这种方式需要更多的努力，但是它能更多地洞察操作系统具体在做什么。尽管这样的讨论会涉及专门的 POSIX，以及 UNIX、System V、BSD、Linux、MINIX 3 等，但是多数现代操作系统都有实现相同功能的系统调用，尽管它们在细节上差别很大。由于引发系统调用的实际机制是非常依赖于机器的，而且必须用汇编代码表达，所以，通过提供过程库使 C 程序中能够使用系统调用，当然也包括其他语言。

记住下列事项是有益的。任何单 CPU 计算机一次只能执行一条指令。如果一个进程正在用户态进行一个用户程序，并且需要一个系统服务，比如从一个文件读数据，那么它就必须执行一个陷阱或系统调用指令，将控制转移到操作系统。操作系统接着通过参数检查找出所需要的调用进程。然后，它执行系统调用，并把控制返回给出在系统调用后面跟随着的指令。在某种意义上，进行系统调用就像进行一个特殊的过程调用，但是只有系统调用可以进入内核，而过程调用则不能。

为了使系统调用机制更清晰，我们简要地考察 read 系统调用。如上所述，它有三个参数：第一个参数指定文件，第二个指向缓冲区，第三个说明要读出的字节数。几乎与所有的系统调用一样，它的调用由 C 程序完成，方法是调用一个与该系统调用名称相同的库过程：read。由 C 程序进行的调用形式如下：

count = read(fd, buffer, nbytes);

系统调用（以及库过程）在 count 中返回实际读出的字节数。这个值通常和 nbytes 相同，但也可能更小，例如，如果在读过程中遇到了文件尾的情形就是如此。

如果系统调用不能执行，不论是因为无效的参数还是磁盘错误，count 都会被设置为 -1，而在全局变量 errno 中放入错误号。程序应该经常检查系统调用的结果，以了解是否出错。

系统调用是通过一系列的步骤实现的。为了更清楚地说明这个概念，考察上面的 read 调用。在准备调用这个实际用来进行 read 系统调用的 read 库过程时，调用程序首先把参数压进堆栈，如图 1-17 中步骤 1~步骤 3 所示。 

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE13.jpg"/>
</div>

由于历史的原因，C 以及 C++ 编译器使用逆序（必须把第一个参数赋给 printf（格式字符串），放在堆栈的顶部）。第一个和第三个参数是值调用，但是第二个参数通过引用传递，即传递的是缓冲区的地址（由 & 指示），而不是缓冲区的内容。接着是对库过程的实际调用（第 4 步）。这个指令是用来调用所有过程的正常过程调用指令。

在可能是由汇编语言写成的库过程中，一般把系统调用的编号放在操作系统所期望的地方，如寄存器中（第 5 步）。然后执行一个 TRAP 指令，将用户态切换到内核态，并在内核中的一个固定地址开始执行（第 6 步）。TRAP 指令实际上与过程调用指令非常类似，它们后面都跟随一个来自远处位置的指令，以及供以后使用的一个保存在栈中的返回地址。

然而，TRAP 指令与过程指令存在两个方面的差别。首先，它的副作用是，切换到内核态。而过程调用指令并不改变模式。其次，不像给定过程所在的相对或绝对地址那样，TRAP 指令不能跳转到任意地址上。根据机器的体系结构，或者跳转到一个单固定地址上，或者指令中有一 8 位长的字段，它给定了内存中一张表格的索引，这张表格中含有跳转地址。

跟随在 TRAP 指令后的内核代码开始检查系统调用编号，然后分派给正确的系统调用处理器，这通常是通过一张由系统调用编号所引用的、指向系统调用处理器的指针表来完成（第 7 步）。此时，系统调用处理器运行（第 9 步）。这个过程接着以通常的过程调用返回的方式，返回到用户程序（第 10 步）。

为了完成整个工作，用户程序还必须清除堆栈，如同它在进行任何过程调用之后一样（第 11 步）。假设堆栈向下增长，如经常所做的那样，编译后的代码准确地增加堆栈针值，以便清除调用 read 之前压入的参数。在这之后，原来的程序就可以随意执行了。

在前面第 9 节中，我们提到 “控制可能会在跟随 TRAP 指令后面的指令中返回给用户空间库过程”，这是有原因的。系统调用可能阻塞调用者，避免它继续执行。例如，如果试图读键盘，但是并没有任何键入，那么调用者就必须被阻塞。在这种情形下，操作系统会查看是否有其他可以运行的进程。稍后，当需要的收入出现时，进程会提醒系统注意，然后步骤 9~步骤 11会接着进行。

下面几小节中，我们将考察一些常用的 POSIX 系统调用，或者用更专业的说法，考察进行这些系统调用的库过程。POSIX 大约有 100 个过程调用，它们中最重要的过程调用列在图 1-18 中。为方便起见，它们被分成 4 类。我们用文字简要地叙述其作用。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE14.jpg"/>
</div>

从广义上看，由这些调用所提供的服务确定了多数操作系统应该具有的功能，而在个人计算机上，资源管理功能是较弱的（至少与多用户的大型机相比较是这样）。所包含的服务有创建与终止进程，创建、删除、读出和写入文件，目录管理以及完成输入/输出。

有必要指出，将 POSIX 过程映射到系统调用并不是一对一的。POSIX 标准定义了构造系统所必须提供的一套过程，但是并没有规定它们是系统调用、库调用还是其他的形式。如果不通过系统调用就可以执行一个过程（即无须陷入内核），那么从性能方面考虑，它通常会在用户空间中完成。不过，多数 POSIX 过程确实进行系统调用，通常是一个过程直接映射到一个系统调用上。在一些情形下，特别是所需要的过程仅仅是某个调用的变体时，一个系统调用会对应若干个库调用。



##### 1.6.1	用于进程管理的系统调用

图 1-18 中的第一组调用用于进程管理。将有关 fork（派生）的讨论作为本节的开始是较为合适的。在 UNIX 中，fork 是唯一可以在 POSIX 中创建进程的途径。它创建一个原有进程的精确副本，包括所有的文件描述符、寄存器等内容。在 fork 之后，原有的进程及其副本（父与子）就分开了。在 fork 时，所有的变量具有一样的值，虽然父进程的数据被复制用以创建子进程，但是其中一个的后续变化并不会影响到另一个。（由父进程和子进程共享的程序正文，是不可改变的。）fork 调用返回一个值，在子进程中该值为零，并且在父进程中等于子进程的**进程标识符**（Process IDentifier，PID）。使用返回的 PID，就可以在两个进程中看出哪一个是父进程，哪一个是子进程。

多数情形下，在 fork 之后，子进程需要执行与父进程不同的代码。这里考虑 shell 的情形。它从终端读取命令，创建一个子进程，等待该子进程执行命令，在该子进程终止时，读入下一条命令。为了等待子进程结束，父进程执行 waitpid 系统调用，它只是等待，直至子进程终止（若有多个子进程的话，则直至任何一个子进程终止）。waitpid 可以等待一个特定的子进程，或者通过将第一个参数设为 -1 的方式，等待任何一个老的子进程。在 waitpid 完成之后，将把第二个参数 statloc 所指向的地址设置为子进程的退出状态（正常或异常终止以及退出值）。有各种可使用的选项，它们由第三个参数确定。例如，如果没有已经退出的子进程则立即返回。

现在考虑 shell 如何使用 fork。在键入一条命令后，shell 调用 fork 创建一个新的进程。这个子进程必须执行用户的命令。通过使用 execve 系统调用可以实现这一点，这个系统调用会引起其整个核心映像被一个文件所替代，该文件由第一个参数给定。（实际上，该系统调用自身是 exec 系统调用，但是若干个不同的库过程使用不同的参数和稍有差别的名称调用该系统调用。在这里，我们把它们都视为系统调用。）在下列函数中，用一个高度简化的 shell 说明 fork、waitpid 以及 execve 的使用。

```c
#define	TRUE 1
												
while (TRUE) {							//一直循环下去
    type_prompt();						//在屏幕上显式提示符
    read_command(command, parameters);	//在终端读取输入
    
    if (fork() != 0) {					//派生子进程
        //父代码
        waitpid(-1, &status, 0);		//等待子进程退出
    } else {
        //子代码
        execve(command, parameters, 0);	//执行命令
    }
}
```



在最一般情形下，execve 有三个参数：将要执行的文件名称，一个指向变量数组的指针，以及一个指向环境数组的指针。这里对这些参数做一个简要的说明。各种库例程，包括 excel、ececv、execle 以及 execve，允许略掉参数或以各种不同的方式给定。在本书中，我们在所有涉及的地方使用 exec 描述系统调用。

下面考虑诸如

cp file1 file2

的命令，该命令将 file1 复制到 file2。在 shell 创建进程之后，该子进程定位和执行文件 cp，并将源文件名和目标文件名传递给它。

CP 主程序（以及多数其他 C 程序的主程序）都有声明

main(argc, argv, envp)

其中 argc 是该命令行有关参数数目的计数器，包括程序名称。例如，上面的例子中，argc 为 3。

第二个参数 argv 是一个指向数组的指针。该数组的元素 i 是指向该命令行第 i 个字符串的指针。在本例中，argv[0] 指向字符串 "cp"，argv[1] 指向字符串 "file1"，argv[2] 指向字符串 "file2"。

main 的第三个参数 envp 是一个指向环境的指针，该环境是一个数组，含有 name = value 的赋值形式，用以将诸如终端类型以及根目录等信息传送给程序。还有供程序调用的库过程，用来取得环境变量，这些变量通常用来确定用户希望如何完成特定的任务（例如，使用默认打印机）。在上列模拟 shell 的程序中，没有环境参数传递给子进程，所以 execve 的第三个参数为 0。

如果读者认为 exec 过于复杂，那么也不要失望。这是在 POSIX 的全部系统调用中最复杂的一个（语义中），其他的都非常简单。作为一个简单例子，考虑 exit，这是在进程完成执行后应执行的系统调用。这个系统调用有一个参数——退出状态（0 至 255），该参数通过 waitpd 系统调用中的 statloc 返回父进程。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE15.jpg"/>
</div>

在 UNIX 中的进程将其存储空间划分为三段：**正文段**（如程序代码）、**数据段**（如变量）以及**堆栈段**。数据向上增长而堆栈向下增长，如图 1-20 所示。夹在中间的是未使用的地址空间。堆栈在需要时自动地向中间的空闲区（gap）增长，不过数据段的扩展是显式地通过系统调用 brk（brk 是系统调用，主要工作是实现虚拟内存到内存的映射，可以让进程的堆指针增长一定的大小，逻辑上消耗掉一块虚拟地址空间） 进行的，在数据段扩充后，该系统调用指定一个数据段结束处的新地址。但是，这个调用不是 POSIX 标准中定义的，对于存储器的动态分配，鼓励程序员使用 malloc 库过程，而 malloc 的内部实现则不是一个适合标准化的主题，因为几乎没有程序员直接使用它，我们有理由怀疑是否有人会注意到 brk 实际不是属于 POSIX 的。



##### 1.6.2	用于文件管理的系统调用

许多系统调用与文件系统有关。本小节讨论在单个文件上的操作，1.6.3 将讨论与目录和整个文件系统有关的内容。

要读写要给文件，先要使用 open 打开该文件。这个系统调用通过绝对路径名或指向工作目录的相对路径名指定要打开文件的名称，而代码 O_RDONLY、O_WRONLY 或 Q_RDWR 的含义分别是只读、只写或两者都可以。为了创建一个新文件，使用 O_CREAT 参数。然后可使用返回的文件描述符进行读写操作。接着，可以用 close 关闭文件，这个调用可以释放该文件描述符，使得它在后续的 open 中能被再次使用。

毫无疑问，最常用的调用是 read 和 write。我们在前面已经讨论过 read。write 具有与 read 相同的参数。

尽管多数程序频繁地读写文件，但是仍有一些应用程序需要能够随机访问一个文件的任意部分。与每个文件相关的是一个指向文件当前位置的指针。在顺序读（写）时，该指针通常指向要读出（写入）的下一个字节。lseek 调用可以改变该位置指针的值，这样后续的 read 或 write 调用就可以在文件的任何地方开始。

lseek 有三个参数：第一个是文件的描述符，第二个是文件位置，第三个说明该文件位置是相对于文件起始位置、当前位置还是文件的结尾。在修改了指针之后，lseek 所返回的值是文件中的绝对位置。

UNIX 为每个文件保存了该文件的类型（普通文件、特殊文件、目录等）、大小、最后修改时间以及其他信息。程序可以通过 stat 系统调用查看这些信息。第一个参数指定了要被检查的文件；第二个参数是一个指针，该指针指向存放这些信息的结构。对于一个打开的文件而言，fstat 调用完成同样的工作。



##### 1.6.3	用于目录管理的系统调用

本小节我们讨论与目录或整个文件系统有关的某些系统调用，而不是 1.6.2 节中与一个特定文件有关的系统调用。mkdir 和 rmdir 分别用于创建和删除空目录。下一个调用是 link。它的作用是允许同一个文件以两个或多个名称出现，多数情形下是在不同的目录中这样做。它的典型应用是，在同一个开发团队中允许若干个成员共享一个共同的文件，他们每个人都在自己的目录中有该文件，但可能采用的是不同的名称。共享一个文件，与每个团队成员都有一个私用副本并不是同一件事，因为共享文件意味着任何成员所作的修改都立即为其他成员所见——只有一个文件存在。而在复制了一个文件的多个副本之后，对其中一个副本所进行的修改并不会影响到其他的副本。

为了考察 link 是如何工作的，考虑图 1-21a 中的情形。有两个用户 ast 和 jim，每个用户都有一些文件的目录。若 ast 现在执行一个含有系统调用的程序

link("/user/jim/memo", "usr/ast/note");

jim 目录中的文件 memo 以文件名 note 进入 ast 的目录。之后，/user/jim/memo 和 usr/ast/note 都引用相同的文件。

理解 link 是如何工作的也许有助于读者看清其作用。在 UNIX 中，每个文件都有唯一的编号，即 i- 编号，用以标识文件。该 i-编号是对 i-**节点**表格的一个引用，它们一一对应，说明该文件的拥有者、磁盘块的位置等。目录就是一个包含了（i-编号，ASCII 名称）对集合的文件。在 UNIX 的第一个版本中，每个目录项有 16 个字节——2 字节用于 i-编号，14 字节用于名称。现在为了支持长文件名，采用了更复杂的结构，但是，在概念上，目录仍然是（i-编号，ASCII 名称）对的一个集合。在图 1-21 中，mail 为 i-编号 16，等等。link 所做的只是利用某个已有文件的 i-编号，创建一个新目录项（也许用一个新名称）。在图 1-21b 中有两个目录项有相同的 i-编号（70），从而指向同一个文件。如果使用 unlink 系统调用将其中一个文件一走了，可以保留另一个。如果两个都被移走了，UNIX 00 看到尚且存在的文件没有目录项（i-节点中的一个域记录着指向该文件的目录项），就会把该文件从磁盘中移去。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE16.jpg"/>
</div>

正如我们已经叙述过的，mount 系统调用允许将两个文件系统合并成为一个。通常的情形是，在硬盘某个分区中的根文件系统含有常用命令的二进制（可执行）版和其他常用的文件，用户文件在另一个分区。并且，用户可插入包含需要读入的文件的 U 盘。

通过执行 mount 系统调用，可以将一个 USB 文件系统添加到根文件系统中，如图 1-22 所示。完成安装操作的典型 C 语句为

mount("/dev/sdb0", "/mnt", 0);

这里，第一个参数是 USB 驱动器 0 的块特殊文件名称，第二个参数是要被挂载在树中的位置，第三个参数说明将要挂载的文件系统是可读写的还是只读的。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE17.jpg"/>
</div>

在 mount 调用之后，驱动器 0 上的文件可以使用从根目录开始的路径或工作目录路径，而不用考虑文件在哪个驱动器上。事实上，第二个、第三个以及第四个驱动器也可安装在树上的任何地方。mount 调用使得把可移动介质都集中到一个文件层次中成为可能，而不用考虑文件在那个驱动器上。尽管这是个 CD-ROM 的例子，但是也可以用同样的方法安装硬盘或者硬盘的一部分（常称为**分区**或**次级设备**），外部硬盘和 USB 盘也一样。当不再需要一个文件系统时，可以用 unmount 系统调用卸载之。



##### 1.6.4	各种系统调用

有各种的系统调用。这里介绍系统调用中的一部分。chdir 调用改变当前的工作目录。在调用

chdir("/usr/ast/test");

之后，打开 xyz 文件，会打开 /usr/ast/test/xyz。工作目录的概念消除了总是键入（长）绝对路径名的需要。

在 UNIX 中，每个文件有一个保护模式。该模式包括针对所有者、组和其他用户的读-写-执行位。chmod 系统调用可以改变文件的模式。例如，要使一个文件对除了所有者之外的用户只读，可以执行

chmod("file", 0644);

kill 系统调用供用户或用户进程发送信号用。若一个进程准备好捕捉一个特定的信号，那么，在信号到来时，运行一个信号处理程序。如果该进程没有准备好，那么信号的到来会杀掉该进程（此调用名称的由来）。

POSIX 定义了若干处理时间的过程。例如，time 以秒为单位返回当前时间，0 对应着 1970 年 1 月 1 日午夜（从此日开始，没有结束）。



##### 1.6.5	Windows Win32 API

到目前为止，我们主要讨论的是 UNIX 系统。现在简要地考察 Windows。Windows 和 UNIX 的主要差别在于编程方式。UNIX 程序包括做各种处理的代码以及完成特定服务的系统调用 。Windows 程序通常是事件驱动程序。其中主程序等待某些事件发生，然后调用要给过程处理该事件。典型的时间包括被敲击的键、移动的鼠标、被按下的鼠标或插入的 U 盘。调用事件处理程序处理事件，刷新屏幕，并更新内部程序状态。总之，这是与 UNIX 不同的程序设计风格，由于本书专注于操作系统的功能和结构，这些程序设计方式上的差异就不过多涉及了。

当然，在 Windows 中也有系统调用。在 UNIX 中，系统调用（如 read）和系统调用所使用的库过程（如 read）之间几乎是一一对应的关系。换句话说，对于每个系统调用，差不过就涉及一个被调用的库过程，如图 1-17 所示。此外，POSIX 有约 100 个过程调用。

在 Windows 中，情况就大不相同了。首先，库调用和实际的系统调用几乎是不对应的。微软定义了一套过程，成为 **Win32应用编程接口**（Application Program Interface，API），程序员用这套过程获得操作系统的服务。从 Windows95 开始的所有 Windows 版本都（或部分）支持这个接口。由于接口与实际的系统调用不对应，微软保留了随着时间（甚至随着版本到版本）改变实际系统调用的能力，防止已有的程序失效。由于最新几版 Windows 中有许多过去没有的新调用，所以究竟 Win32 是由什么构成的，这个问题的答案仍然是含混不清的。在本小节中，Wind32 表示所有 Windows 版本都支持的接口。Win32 提供各 Windows 版本的兼容性。

Win32 API 调用的数量是非常大的，有数千个。此外，尽管其中许多确实涉及系统调用，但有一大批 Win32 API 完全是在用户空间进行的。结果，在 Windows 中，不可能了解哪一个是系统调用（如内核完成），哪一个只是用户空间中的库调用。事实上，某个版本中的一个系统调用，会在另一个不同版本的用户空间中执行，或者相反。当我们在本书中讨论 Windows 的系统调用时，将使用 Win32 过程（在合适之处），这是因为微软保证：随着时间流逝，Win32 过程将保持稳定。但是读者有必要记住，它们并不全都是系统调用（即陷入内核中）。

Windows 中没有类似 UNIX 中的进程层次，所以不存在父进程和子进程的概念。在进程创建之后，创建者和被创建者是平等的。





#### 1.7	操作系统结构

我们已经分析了操作系统的外部（如程序员接口），现在是分析其内部的时候了。在下面的小节中，为了对各种可能的方式有所了解，我们将考察已经尝试过的六种不同的结构设计。这样做并没有涵盖各种结构方式，但是至少给出了在实践中已经试验过的一些涉及思想。我们将讨论的这六种涉及包括单体系统、层次式系统、微内核、客户端-服务器模式、虚拟机和外核等。



##### 1.7.1	单体系统

到目前为止，在大多数常见的组织中，整个操作系统在内核态以单一程序的方式运行。整个操作系统以过程集合的方式编写，链接成一个大型可执行二进制程序。使用这种技术，系统中每个过程可以自由调用其他过程，只要后者提供了前者所需要的一些有用的计算工作。调用任何一个你所需要的过程或许会非常高效，但上千个可以不受限制地彼此调用的过程常常导致系统笨拙且难于理解。并且，任何一个过程的崩溃都会连累整个系统。

在使用这种处理方式构造实际的目标程序时，首先编译所有单个的过程，或者编译包含过程的文件，然后通过系统链接程序将它们链接成单一的目标文件。就信息隐藏来说，这里实际上是不存在的，每个过程对其他过程都是可见的（与包含模块或包的结构相反，在结构中，其中多数信息隐藏在模块之中，而且只能通过正式设计的入口点实现模块的外部调用）。

但是，即使在单体系统中，也可能有一些结构存在。可以将参数放置在良好定义的位置（如栈），通过这种格式，向操作系统请求所能提供的服务（系统调用），然后执行一个陷阱指令。这里指令将机器从用户态切换到内核态并把控制传递给操作系统，如图 1-17 中第 6 步所示。然后，操作系统取出参数并且确定应该执行哪一个系统调用。随后，它在一个表格中检索，在该表格的 k 槽中存放着指向执行系统调用 k 过程的指针（图 1-17 中第 7 步）。

对于这类操作系统的基本结构，有者如下结构上的建议：

1. 需要一个主程序，用来处理服务过程请求。
2. 需要一套服务过程，用来执行系统调用。
3. 需要一套实用过程，用来辅助服务过程。

在该模型中，每一个系统调用都通过一个服务过程为其工作并运行之。要有一组实用程序来完成一些服务过程所需要用到的功能，如从用户程序取数据等。可将各种过程划分为一个三层的模型，如图 1-24 所示。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE18.jpg"/>
</div>

除了在计算机初启时所装载的核心操作系统外，许多操作系统支持可装载的扩展，诸如 I/O 设备驱动和文件系统。这些部件可以按照需要载入。在 UNIX 中它们被叫作**共享库**（shared library），在 Windows 中则被称为**动态链接库**（Dynamic Link Library，DLL）。它们的扩展类型为 .dll，在 C:\Windows\system32 目录下存在 1000 多个 DDL 文件。



##### 1.7.2	层次式系统

把图 1-24 中的系统进一步通用化，就变成一个层次式结构的操作系统，它的上层软件都是在下一层软件的基础之上构建的。THE 系统是按此模型构造的第一个操作系统（1968）。THE 系统是为荷兰的一种计算机 Electrologica X8 配备的一个简单的批处理系统，其内存只有 32K 个字，每字 27 位（那时二进制位是很昂贵的）。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE19.jpg"/>
</div>

该系统共分为六层，如图 1-25 所示。处理器分配在第 0 层中进行，当中断发生或定时器到期时，由该层进行进程切换。在第 0 层之上，系统由一些连续的进程所组成，编写这些进程时不用再考虑在单处理器上多进程运行的细节。也就是说，在第 0 层中提供了基本的 CPU 多道程序设计功能。

内存管理在第 1 层中进行，它分配进程的主存空间，当内存用完时则在一个 512K 字的磁鼓上保留进程的一部分（页面）。在第 1 层上，进程不用考虑它是在磁鼓上还是在内存中运行。第 1 层软件保证一旦需要访问某一页面，该页面必定已在内存中，并在页面不再需要时将其移出。

第 2 层处理进程与操作员控制台（即用户）之间的通信。在这层的上部，可以认为每个进程都有自己的操作员控制台。第 3 层管理 I/O 设备和相关的信息流缓冲区。在第 3 层上，每个进程都与有良好特性的抽象 I/O 设备打交道，而不必考虑外部设备的而无力细节。第 4 层是用户程序层。用户程序不用考虑进程、内存、控制台或 I/O 设备管理等细节。系统操作员进程位于第 5 层中。

在 MULTICS 系统中采用了更进一步的通用层次化概念。MULTICS 由许多的同心环构造而成，而不是采用层次化构造，内环比外环有更高的级别（它们实际上是一样的）。当外环的过程欲调用内环的过程时，它必须执行一条等价于系统调用的 TRAP 指令。在执行该 TRAP 指令前，要进行严格的参数合法性检查。在 MULTICS 中，尽管整个操作系统是各个用户进程的地址空间的一部分。但是硬件仍能对单个过程（实际是内存中的一个段）的读、写和执行进行保护。

实际上，THE 分层方案只是为设计提供了一些方便，因为该系统的各个部分最终仍然呗链接成了完整的单个目标程序。而在 MULTICS 里，环形机制在运行中是实际存在的，而且是由硬件实现的。环形机制的一个有点是很容易扩展，可用以构造用户子系统。例如，在一个 MULTICS 系统中，教授可以写一个程序检查学生编写的程序并给他们打分，在第 n 个环中运行教授的程序，而在第 n+1 个环中运行学生的程序，这样学生就无法篡改教授所给出的成绩。



##### 1.7.3	微内核

在分层方式中，设计者要确定在哪里划分内核-用户的边界。传统上，所有的层都在内核中，但是这样做没有必要。事实上，尽可能减少内核态中功能的做法更好，因为内核中的错误会快速拖累系统。相反，可以把用户进程设置为具有较小的权限，这样，某个错误的后果就不会是致命的。

有不少研究人员对每千行代码中错误的数量进行了分析。代码错误的密度取决于模块大小、模块寿命等，不过对一个实际工业系统而言，每千行代码中会有 2~10 个错误。这意味着在有 500 万行代码的单体操作系统中，大约有 10000~50000 个内核错误。当然，并不是所有的错误都是致命的，诸如给出了不正确的故障信息之类的某些错误，实际是很少发生的。无论怎样看，操作系统中充满了错误，所以计算机制造商设置了复位按钮（通常在前面板上），而电视机、立体音响以及汽车的制造商则不这样做，尽管在这些装置中也有大量的软件。

而微内核设计背后的思想是，为了实现高可靠性，将操作系统划分成小的、良好定义的模块，只有其中一个模块——微内核——运行在内核态，其余的模块由于功能相对弱些，则作为普通用户进程运行。特别地，由于把每个设备驱动和文件系统分别作为普通用户进程，这些模块中的错误虽然会使这些模块崩溃，但是不会使整个系统死机。所以，音频驱动中的错误会使声音断续或停止，但是不会使整个计算机垮掉。相反，在单体系统中，由于所有的设备驱动都在内核中，一个有故障的音频驱动很容易引起对无效地址的引用，从而造成恼人的系统立即停机。

有许多微内核已经被实现并应用了数十年。除了基于 Mach 微内核的 OS X 外，通常的桌面操作系统并不使用微内核。然而，微内核在实时、工业、航空以及军事应用中特别流行，这些领域都是关键任务，需要有高度的可靠性。

一个与小内核相关联的思想是内核中的**机制**与**策略**分离的原则。为了更清晰地说明这一点，我们考虑进程调度。一个比较简单的调度算法是，对每个进程赋予一个优先级，并让内核执行具有最高优先级的进程。这里，机制（在内核中）就是寻找最高优先级的进程并运行之。而策略（赋予进程优先级）可以由用户态中的进程完成。在这种方式中，机制和策略是分离的，从而使系统内核变得更小。



##### 1.7.4	客户端—服务器模式

一个微内核思想的略微变体是将进程划分为两类：**服务器**，每个服务器提供某种服务；**客户端**，使用这些服务。这个模式就是所谓的**客户端—服务器**模式。通常，在系统最底层是微内核，但并不是必须这样。这个模式的本质是存在客户端进程和服务器进程。

一般来说，客户端和服务器之间的通信是消息传递。为了获得一个服务，客户端进程构造一段消息，说明所需要的服务，并将其发给合适的服务器。该服务器完成工作，发送回应。如果客户端和服务器恰巧运行在同一个机器上，则有可能进行某种优化，但是从概念上看，这里讨论的是消息传递。

这个思想的一个显然的普遍方式是，客户端和服务器运行在不同的计算机上，它们通过局域网或广域网连接，如图 1-27 所示。由于客户端通过发送消息与服务器通信，客户端并不需要知道这些消息是在本地机器上处理，还是通过网络被送到远程机器上处理。对于客户端而言，这两种情形是一样的：都是发送请求并得到回应。所以，客户端—服务器模式是一种可以应用在单机或者网络机器上的抽象。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE20.jpg"/>
</div>





##### 1.7.5	虚拟机

OS／360 的最早版本是纯粹的批处理系统。然而，有许多 360 用户希望能够在终端上交互工作，于是 IBM 公司内外的一些研究小组决定为它编写一个分时系统。后来推出了正式的 IBM 分时系统 TSS／360。但是它非常庞大，运行缓慢，于是在花费了约 5000 万美元的研制费用后，该系统最后被弃之不用（Graham，1970）。但是在位于麻省剑桥的 IBM 研究中心开发了另一个完全不同的系统，这个系统最终被 IBM 用作产品。它的直接后代，称为 z/VM，目前在 IBM 的大型机上广泛使用，zSeries 则在大型公司的数据中心广泛使用，例如，作为电子商务服务器，它们每秒可以处理成百上千个事务，并使用规模达数百万 GB 的数据库。



**1.VM/370**

这个系统最初被命名为 CP/CMS，后来改名为 VM/370。它是源于如下机敏的观察，即分时系统应该提供这些功能：（1）多道程序，（2）一个比裸机更方便的、有扩展界面的计算机。VM／370 存在的目的是将二者彻底地隔离开来。

这个系统的核心称为**虚拟机监控程序**（virtual machine monitor），它在裸机上运行并且具备了多道程序功能。该系统向上层提供了若干台虚拟机，如图 1-28 所示。它不同于其他操作系统的地方是：这些虚拟机不是那种具有文件等优良特征的扩展计算机。与之相反，它们仅仅是裸机硬件的精确复制品。这个复制品包含了内核态/用户态、I/O 功能、中断及其他真实硬件所应该具有的全部内容。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE21.jpg"/>
</div>

由于每台虚拟机都与裸机相同，所以在每台虚拟机上都可以运行一台裸机所能够运行的任何类型的操作系统。不同的虚拟机可以运行不同的操作系统，而且实际上往往就是如此。在早期的 VM/370 系统上，有一些系统运行 OS／360 或者其他大型批处理或事务处理操作系统，而另一些虚拟机运行单用户、交互式系统供分时用户使用，这个系统称为**会话监控系统**（Conversational Monitor System，CMS）。后者在程序员中很流行。

当一个 CMS 程序执行系统调用时，该调用被陷入到其虚拟机的操作系统上，而不是 VM/370 上，似乎它运行在实际的机器上，而不是在虚拟机上。CMS 然后发出普通的硬件 I/O 指令读出虚拟磁盘或其他需要执行的调用。这些 I/O 指令由 VM/370 陷入，然后，作为对实际硬件模拟的一部分，VM/370 完成指令。通过对多道程序功能和提供扩展机器二者的完全分离，每个部分都变得非常简单、非常灵活且容易维护。

虚拟机的现代化身 z/VM 通常用于运行多个完整的操作系统，而不是简化成如 CMS 一样的单用户系统。例如，zSeries 有能力与传统的 IBM 操作系统一起，运行一个或多个 Linux 虚拟机。



**2.虚拟机的再次发现**

IBM 拥有虚拟机产品已经有 40 年了，而少数公司，包括 Oracle 公司和 Hewlett-Packard 公司等，近来也在其高端企业服务器上增加对虚拟机的支持，在 PC 上，直到最近之前，虚拟化的思想在很大程度上被忽略了。不过近年来，新的需求、新的软件和新的技术已经使得虚拟机成为热点。

首先看需求。传统上，许多公司在不同的计算机上，有时还在不同的操作系统上，运行其邮件服务器、Web 服务器、FTP 服务器以及其他服务器。他们看到可以在同一台机器上实现虚拟化来运行所有的服务器，而不会由于一个服务器崩溃影响其他系统。

虚拟化在 Web 托管世界里也很流行。没有虚拟化，Web 托管客户端只能**共享托管**（在 Web 服务器上给客户端一个账号，但是不能控制整个服务器软件）以及独占托管（提供给客户端整个机器，这样虽然很灵活，但是对于小型或中型 Web 站点而言，成本效益比不高）。当 Web 托管公司提供租用虚拟机时，一台物理机器就可以运行许多虚拟机，每个虚拟机看起来都是一台完全的机器。租用虚拟机的客户端可以运行自己想使用的操作系统和软件，但是只需支付独占一台机器的几分之一的费用（因为一台物理机器可以同时支持多台虚拟机）。

虚拟化的另外一个用途是，为希望同时运行两个或多个操作系统（比如 Windows 和 Linux）的最终用户服务，某个偏好的应用程序可运行在一个操作系统上，而其他的应用程序可运行在另一个操作系统上。如图1-29a所示，在这里术语 “虚拟机监控程序” 已经被重命名为第一类虚拟机管理程序（type 1 hypervisor），后者现在更常用，因为输入前者的英文 “virtual machine monitor” 超出了人们所能接受的按键次数。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE22.jpg"/>
</div>

虚拟机的吸引力是没有争议的，问题在于实现。为了在一台计算机上运行虚拟机软件，其 CPU 必须被虚拟化。简言之，存在一个问题。当运行虚拟机（在用户态）的操作系统执行某个特权指令时，比如修改 PSW 或进行 I/O 操作，硬件实际上陷入到了虚拟机中，这样有关指令就可以在软件中模拟。在某些 CPU 上（特别是 Pentium 和它的后继者及其克隆版中）试图在用户态执行特权指令时，会被忽略掉。这种特性使得在这类硬件中无法实现虚拟机，这也解释了 PC 世界对虚拟机不感兴趣的原因。当然，对于 Pentium 而言，还有解释器可以运行在 Pentium 上，例如 Bochs 但是其性能丧失了 1～2 数量级，这样对于要求高的工作来说就没有意义了。

由于 20 世纪 90 年代和本世纪这些年来若干学术研究小组的努力，特别是斯坦福大学的Disco（Bugnion 等人，1997）和剑桥大学的 Xen（Barham 等人，2003）实现了商业化产品（例如 VMware 工作站和 Xen），使得人们对虚拟机的热情得以复燃。除了 VMware 和 Xen 外，现在流行的虚拟机管理程序还有 KVM（针对 Linux 内核）、Oracle 公司的 VirtualBox 以及微软公司的 Hyper-V。

一些早期研究项目通过即时翻译大块代码、将其存储到内部高速缓存并在其再次执行时复用的方式，提高了 Bochs 等翻译器的性能。这种手段大幅提高了性能，也推动了模拟器（machine simulator）的出现，如图 1-29b 所示。这项被称为二进制翻译（binary translation）的技术对性能的提升有所帮助，不过，生成的系统虽然优秀到足以在学术会议上发表论文，但仍没有快到可以在极其注重性能的商业环境下使用。

改善性能的下一步在于添加分担重担的内核模块，如图 1-29c 所示。事实上，现在所有商业可用的虚拟机管理程序都使用这种混合策略（并且也有很多其他改进），如 VMware 工作站。它们被称为第二类虚拟机管理程序，本书中我们也延续使用这个名称（虽然有些不太情愿），即使我们更愿意用类型 1.7 虚拟机管理程序来反映它们并不完全是用户态程序。在第 7 章中，我们将详细描述 VMware 工作站的工作原理及其各部分的作用。

实际上，第一类和第二类虚拟机管理程序的真正区别在于，后者利用**宿主操作系统**（host operating system）并通过其文件系统创建进程、存储文件等。第一类虚拟机管理程序没有底层支持，所以必须自行实现所有功能。

当第二类虚拟机管理程序启动时，它从 CD-ROM 安装盘中读入供选择的**客户操作系统**（guest operating system），并安装在一个虚拟盘上，该盘实际上只是宿主操作系统的文件系统中的一个大文件。由于没有可以存储文件的宿主操作系统，因此第一类虚拟机管理程序不能采用这种方式。它们必须在原始的硬盘分区上自行管理存储。

在客户操作系统启动时，它完成的工作与在真实硬件上相同，如启动一些后台进程，然后是 GUI。对用户而言，客户操作系统与在裸机上运行时表现出相同的行为，虽然事实并非如此。

处理控制指令的一种不同方式是，修改操作系统，删掉它们。这种方式不是真正的虚拟化，而是**半虚拟化**（paravirtualization）。我们将在第 7 章具体讨论虚拟化。



**3.Java 虚拟机**

另一个使用虚拟机的领域，是为了运行 Java 程序，但方式有些不同。在 Sun 公司发明 Java 程序设计语言时，也同时发明了称为 **JVM**（Java Virtual Machine）的虚拟机（一种体系结构）。Java 编译器为 JVM 生成代码，这些代码以后可以由一个软件 JVM 解释器执行。这种处理方式的优点在于，JVM 代码可以通过 Internet 传送到任何有 JVM 解释器的计算机上，并在该机器上执行。举例来说，如果编译器生成了 SPARC 或 Pentium 二进制代码，这种代码不可能轻易地送到任何地方并执行。（当然，Sun 可以生产一种生成 SPARC 二进制代码地编译器，并且发布一种 SPARC 解释器，但是 JVM 具有非常简单的、只需要解释的体系结构。）使用 JVM 的另一种优点是，如果解释器正确地完成，并不意味着就结束了，还要对所输入的 JVM 程序进行安全性检查，然后在一种保护环境下执行，这样，这些程序就不能偷窃数据或进行其他任何有害的操作。



##### 1.7.6	外核

与虚拟机克隆真实机器不同，另一种策略是对机器进行分区，换句话说，给每个用户整个资源的一个子集。这样，某个虚拟机可能得到磁盘的 0 至 1023 盘块，而另一台虚拟机会得到 1024 至 2047 盘块，等等。

在底层中，一种称为外核（exokernel，Engler 等人，1995）的程序在内核态运行。它的任务是为虚拟机分配资源，并检查使用这些资源的企图，以确保没有机器会使用他人的资源。每个用户层的虚拟机可以运行自己的操作系统，如 VM/370 和 Pentium 虚拟 8086 等，但限制只能使用已经申请并且获得分配的那部分资源。

外核机制的优点是，它减少了映像层。在其他的设计中，每个虚拟机都认为它有自己的磁盘，其盘块号从 0 到最大编号，这样虚拟机监控程序必须维护一张表格以重映像磁盘地址（以及其他资源）。有了外核，这个重映像处理就不需要了。外核只需要记录已经分配给各个虚拟机的有关资源即可。这个方法还有一个优点，它将多道程序（在外核内）与用户操作系统代码（在用户空间内）加以分离，而且相应负载并不重，这是因为外核所做的只是保持多个虚拟机彼此不发生冲突。



#### 1.8	依靠 C 的世界

操作系统通常是由许多程序员写成的，包括很多部分的大型 C（有时是 C++）程序。用于开发操作系统的环境，与个人（如学生）用于编写小型 Java 程序的环境是非常不同的。本节试图为那些有时编写Java或者Python程序的程序员简要地介绍编写操作系统的环境。

**1.8.1   C语言**

这里不是 C 语言的指南，而是简要介绍 C 与类 **Python** 语言特别是 Java 之间的关键差别。Java 是基于 C 的，所以两者之间有许多类似之处。Python 有一点不同，但仍然十分相似。为方便起见，我们将注意力放在 Java 上。Java、Python 和 C 都是命令式的语言，例如，有数据类型、变量和控制语句等。在 C 中基本数据类型是整数（包括短整数和长整数）、字符和浮点数等。使用数组、结构体和联合，可以构造组合数据类型。C 语言中的控制语句与 Java 类似，包括 if、switch、for 以及 while 等语句。在这两个语言中，函数和参数大致相同。

一项 C 语言中有而 Java 和 Python 中没有的特点是显式指针（explicit pointer）。指针是一种指向（即包含对象的地址）一个变量或数据结构的变量。考虑下面的语句：

```c
char c1，c2，*p； 
c1 = 'c'； 
p = &c1；  
c2 = *p； 
```



这些语句声明 c1 和 c2 是字符变量，而 p 是指向一个字符的变量（即包含字符的地址）。第一个个赋值语句将字符 c 的 ASCII 代码存到变量 c1 中。第二个语句将 c1 的地址赋给指针变量 p。第三个语句将由 p 指向变量的内容赋给变量 c2，这样，在这些语句执行之后，c2 也含有 c 的 ASCII 代码。在理论上，指针是输入类型，所以不能将浮点数地址赋给一个字符指针，但是在实践中，编译器接受这种赋值，尽管有时给出一个警告。指针是一种非常强大的结构，但是如果不仔细使用，也会是造成大量错误的一个原因。

C 语言中没有包括内建字符串、线程、包、类、对象、类型安全（type safety）以及垃圾回收（garbage collection）等。最后一个是操作系统的 “淋浴器塞子”。在 C 中分配的存储空间或者是静态的，或者是程序员明确分配和释放的，通常使用 malloc 以及 free 库函数。正是由于后面这个性质—由程序员控制所有内存—而且是用明确的指针，使得 C 语言对编写操作系统而言非常有吸引力。从一定程度上来说，操作系统实际上是个实时系统，甚至通用系统也是实时系统。当中断发生时，操作系统可能只有若干微秒去完成特定的操作，否则就会丢失关键的信息。在任意时刻启动垃圾回收功能是不可接受的。



**1.8.2   头文件**

一个操作系统项目通常包括多个目录，每个目录都含有许多 .c 文件，这些文件中存有系统某个部分的代码，而一些 .h 头文件则包含供一个或多个代码文件使用的声明以及定义。头文件还可以包括简单的宏，如

```c
#define BUFFER_SIZE 4096 
```

宏允许程序员命名常数，这样代码中出现的 BUFFER_SIZE 在编译时就被数值 4096 所替代。良好的 C 程序设计实践是命名除了 0，1 和 -1 之外的所有常数，有时甚至也命名这三个数。宏可以附带参数，例如

```c
#define max(a, b)(a > b ? a: b) 
```



这个宏允许程序员编写

```c
i = max(j，k+1) 
```



从而得到

```c
i= (j > k+1 ? j : k+1) 
```



将 j 与 k+1 之间的较大者存储在 i 中。头文件还可以包含条件编译，例如

```c
#ifdef X86 
intel_int_ack();  
#endif 
```



如果宏 x86 有定义，而不是其他，则编译进对 intel_int_ack 函数的调用。为了分隔与结构有关的代码，大量使用了条件编译，这样只有当系统在 x86 上编译时，一些特定的代码才会被插入，其他的代码仅当系统在 SPARC 等机器上编译时才会插入。通过使用 #include 指令，一个 .c 文件体可以含有零个或多个头文件。



**1.8.3   大型编程项目**

为了构建操作系统，每个 .c 被 C 编译器编译成一个**目标文件**。目标文件使用后缀 .o，含有目标机器的二进制代码。随后它们可以直接在 CPU 上运行。在 C 的世界里，没有类似于 Java 字节代码的东西。

C 编译器的第一道处理称为 C **预处理器**。在它读入每个 .c 文件时，每当遇到一个 #include 指令，就取来该名称的头文件，并加以处理、扩展宏、处理条件编译（以及其他事务），然后将结果传递给编译器的下一道，仿佛它们原先就包含在该文件中一样。

由于操作系统非常大（500 万行代码是很寻常的），每当文件修改后就重新编译是无法忍受的。另一方面，改变了用在成千上万个文件中的一个关键头文件，确实需要重新编译这些文件。没有一定的协助，要想记录哪个目标文件与哪个头文件相关是完全不可行的。

幸运的是，计算机非常善于处理事物分类。在 UNIX 系统中，有个名为 make 的程序（其大量的变体如 gmake、pmak e等），它读入 Makefile，该 Makefile 说明哪个文件与哪个文件相关。make 的作用是，在构建操作系统二进制码时，检查此刻需要哪个目标文件，而且对于每个文件，检查自从上次目标文件创建之后是否有任何它依赖的文件（代码和头文件）已经被修改了。如果有，目标文件需要重新编译。在 make 确定了哪个 .o 文件需要重新编译之后，它调用 C 编译器重新编译这些文件，这样，就把编译的次数降到最低限度。在大型项目中，创建 Makefile 是一件容易出错的工作，所以出现了一些工具使该工作能够自动完成。

一旦所有的 .o 文件就绪，这些文件被传递给称为 linker 的程序，将其组合成一个可执行的二进制文件。此时，任何被调用的库函数都已经包含在内，函数之间的引用都已经解决，而机器地址也都按需要分配完毕。在 linker 完成之后，得到一个可执行程序，在 UNIX 中传统上称为 a.out 文件。这个过程中的各个部分如图 1-30 所示，图中的程序包含三个 C 文件和两个头文件。这里虽然讨论的是有关操作系统的开发，但是所有内容对开发任何大型程序而言都是适用的。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE23.jpg"/>
</div>





**1.8.4   运行模型**

在操作系统二进制代码链接完成后，计算机就可以重新启动，新的操作系统开始运行。一旦运行，系统会动态调入那些没有静态包括在二进制代码中的模块，如设备驱动和文件系统。在运行过程中，操作系统可能由若干段组成，有文本段（程序代码）、数据段和堆栈段。文本段通常是不可改变的，在运行过程中不可修改。数据段开始时有一定的大小，并用确定的值进行初始化，但是随后就被修改了，其大小随需要增长。堆栈段被初始化为空，但是随着对函数的调用和从函数返回，堆栈段时时刻刻在增长和缩小。通常文本段放置在接近内存底部的位置，数据段在其上面，这样可以向上增长。而堆栈段处于高位的虚拟地址，具有向下增长的能力，不过不同系统的工作方式各有差别。

在所有情形下，操作系统代码都是直接在硬件上执行的，不用解释器，也不是即时编译，如 Java 通常做的那样。



##### 1.9~1.11

略



##### 1.12	小结

考察操作系统有两种观点：资源管理观点和扩展的机器观点。在资源管理观点中，操作系统的任务是有效地管理系统的各个部分。在扩展的机器观点中，系统的任务是为用户提供比实际机器更便于运用的抽象。这些抽象包括进程、地址空间以及文件。

操作系统的历史很长，从操作系统开始替代操作人员的那天开始到现代多道程序系统，主要包括早期批处理系统、多道程序系统以及个人计算机系统。

由于操作系统同硬件的交互密切，掌握一些硬件知识对于理解它们是有益的。计算机由处理器、存储器以及 I/O 设备组成。这些部件通过总线连接。

所有操作系统构建所依赖的基本概念是进程、存储管理、I/O 管理、文件管理和安全。这些内容都将在后续用一章来讲述。

任何操作系统的核心是它可处理的系统调用集。这些系统调用真实地说明了操作系统所做的工作。对于 UNIX，我们已经考察了四组系统调用。第一组系统调用同进程的创建和终止有关；第二组用于读写文件；第三组用于目录管理；第四组包括各种杂项调用。

操作系统构建方式有多种。最常见的有单体系统、层次化系统、微内核系统、客户端-服务器系统、虚拟机系统和外核系统。





### 第 2 章	进程与线程

从本章开始，我们将深入考察操作系统是如何设计和构造的。操作系统中最核心的概念是**进程**：这是对正在运行程序的一个抽象。操作系统的其他所有内容都是围绕着进程的概念展开的，所以，让操作系统的设计者（及学生）尽快并透彻地理解进程是非常重要的。

进程是操作系统提供的最古老的也是最重要的抽象概念之一。即使可以使用的 CPU 只有一个，但它们也具有支持（伪）并发操作的能力，它们将一个单独的 CPU 变换成多个虚拟的 CPU。没有进程的抽象，现代计算将不复存在。本章会通过大量的细节去探究进程，以及它们的第一个亲戚——线程。



#### 2.1	进程

所有现代的计算机经常会在同一时间做许多件事。习惯于在个人计算机上工作的人们也许不会十分注意这个事实，因此列举一些例子可以更清楚地说明这一问题。先考虑一个网络服务器，一些网页请求从各处进入。当一个请求进入时，服务器检查其需要的网页是否在缓存中。如果是，则把网页发送回去；如果不是，则启动一个键盘请求以获取网页。然而，从 CPU 的角度来看，磁盘请求需要漫长的时间，当等待磁盘请求完成时，其他更多的请求将会进入。如果有多个磁盘存在，可以在满足第一个请求之前就接二连三地对其他的磁盘发出部分或全部请求。很明显，需要一些方法去模拟并控制这种并发。进程（特别是线程）在这里就可以发挥作用。

现在考虑只有一个用户的 PC。一般用户不知道，当启动系统时，会秘密启动许多进程。例如，启动一个进程来等待进入的电子邮件；或者启动另一个防病毒进程周期性地检查是否有病毒库更新。另外，某个用户进程可能会在所有用户上网地时候打印文件以及刻录 CD-ROM。这些活动都需要管理，于是一个支持多进程地多道程序系统在这里就显得很有用了。

在任何多道程序设计系统中，CPU 由一个进程快速切换至另一个进程，使每个进程各运行几十或几百毫秒。严格地说，在某一个瞬间，CPU 只能运行一个进程。但在 1 秒钟内，它可能运行多个进程，这样就产生并行的错觉。有时人们所说的**伪并行**就是指这种情形，以此来区分**多处理器系统**（该系统有两个或多个 CPU 共享同一个物理内存）的真正硬件并行。人们很难对多个并行活动进行跟踪，因此，经过多年的努力，操作系统的设计者开发了用于描述并行的一种概念模型（顺序进程），使得并行更容易处理。有关该模型、它的使用以及它的影响正是本章的主题。



##### 2.1.1	进程模型

在进程模型中，计算机上所有可运行的软件，通常也包括操作系统，被组织成若干**顺序进程**（sequential process），简称**进程**（process）。一个进程就是一个正在运行程序的示例，包括顺序计数器、寄存器和变量的当前值。从概念上说，每个进程拥有它自己的虚拟 CPU。当然，实际上真正的 CPU 在各进程之间来回切换。但为了理解这种系统，考虑在（伪）并行情况下运行的进程集，要比试图跟踪 CPU 如何在程序间来回切换简单得多。正在在第 1 章所看到的，这种快速的切换称作**多道程序设计**。

在图 2-1a 中可以看到，在一台多道程序计算机的内存中有 4 道程序。在图 2-1b 中，这 4 道程序被抽象为 4 个各自拥有自己控制流程（即每个程序自己的逻辑程序计数器）的进程，并且每个程序都独立地运行。当然，实际上只有一个物理程序计数器，所以在每个程序运行时，它的逻辑程序计数器被装入实际的程序计数器中。当该程序执行结束（或暂停执行）时，物理程序计数器被保存在内存中该进程的逻辑程序计数器中。在图 2-1c 中可以看到，在观察足够长的一段时间后，所有的进程都运行了，但在任何一个给定的瞬间仅有一个进程真正在运行。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE24.jpg"/>
</div>

在本章中，我们假设只有一个 CPU。当然，逐渐这个假设就不为真了，因为新的芯片经常是多核的，包含 2 个、4 个或更多的 CPU。第 8 章将会介绍多核芯片以及多处理器，但是现在，一次只考虑一个 CPU 会更简单一些。因此，当我们说一个 CPU 只能真正运行一个进程的时候，即使有 2 个核（或 CPU），每一个核也只能一次运行一个进程。

由于 CPU 在各进程之间来回快速切换，所以每个进程执行其运算的速度是不确定的。而且当同一进程再次运行时，其运算速度通常也不可再现。所以，在对进程编程时决不能对时序做任何想当然的假设。例如，考虑一个 I/O 进程，它用流式磁带机恢复备份的文件，它执行一个 10 000 次的空循环以等待磁带机达到正常速度，然后发出命令读取第一个记录。如果 CPU 决定在空循环期间切换到其他进程，则磁带机进程可能在第一条记录通过磁头之后还未被再次运行。当一个进程具有此类严格的实时要求时，也就是一些特定事件一定要在所指定的若干毫秒内发生，那么必须采取特殊措施以保证它们一定在这段时间中发生。然而，通常大多数进程并不受 CPU 多道程序设计或其他进程相对速度的影响。

进程和程序间的区别是很微妙的，但非常重要。用一个比喻可以更容易理解这一点。想象一位有一手好厨艺的计算机科学家正在为他的女儿烘制生日蛋糕。他有做生日蛋糕的食谱，厨房里有所需的原料：面粉、鸡蛋、糖、香草汁等。在这个比喻中，做蛋糕的食谱就是程序（即用适当形式描述的算法），计算机科学家就是处理器（CPU），而做蛋糕的各种原料就是输入数据。进程就是厨师阅读食谱、取来各种原料以及烘制蛋糕等一系列动作的总和。

现在假设计算机科学家的儿子哭着跑了进来，说他的头被一只蜜蜂蛰了。计算机科学家就记录下他照着食谱做到哪儿了（保存进程的当前状态），然后拿出一本急救手册，按照其中的指示处理蛰伤。这里，处理机从一个进程（做蛋糕）切换到另一个高优先级的进程（实施医疗救治），每个进程拥有各自的程序（食谱和急救手册）。当蜜蜂蛰伤处理完之后，这位计算机科学家又回来做蛋糕，从他离开时的那一步继续做下去。

这里的关键思想是：一个进程是某种类型的一个活动，它有程序、输入、输出以及状态。单个处理器可以被若干进程共享，它使用某种调度算法决定何时停止一个进程的工作，并转而为另一个进程提供服务。

值得注意的是，如果一个程序运行了两遍，则算作两个进程。例如，人们可能经常两次启动同一个字处理软件，或在有两个可用的打印机的情况下同时打印两个文件。像“两个进程恰好运行同一个程序”这样的事实其实无关紧要，因为它们是不同的进程。操作系统能够使它们共享代码，因此只有一个副本放在内存中，但那只是一个技术性的细节，不会改变有两个进程正在运行的概念。



##### 2.1.2	进程的创建

操作系统需要有一种方式来创建进程。一些非常简单的系统，即那种只为运行一个应用程序设计的系统（例如，微波炉中的控制器），可能在系统启动之时，以后所需要的所有进程都已存在。然而，在通用系统中，需要有某种方法在运行时按需要创建或撤销进程，现在开始考察这个问题。

4 种主要事件会导致进程的创建：

1. 系统初始化。

2. 正在运行的程序执行了创建进程的系统调用。

3. 用户请求创建一个新进程。

4. 一个批处理作业的初始化。

   

启动操作系统时，通常会创建若干个进程。其中有些是前台进程，也就是同用户（人类）交互并且替他们完成工作的那些进程。其他的是后台进程，这些进程与特定的用户没有关系，相反，却具有某些专门的功能。例如，设计一个后台进程来接收发来的电子邮件，这个进程在一天的大部分时间都在睡眠，但是当电子邮件到达时就突然被唤醒了。也可以设计另一个后台进程来接收对该机器中 Web 页面的访问请求，在请求到达时唤醒该进程以便服务该请求。停留在后台处理诸如电子邮件、Web 页面、新闻、打印之类活动的进程称为**守护进程**（daemon）。在大型系统中通常有很多守护进程。在 UNIX 中，可以用 ps 程序列出正在运行的进程；在 Windows 中，可使用任务管理器。

除了在启动阶段创建进程之外，新的进程也可以以后创建。一个正在运行的进程经常发出系统调用，以便创建一个或多个新进程协助其工作。在所要从事的工作可以容易地划分成若干相关的但没有相互作用的进程时，创建新的进程就特别有效果。例如，如果有大量的数据要通过网络调取并进行顺序处理，那么创建一个进程取数据，并把数据放入共享缓冲区中，而让第二个进程取走数据项并处理之，应该比较容易。在多处理机中，让每个进程在不同的CPU上运行会使整个作业运行得更快。

在交互式系统中，键入一个命令或者点（双）击一个图标就可以启动一个程序。这两个动作中的任何一个都会开始一个新的进程，并在其中运行所选择的程序。在基于命令行的 UNIX 系统中运行程序 X，新的进程会从该进程接管开启它的窗口。在 Microsoft Windows 中，多数情形都是这样的，在一个进程开始时，它并没有窗口，但是它可以创建一个（或多个）窗口。在 UNIX 和 Windows 系统中，用户可以同时打开多个窗口，每个窗口都运行一个进程。通过鼠标用户可以选择一个窗口并且与该进程交互，例如，在需要时提供输入。

最后一种创建进程的情形仅在大型机的批处理系统中应用。用户在这种系统中（可能是远程地）提交批处理作业。在操作系统认为有资源可运行另一个作业时，它创建一个新的进程，并运行其输入队列中的下一个作业。

从技术上看，在所有这些情形中，新进程都是由于一个已存在的进程执行了一个用于创建进程的系统调用而创建的。这个进程可以是一个运行的用户进程、一个由键盘或鼠标启动的系统进程或者一个批处理管理进程。这个进程所做的工作是，执行一个用来创建新进程的系统调用。这个系统调用通知操作系统创建一个新进程，并且直接或间接地指定在该进程中运行的程序。

在 UNIX 系统中，只有一个系统调用可以用来创建新进程：fork。这个系统调用会创建一个与调用进程相同的副本。在调用了 fork 后，这两个进程（父进程和子进程）拥有相同的内存映像、同样的环境字符串和同样的打开文件。这就是全部情形。通常，子进程接着执行 execve 或一个类似的系统调用，以修改其内存映像并运行一个新的程序。例如，当一个用户在 shell 中键入命令 sort 时，shell 就创建一个子进程，然后，这个子进程执行 sort。之所以要安排两步建立进程，是为了在 fork 之后但在 execve 之前允许该子进程处理其文件描述符，这样可以完成对标准输入文件、标准输出文件和标准错误文件的重定向。

在 Windows 中，情形正相反，一个 Win32 函数调用 CreateProcess 既处理进程的创建，也负责把正确的程序装入新的进程。该调用有 10 个参数，其中包括要执行的程序、输入给该程序的命令行参数、各种安全属性、有关打开的文件是否继承的控制位、优先级信息、该进程（若有的话）所需要创建的窗口规格以及指向一个结构的指针，在该结构中新创建进程的信息被返回给调用者。除了 CreateProcess，Win32 中有大约 100 个其他的函数用于处理进程的管理、同步以及相关的事务。

在 UNIX 和 Windows 中，进程创建之后，父进程和子进程有各自不同的地址空间。如果其中某个进程在其地址空间中修改了一个字，这个修改对其他进程而言是不可见的。在 UNIX 中，子进程的初始地址空间是父进程的一个副本，但是这里涉及两个不同的地址空间，不可写的内存区是共享的。某些 UNIX 的实现使程序正文在两者间共享，因为它不能被修改。或者子进程共享父进程的所有内存，但这种情况下内存通过**写时复制**（copy-on-write）共享，这意味着一旦两者之一想要修改部分内存，则这块内存首先被明确地复制，以确保修改发生在私有内存区域。再次强调，可写的内存是不可以共享的。但是，对于一个新创建的进程而言，确实有可能共享其创建者的其他资源，诸如打开的文件等。在 Windows 中，从一开始父进程和子进程的地址空间就是不同的。



##### 2.1.3	进程的终止

进程在创建之后，它开始运行，完成其工作。但永恒是不存在的，进程也一样。迟早这个新的进程会终止，通常由下列条件引起：

1. 正常退出（自愿的）。
2. 出错退出（自愿的）。
3. 严重错误（非自愿）。
4. 被其他进程杀死（非自愿）。

多数进程是由于完成了它们的工作而终止。当编译器完成了所给定程序的编译之后，编译器执行一个系统调用，通知操作系统它的工作已经完成。在 UNIX 中该调用是 exit，而在 Windows 中，相关的调用是 ExitProcess。面向屏幕的程序也支持自愿终止。字处理软件、Internet 浏览器和类似的程序中总有一个供用户点击的图标或菜单项，用来通知进程删除它所打开的任何临时文件，然后终止。

进程种植的第二个原因是进程发现了严重操作。例如，如果用户键入命令

cc foo.c

要编译程序 foo.c，但是该程序并不存在，于是编译器就会退出。在给出了错误参数时，面向屏幕的交互式进程通常并不退出。相反，这些程序会弹出要给对话框，并要求用户再试一次。

进程终止的第三个原因是由进程引起的错误，通常是由于程序中的错误所致。例如，执行了一条非法指令、引用不存在的内存，或除数是零等。有些系统中（如 UNIX），进程可以通知操作系统，它希望自行处理某些类型的错误，在这类错误中，进程会收到信号（被中断），而不是在这类错误出现时终止。

第四种终止进程的原因是，某个进程执行一个系统调用通知操作系统杀死某个其他进程。在 UNIX 中，这个系统调用是 kill。在 Win32 中对应的函数是 TerminateProcess。在这两种情形中，“杀手” 都必须获得确定的授权以便进行动作。在有些系统中，当一个进程终止时，不论是自愿的还是其他原因，由该进程所创建的所有进程也一律立即被杀死。不过，UNIX 和 Windows 都不是这种工作方式。



##### 2.1.4	进程的层次结构

某些系统中，当进程创建了另一个进程后，父进程和子进程就以某种形式继续保持关联。子进程自身可以创建更多的进程，组成一个进程的层次结构。请注意，这与植物和动物的有性繁殖不同，进程只有一个父进程（但是可以有零到多个子进程）。

在 UNIX 中，进程和它的所有子进程以及后裔共同组成一个进程组。当用户从键盘发出一个信号时，该信号被送给当前与键盘相关的进程组中的所有成员（它们通常是在当前窗口创建的所有活动进程）。每个进程可以分别捕获该信号、忽略该信号或采取默认的动作，即被该信号杀死。

这里有另一个例子，可以用来说明进程层次的作用，考虑 UNIX 在启动时如何初始化自己。一个称为 init 的特殊进程出现在启动映像中。当它开始运行时，读入一个说明终端数量的文件。接着，为每个终端创建一个新进程。这些进程等待用户登录。如果有一个用户登录成功，该登录进程就执行一个 shell 准备接收命令。所接收的这些命令会启动更多的进程，以此类推。这样，在整个系统中，所有的进程都属于以 init 为根的一棵树。

相反，Windows 中没有进程层次的概念，所有的进程都是地位相同的。唯一类似于进程层次的暗示是在创建进程的时候，父进程得到一个特别的令牌（称为**句柄**），该句柄可以用来控制子进程。但是，它有权把这个令牌传送给某个其他进程，这样就不存在进程层次了。在 UNIX 中，进程就不能剥夺其子继承的 “继承权”。



##### 2.1.5	进程的状态

尽管每个进程是一个独立的实体，有其自己的程序计数器和内部状态，但是，进程之间经常需要相互作用。一个进程的输出结构可能作为另一个进程的输入。在 shell 命令

cat chapter1 chapter2 chapter3 | grep tree

中，第一个进程运行 cat，将三个文件连接并输出。第二个进程运行 grep，它从输入中选择所有包含单词 “tree” 的那些行。根据这两个进程的相对速度（这取决于这两个程序的相对复杂度和各自所分配到的 CPU 时间），可能发生这种情况：grep 准备就绪可以运行，但输入还没有完成。于是必须阻塞 grep，直到输入到来。

当一个进程在逻辑上不能继续运行时，它就会被阻塞，典型的例子是它在等待可以使用的输入。还可能有这样的情况：一个概念上能够运行的进程被迫停止，因为操作系统调度另一个进程占用了 CPU。这两种情况是完全不同的。在第一种情况下，进程被迫挂起是程序自身固有的原因（在键入用户命令行之前，无法执行命令）。第二种情况则是由系统技术上的原因引起的（由于没有足够的 CPU，所以不能使每个进程都有一台私用的处理器）。在图 2-2 中可以看到显示进程的三种状态的状态图，这三种状态是：

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE25.jpg"/>
</div>



1. 运行态（该时刻进程实际占用 CPU）。
2. 就绪态（可运行，但因为其他进程正在运行而暂时停止）。
3. 阻塞态（除非某种外部事件发生，否则进程不能运行）。

前两种状态在逻辑上类似的。处于这两种状态的进程都可以运行，只是对于第二种状态暂时没有 CPU 分配给它。第三种状态与前两种状态不同，处于该状态的进程不能运行，即使 CPU 空闲也不行。

进程的三种状态之间有四种可能的转换关系。如图 2-2 所示。在操作系统发现进程不能继续运行下去时，发生转换 1。在某些系统中，进程可以执行一个诸如 pause 的系统调用来进入阻塞状态。在其他系统中，包括 UNIX，当一个进程从管道或设备文件（例如终端）读取数据时，如果没有有效的输入存在，则进程会被自动阻塞。

转换 2 和 3 是由进程调度程序引起的，进程调度程序是操作系统的一部分，进程甚至感觉不到调度程序的存在。系统认为一个运行进程占用处理器的时间已经过长，决定让其他进程使用 CPU 时间时，会发生转换 2。在系统已经让所有其他进程享有了它们应有的公平待遇而重新轮到第一个进程再次占用 CPU 时，会发生转换 3。调度程序的主要工作就是决定应当运行哪个进程、何时运行及它应该运行多长时间，这是很重要的一点，我们将在本章的后面部分进行讨论。明确已经提出了许多算法，这些算法力图在整体效率和进程的竞争公平性之间取得平衡。我们将在本章稍后部分研究其中的一些问题。

当进程等待的一个外部事件发生时（如一些输入到达），则发生转换 4。如果此时没有其他进程运行，则立即触发转换 3，该进程便开始运行。否则该进程将处于就绪态，等待 CPU 空闲并且轮到它运行。

使用进程模型使得我们易于想象系统内部的操作状况。一些进程正在运行执行用户键入命令所对应的程序。另一些进程是系统的一部分，它们的任务是完成下列一些工作：比如，执行文件服务请求、管理磁盘驱动器和磁带机的执行细节等。当发生一个磁盘中断时，系统会做出决定，停止运行当前进程，转而运行磁盘进程，该进程在此之前因等待中断而处于阻塞态。这样就可以不再考虑中断，而只是考虑用户进程、磁盘进程、终端进程等。这些进程在等待时总是处于阻塞整体。在已经读入磁盘或键入字符后，等待它们的进程就被接触阻塞，并成为可调度运行的进程。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE26.jpg"/>
</div>

从这个观点引出了图 2-3 所示的模型。在图 2-3 中，操作系统的最底层是调度程序，在它上面有许多进程。所有关于中断处理、启动进程和停止进程的具体细节都隐藏在调度程序中。实际上，调度程序是一段非常短小的程序。操作系统的其他部分被简单地组织成进程的形式。不过，很少有真实的系统是以这样的理想方式构造的。





##### 2.1.6	进程的实现

为了实现进程模型，操作系统维护着一张表格（一个结构数组），即**进程表**（process table）。每个进程占用一个进程表项。（有些作者称这些表项为**进程控制块**。）该表项包含了进程状态的重要信息，包括程序计数器、堆栈指针、内存分配状况、所打开文件的状态、账号和调度信息，以及其他在进程由运行态转换到就绪态或阻塞态时必须保存的信息，从而保证该进程随后能再次启动，就像从未被中断过一样。

图 2-4 中展示了在一个典型系统中的关键字段。第一列中的字段与进程管理有关。其他两列分别与存储管理和文件管理有关。应该注意到进程表中的字段是与系统密切相关的，不过该组给出了所需要信息的大致介绍。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE27.jpg"/>
</div>

在了解进程表后，就可以对在单个（或每一个）CPU 上如何维持多个顺序进程的错觉做更多的阐述。与每一 I/O 类关联的时一个称作**中断向量**（interrupt ）的位置（靠近内存底部的固定区域）。它包含中断服务程序的入口地址。假设当一个磁盘中断发生时，用户进程 3 正在运行，则中断硬件将程序计数器、程序状态字、有时还有一个或多个寄存器压入堆栈，计算机随即跳转到中断向量所指示的地址。这些是硬件完成的所有操作，然后软件，特别是中断服务例程就接管一切剩余的工作。

所有的中断都从保存寄存器开始，对于当前进程而言，通常是保存在进程表项中。随后，会从堆栈中删除由中断硬件机制存入堆栈的那部分信息，并将堆栈指针指向一个由进程处理程序所使用的临时堆栈。一些诸如保存寄存器值和设置堆栈指针等操作，无法用 C 语言这一类高级语言描述，所以这些操作通过一个短小的汇编语言例程来完成，通常该例程可以供所有的中断使用，因为无论中断是怎样引起的，有关保存寄存器的工作则是完全一样的。

当该例程结束后，它调用一个 C 过程处理某个特定的中断类型剩下的工作。（假定操作系统由 C 语言编写，通常这是所有真实操作系统的选择）。在完成有关工作之后，大概就会使某些进程就绪，接着调用调度程序，决定随后该运行哪个进程。随后将控制转给一段汇编语言代码，为当前的进程装入寄存器值以及内存映射并启动该进程运行。图 2-5 中总结了中断处理和调度的过程。值得注意的是，各种系统之间某些细节会有所不同。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE28.jpg"/>
</div>

一个进程在执行过程中可能被中断数千次，关键是每次中断后，被中断的进程都返回到与中断发生前完全相同的状态。



##### 2.1.7	多道程序设计模型

采用多道程序设计可以提高 CPU 的利用率。严格地说，如果进程用于计算的平均时间是进程在内存中停留时间的 20%，且内存中同时有 5 个进程，则 CPU 将一直满负载运行。然而，这个模型在现实中过于乐观，因为它假设这 5 个进程不会同时等待 I/O。

更好的模型是从概率的角度来看 CPU 的利用率。假设一个进程等待 I/O 操作的时间与其停留在内存中时间的比为 p。当内存中同时有 n 个进程时，则所有 n 个进程都在等待 I/O（此时 CPU 空转）的概率时 P^n^。CPU 的利用率由下面的公式给出：

CPU 利用率 = 1- P^n^

图 2-6 以 n 为变量的函数表示了 CPU 的利用率，n 称为**多道程序设计的道数**（degree of multiprogramming）。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE29.jpg"/>
</div>

从图 2-6 中可以清楚地看到，如果进程花费 80% 的时间等待 I/O，为使 CPU 的浪费低于 10%，至少要有 10 个进程同时在内存中。当读者认识到一个等待用户从终端输入的交互式进程是处于 I/O 等待状态时，那么很明显，80% 甚至更多的 I/O 等待时间是普遍的。即使是在服务器中，做大量磁盘 I/O 操作的进程也会花费同样或更多的等待时间。

从完全精确的角度考虑，应该指出此概率模型只是描述了一个大致的状况。它暗中假设了所有 n 个进程是独立的，即对某个系统来说，内存中的 5 个进程中，3 个运行，2 个等待，是完全可接受的（上面模型没有考虑进程间有关联会互相影响，相互依赖的情况）。但在单 CPU 中，不能同时运行 3 个进程，所以当 CPU 忙时，已就绪的进程也必须等待 CPU（就绪状态就是进程互相影响的情况）。因而，进程不是独立的。更精确的模型应该用排队论构建，但我们的模型（当进程就绪时，给进程分配 CPU，否则让 CPU 空转）仍然是有效的，即使真实曲线会与图 2-6 中所画的略有不同。

虽然图 2-6 的模型很简单、很粗略，它仍然对预测 CPU 的性能很有效。例如，假设计算机有 8GB 内存，操作系统及相关表格占用 2GB，每个用户程序也占用 2GB。这些内存空间允许 3 个用户程序同时驻留在内存中。若 80% 的时间用于 I/O 等待，则 CPU 的利用率（忽略操作系统开销）大约是 1 - 0.8^3^，即大约 49%。在增加 8GB 字节的内存后，可从 3 道程序设计提高到 7 道程序设计，因而 CPU 利用率提高到 79%，换言之，第二个 8GB 内存提高了 30% 的吞吐量。

增加第三个 8GB 内存只能将 CPU 利用率从 79% 提高到 91%，吞吐量的提高仅为 12%。通过这一模型，计算机用户可以确定，第一次增加内存是一个划算的投资，而第二个则不是。



#### 2.2	线程

在传统操作系统中，每个进程有一个地址空间和一个控制线程。事实上，这几乎就是进程的定义。不过，经常存在同一个地址空间中准并行运行多个控制线程的情形（准并行：几乎并行，
具有并行系统或设备的一些特性），这些线程就像（差不多）分离的进程（共享地址空间除外）。在下面各节中，我们将讨论这些情形及其实现。



##### 2.2.1	线程的使用

为什么人们需要在一个进程中再有一类进程？有若干理由说明产生这些迷你进程（称为**线程**）的必要性。下面我们来讨论其中一些理由。人们需要多线程的主要原因是，在许多应用中同时发生着多种活动。其中某些活动随着时间的推移会被阻塞。通过将这些应用程序分解成可以准并行运行的多个顺序线程，程序设计模型会变得更简单。

前面已经进行了有关讨论。准确地说，这正是之前关于进程模型的讨论。有了这样的抽象，我们才不必考虑中断、定时器和上下文切换，而只需考虑并行进程。类似地，只是在有了多线程概念之后，我们才加入了一种新的元素：并行实体拥有共享同一个地址空间和所有可用数据的能力。对于某些应用而言，这种能力是必需的，而这正是多进程模型（它们具有不同的地址空间）所无法表达的。

第二个关于需要多线程的理由是，由于线程比进程更轻量级，所以它们比进程更容易（即更快）创建，也更容易撤销。在许多系统中，创建一个线程较创建一个进程要快 10~100 倍。在有大量线程需要动态和快速修改时，具有这一特性是很有用的。

需要多线程的第三个原因涉及性能方面的讨论。若多个线程都是 CPU 密集型的，那么并不能获得性能上的增强，但是如果存在着大量的计算和大量的 I/O 处理，拥有多个线程允许这些活动彼此重叠进行，从而会加快应用程序执行的速度。

最后，在多 CPU 系统中，多线程是有益的，在这样的系统中，真正的并行有了实现的可能，第 8 章将讨论这个主题。

通过考察一些实际的例子，我们可以更清楚地看出引出多线程的好处。作为第一个例子，考察一个字处理软件。字处理软件通常按照出现在打印页上的格式在屏幕上精准显示文档。特别地，所有的行分隔符和页分隔符都在正确的最终位置上，这样在需要时用户可以检查和修改文档（比如，消除孤行—在一页上不完整的顶部行和底部行，因为这些行不甚美观）。

假设用户正在写一本书。从作者的观点来看，最容易的方法是把整本书作为一个文件，这样一来，查询内容、完成全局替换等都非常容易。另一种方法是，把每一章都处理成单独一个文件。但是，在把每个小节和子小节都分成单个的文件之后，若必须对全书进行全局的修改时，那就真是麻烦了，因为有成百个文件必须一个个地编辑。例如，如果所建议的某个标准××××正好在书付印之前被批准了，于是“标准草案××××”一类的字眼就必须改为“标准××××”。如果整本书是一个文件，那么只要一个命令就可以完成全部的替换处理。相反，如果一本书分成了300个文件，那么就必须分别对每个文件进行编辑。

现在考虑，如果有一个用户突然在一个有 800 页的文件的第一页上删掉了一个语句之后，会发生什么情形。在检查了所修改的页面并确认正确后，这个用户现在打算接着在第 600 页上进行另一个修改，并键入一条命令通知字处理软件转到该页面（可能要查阅只在那里出现的一个短语）。于是字处理软件被强制对整本书的前 600 页重新进行格式处理，这是因为在排列该页前面的所有页面之前，字处理软件并不知道第 600 页的第一行应该在哪里。而在第 600 页的页面可以真正在屏幕上显示出来之前，计算机可能要拖延相当一段时间，从而令用户不甚满意。

多线程可以在这里发挥作用。假设字处理软件倍编写成含有两个线程的程序。一个线程与用户交互，而另一个在后台重新进行格式处理。一旦在第 1 页中的语句被删除掉，交互线程就立即通知格式化线程对整本书重新进行处理。同时，交互线程继续监控键盘和鼠标，并响应诸如滚动第 1 页之类的简单命令，此可，另一个线程正在后台疯狂地运算。如果有点运气的话，重新格式化会在用户请求查看第 600 页之前完成，这样，第 600 页页面就立即可以在屏幕上显示出来。

如果已经做到了这一步，那么为什么不再进一步增加一个线程呢？许多字处理软件都有每隔若干分钟自动在磁盘上保存整个文件的特点，用于避免由于程序崩溃、系统崩溃或电源故障而造成用户一整天的工作丢失的情况。第三个线程可以处理磁盘备份，而不必干扰其他两个线程。拥有三个线程的情形，如图 2-7 所示。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE30.jpg"/>
</div>

如果程序是单线程的，那么在进行磁盘备份时，来自磁盘和鼠标的命令就会被忽略，直到备份工作完成为止。用户读入会认为性能很差。另一个方法是，为了获得好的性能，可以让键盘和鼠标事件中断磁盘备份，但这样却引入了复杂的中断驱动程序设计模型。如果使用三个线程，程序设计模型就很简单了。第一个线程只是和用户交互；第二个线程在得到通知时进行文档的重新格式化；第三个线程周期性地将 RAM 中的内容写道磁盘上。

很显然，在这里用三个不同地进程是不能工作地，这是因为这三个线程都需要对同一个文件进行操作。由于多个线程可以共享公共内存，所以通过用三个线程替换三个进程，使得它们可以访问同一个正在编辑的文件，而三个进程是做不到的。

许多其他的交互式程序中也存在类似的情形。例如，电子表格是允许用户维护矩阵的一种程序，矩阵中的一些元素是用户提供的数据；另一些元素是通过所输入的数据运用可能比较复杂的公式而得出的计算结果。当用户改变一个元素时，许多其他元素就必须重新计算。通过一个后台线程进行重新计算的方式，交互式线程就能够在进行计算的时候，让用户从事更多的工作。类似地，第三个线程可以在磁盘上进行周期性的备份工作。

现在考虑另一个多线程发挥作用的例子：一个万维网服务器。对页面的请求发给服务器，而所请求的页面发回给客户机。在多数 Web 站点上，某些页面较其他页面相比，有更多的访问。例如，对 Sony 主页的访问就远远超过对深藏在页面树里的任何特定摄像机的技术说明书页面的访问。利用这一事实，Web 服务器可以把获得大量访问的页面集合保存在内存中，避免到磁盘去调入这些页面，从而改善性能。这样的一种页面集合称为**高速缓存**（cache），高速缓存也运用在其他许多场合中。例如在第 1 章中介绍的 CPU 缓存。

一种组织 Web 服务器的方式如图 2-8 所示。在这里，一个称为**分派程序**（dispatcher）的线程从网络中读入工作请求。在检查请求之后，分派线程挑选一个空转的（即被阻塞的）**工作线程**（worker thread），提交该请求，通常是在每个线程所配有的某个专门字中写入一个消息指针。接着分派线程唤醒睡眠的工作线程，将它从阻塞状态转为就绪状态。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE39.jpg"/>
</div>

在工作线程被唤醒之后，它检查有关的请求是否在 Web 页面高速缓存之中，这个高速缓存是所有线程都可以访问的。如果没有，该线程开始一个从磁盘调入页面的 read 操作，并且阻塞直到该磁盘操作完成。当上述线程阻塞在磁盘操作上时，为了完成更多的工作，分派线程可能挑选另一个线程运行，也可能把另一个当前就绪的工作线程投入运行。

这种模型允许把服务器编写为顺序线程的一个集合。在分派线程的程序中包含一个无限循环，该循环用来获得工作请求并且把工作请求派给工作线程。每个工作线程的代码包含一个从分派线程接收请求，并且检查 Web 高速缓存中是否存在所需页面的无限循环。如果存在，就将该页面返回给客户机，接着该工作线程阻塞，等待一个新的请求。如果没有，工作线程就从磁盘调入该页面，将该页面返回给客户机，然后该工作线程阻塞，等待一个新的请求。

图 2-9 给出了有关代码的大致框架。如同本书的其他部分一样，这里假设 TRUE 为常数 1。另外，buf 和 page 分别是保存工作请求和 Web 页面的相应结构。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE31.jpg"/>
</div>

现在考虑在没有多线程的情形下，如何编写 Web 服务器。一种可能的方式是，使其像一个线程一样运行。Web 服务器的主循环获得请求，检查请求，并且在取下一个请求之前完成整个工作。在等待磁盘操作时，服务器就空转，并且不处理任何到来的其他请求。如果该 Web 服务器运行在唯一的机器上，通常情形都是这样，那么在等待磁盘操作时 CPU 只能空转。结果导致每秒钟只有很少的请求被处理。可见线程较好地改善了 Web 服务器的性能，而且每个线程都是按通常方式顺序编程的。

到现在为止，我们有了两个可能的设计方案：多线程Web服务器和单线程Web服务器。假设没有多线程可用，而系统设计者又认为由于单线程所造成的性能降低是不能接受的，那么如果可以使用read系统调用的非阻塞版本，还存在第三种可能的设计。在请求到来时，这个唯一的线程对请求进行考察。如果该请求能够在高速缓存中得到满足，那么一切都好，如果不能，则启动一个非阻塞的磁盘操作。

服务器在表格中记录当前请求的状态，然后去处理下一个事件。下一个事件可能是一个新工作的请求，或是磁盘对先前操作的回答。如果是新工作的请求，就开始该工作。如果是磁盘的回答，就从表格中取出对应的信息，并处理该回答。对于非阻塞磁盘I/O而言，这种回答多数会以信号或中断的形式出现。

在这一设计中，前面两个例子中的“顺序进程”模型消失了。每次服务器从为某个请求工作的状态切换到另一个状态时，都必须显式地保存或重新装入相应的计算状态。事实上，我们以一种困难的方式模拟了线程及其堆栈。这里，每个计算都有一个被保存的状态，存在一个会发生且使得相关状态发生改变的事件集合，我们把这类设计称为有限状态机（finite-state machine）。有限状态机这一概念广泛地应用在计算机科学中。

现在很清楚多线程必须提供的是什么了。多线程使得顺序进程的思想得以保留下来，这种顺序进程阻塞了系统调用（如磁盘 I/O），但是仍旧实现了并行性。对系统调用进行阻塞使程序设计变的较为简单，而且并行性改善了性能。单线程服务器虽然保留了阻塞系统调用的简易性，但是却放弃了性能。第三种处理方法运用了非阻塞调用和中断，通过并行性实现了高性能，但是给编程增加了困难。在图 2-10 中给出了上述模式的总结。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE32.jpg"/>
</div>

有关多线程作用的第三个例子是那些必须处理极大量数据的应用。通常的处理方式是，读进一块数据，对其处理，然后再写出数据。这里的问题是，如果只能使用阻塞系统调用，那么在数据进入和数据输出时，会阻塞进程。在有大量计算需要处理的时候，让 CPU 空转显然是浪费，应该尽可能避免。

多线程提供了一种解决方案，有关的进程可以用一个输入线程、一个处理线程和一个输出线程构造。输入线程把数据读入到输入缓冲区中；处理线程从输入缓冲区中取出数据，处理数据，并把结果放到输出缓冲区中；输出线程把这些结果写到磁盘上。按照这种工作方式，输入、处理和输出可以全部同时进行。当然，这种模型只有当系统调用只阻塞调用线程而不是阻塞整个进程时，才能正常工作。



##### 2.2.2	经典的线程模型

既然已经清楚为什么线程会有用以及如何使用它们，不如让我们用更进一步的眼光来审查一下上面的想法。进程模型基于两种独立的概念：资源分组处理与执行。有时，将这两种概念区分开来会更好，这就引入了 “线程” 这一概念。下面先介绍经典的线程模型；之后我们会来研究 “模糊进程与线程分界线” 的 Linux 线程模型。

理解进程的另一个角度是，用某种方法把相关的资源集中在一起。进程有存放程序正文和数据以及其他资源的地址空间。这些资源中包括打开的文件、子进程、即将发生的定时器、信号处理程序、账号信息等。把它们都放到进程中可以更容易管理。

另一个概念是，进程拥有一个执行的线程，通常简写为**线程**（thread）。在线程中有一个程序计数器，用来记录接着要执行哪一条指令。线程拥有寄存器，用来保存线程当前的工作变量。线程还拥有一个堆栈，用来记录执行历史，其中每一帧保存了一个已调用的但是还没有从中返回的过程。尽管线程必须在某个进程中执行，但是线程和它的进程是不同的概念，并且可以分别处理。进程用于把资源集中到一起，而线程则是在 CPU 上被调度执行的实体。

线程给进程模型增加了一项内容，即在同一个进程环境中，允许彼此之间有较大独立性的多个线程执行。在同一个进程中并行运行多个线程，是对在同一台计算机上并行运行多个进程的模拟。在前一种情形下，多个线程共享同一个地址空间和其他资源。而在后一种情形中，多个进程共享物理内存、磁盘、打印机和其他资源。由于线程具有进程的某些性质，所以有时被称为**轻量级进程**（lightweight process）。**多线程**这个术语，也用来描述在同一个进程中允许多个线程的情形。正如在第 1 章中看到的，一些 CPU 已经有直接硬件支持多线程，并允许线程切换在纳秒级完成。

在图 2-11a 中，可以看到三个传统的进程。每个进程有自己的地址空间和单个控制线程。相反，在图 2-11b 中，可以看到一个进程带有三个控制线程。尽管在两种情形中都有三个先后从，但是在图 2-11a 中，每一个线程都在不同的地址空间中允许，而在图 2-11b 中，这三个线程全部在相同的地址空间中运行。

当多线程进程在单 CPU 系统中运行时，线程轮流运行。从图 2-1 中，我们已经看到了进程的多道程序设计是如何工作的。通过在多个进程之间来回切换，系统制造了不同的顺序进程并行运行的假象，好似它们在一个比实际 CPU 慢一些的 CPU 上同时运行。在一个有三个计算密集型线程的进程中，线程以并行方式运行，每个线程在一个 CPU 上得到了真实 CPU 速度的三分之一。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE33.jpg"/>
</div>

进程中的不同线程不像不同进程之间那样存在很大的独立性。所有的线程都有完全一样的地址空间，这意味着它们也共享同样的全局变量。由于各个线程都可以访问进程地址空间中的每一个内存地址，所以一个线程可以读、写或甚至清除另一个线程的堆栈。线程之间是没有保护的，原因是：1）不可能，2）也没有必要。这与不同进程是有差别的。不同的进程会来自不同的用户，它们彼此之间可能有敌意，一个进程总是由某个用户所拥有，该用户创建多个线程应该是为了它们之间的合作而不是彼此间争斗。 除了共享地址空间之外，所有线程还共享同一个打开文件集、子进程、定时器以及相关信号等，如图 2-12 所示。这样，对于三个没有关系的线程而言，应该使用图 2-11a 的结构，而在三个线程实际完成同一个作业，并彼此积极密切合作的情形中，图 2-11b 则比较合适。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE34.jpg"/>
</div>

图 2-12 中，第一列表项是进程的属性，而不是线程的属性。例如，如果一个线程打开了一个文件，该文件对该进程中的其他线程都可见，这些线程可以对该文件进行读写。由于资源管理的单位是进程而非线程，所以这种情形是合理的。如果每个线程都有其自己的地址空间、打开文件、即将发生的定时器等，那么它们就应该是不同的进程了。线程概念试图实现的是，共享一组资源的多个线程的执行能力，以便这些线程可以为完成某一任务而共同工作。

和传统进程一样（即只有一个线程的进程），线程可以处于若干种状态的任何一个：运行、阻塞、就绪或终止。正在运行的线程拥有CPU并且是活跃的。被阻塞的线程正在等待某个释放它的事件。例如，当一个线程执行从键盘读入数据的系统调用时，该线程就被阻塞直到键入了输入为止。线程可以被阻塞，以便等待某个外部事件的发生或者等待其他线程来释放它。就绪线程可被调度运行，并且只要轮到它就很快可以运行。线程状态之间的转换和进程状态之间的转换是一样的，如图 2-2 所示。

认识到每个线程有其自己的堆栈很重要，如图 2-13 所示。每个线程的堆栈有一帧，供各个被调用但是还没有从中返回的过程使用。在该栈帧中存放了相应过程的局部变量以及过程调用完成之后使用的返回地址。例如，如果过程 X 调用过程 Y，而 Y 又调用 Z，那么当 Z 执行时，供 X、Y 和 Z 使用的栈帧会全部存在堆栈中。通常每个线程会调用不同的过程，从而有一个各自不同的执行历史，这就是为什么每个线程需要有自己的堆栈的原因。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE35.jpg"/>
</div>

在多线程的情况下，进程通常会从当前的单个线程开始。这个线程有能力通过调用一个库函数（如 thread_create）创建新的线程。thread_create 的参数专门指定了新线程要运行的过程名。这里，没有必要对新线程的地址空间加以规定，因为新线程会自动在创建线程的地址空间中运行。有时，线程是有层次的，它们具有一种父子关系，但是，通常不存在这样一种关系，所有的线程都是平等的。不论有无层次关系，创建线程通常都返回一个线程标识符，该标识符就是新线程的名字。

当一个线程完成工作后，可以通过调用一个库过程（如 thread_exit）退出。该线程接着消失，不再可调度。在某些线程系统中，通过调用一个过程，例如 thread_join，一个线程可以等待一个（特定）线程退出。这个过程阻塞调用线程直到那个（特定）线程退出。 在这种情况下，线程的创建和终止非常类似于进程的创建和终止，并且也有着同样的选项。

另一个常见的线程调用是 thread_yield，它允许线程自动放弃 CPU 从而让另一个线程运行。这样一个调用是很重要的，因为不同于进程，（线程库）无法利用时钟中断强制线程让出 CPU。所以设法使线程行为 “高尚” 起来，并且随着时间的推移自动交出 CPU，以便让其他线程有机会运行，就变得非常重要。有的调用允许某个线程等待另一个线程完成某些任务，或等待一个线程宣称它已经完成了有关的工作等。

通常而言，线程是有益的，但是线程也在程序设计模式中引入了某种程度的复杂性。考虑一下 UNIX 中的 fork 系统调用。如果父进程有多个线程，那么它的子进程也应该拥有这些线程吗？如果不是，则该子进程可能会工作不正常，因为这些线程可能是必不可少的。

然而，如果子进程拥有了与父进程一样的多个线程，如果父进程在 read 系统调用（比如键盘）上被阻塞了会发生什么情况？是两个线程被阻塞在键盘上（一个属于父进程，另一个属于子进程）吗？在键入一行输入之后，这两个线程都得到该输入的副本吗？还是仅有父进程得到该输入的副本？或是仅有子进程得到？类似的问题在进行网络连接时也会出现。

另一类问题和线程共享许多数据结构的事实有关。如果一个线程关闭了某个文件，而另一个线程还在该文件上进行读操作时会怎样？假设有一个线程注意到几乎没有内存了，并开始分配更多的内存。在工作一半的时候，发生线程切换，新线程也注意到几乎没有内存了，并且也开始分配更多的内存。这样，内存可能会被分配两次。不过这些问题通过努力是可以解决的。总之，要使多线程的程序正确工作，就需要仔细思考和设计。



##### 2.2.3	POSIX 线程

为实现可移植的线程程序，IEEE 在 IEEE 标准 1003.1c 中定义了线程的标准。它定义的线程包叫作 pthread。大部分 UNIX 系统都支持该标准。这个标准定义了超过 60 个函数调用，如果在这里列举一遍就太多了。这里仅描述一些主要的函数，以说明它是如何工作的。图 2-14 中列举了这些函数调用。

所有 pthread 线程都有某些特性。每一个都含有一个标识符、一组寄存器（包括程序计数器）和一组存储在结构中的属性。这些属性包括堆栈大小、调度参数以及其他线程需要的项目。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE36.jpg"/>
</div>

创建一个新线程需要使用 pthread_create 调用。新创建的线程的线程标识符会作为函数值返回。这种调用有意看起来很像 fork 系统调用，其中线程标识符起着 PID 的作用，而这么做的目的主要是为了标识在其他调用中引用的线程。

当一个线程完成分配给它的工作时，可以通过调用 pthread_exit 来终止。这个调用终止该线程并释放它的栈。

一般一个线程在继续运行前需要等待另一个线程完成它的工作并退出。可以通过 pthread_join 线程调用来等待别的特定线程的终止。而要等待线程的线程标识符作为一个参数给出。

有时会出现这种情况：一个线程逻辑上没有阻塞，但感觉上它已经运行了足够长时间并且希望给另外一个线程机会去运行。这时可以通过调用 pthread_yield 完成这一目标。而进程中没有这种调用，因为假设进程间会有激烈的竞争性，并且每一个进程都希望获得它所能得到的所有的CPU时间。但是，由于同一进程中的线程可以同时工作，并且它们的代码总是由同一个程序员编写的，因此，有时程序员希望它们能互相给对方一些机会去运行。

下面两个线程调用是处理属性的。pthread_attr_init 建立关联一个线程的属性结构并初始化成默认值。这些值（例如优先级）可以通过修改属性结构中的域值来改变。

最后，pthread_attr_destroy 删除一个线程的属性结构，释放它占用的内存。它不会影响调用它的线程。这些线程会继续存在。

为了更好地了解 pthread 是如何工作的，考虑图 2-15 提供的简单例子。这里主程序在宣布它的意图之后，循环 NUMBER_OF_THREADS 次，每次创建一个新的线程。如果线程创建失败，会打印出一条错误信息然后退出。在创建完所有线程之后，主程序退出。

当创建一个线程时，它打印一条一行的发布信息，然后退出。这些不同信息交错的顺序是不确定的，并且可能在连续运行程序的情况下发生变化。

pthread 调用不只是前面介绍的这几个，还有许多的pthread调用会在讨论“进程与线程同步”之后再介绍。



##### 2.2.4	在用户空间中实现线程

有两种主要的方法实现线程包：在用户空间中和在内核中。这两种方法的选择有点争议，混合实现也是可能的。我们现在介绍这些方法，并分析它们的优点和缺点。

第一种方法是把整个线程包放在用户空间中，内核对线程包一无所知。从内核角度考虑，就是按正常的方式管理，即单线程进程。这种方法第一个也是最明显的优点是，用户级线程包可以在不支持线程的操作系统上实现。过去所有的操作系统都属于这个范围，即使现在也有一些操作系统还是不支持线程。通过这一方法，可以用函数库实现线程。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE37.jpg"/>
</div>

所有的这类实现都有同样的通过结构，如图 2-16a 所示。线程在一个运行时系统的上层运行，该运行系统是一个管理线程的过程的集合。前面已经介绍过其中的四个过程：pthread_create，pthread_exit，pthread_join和pthread_yield。不过，一般还会有更多的过程。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE38.jpg"/>
</div>

在用户空间管理线程时，每个进程需要有其专用的**线程表**（thread table），用来跟踪该进程中的线程。这些表和内核中的进程表类似，不过它仅仅记录各个线程的属性，如每个线程的程序计数器、堆栈指针、寄存器和状态等。该线程表由运行时系统管理。当一个线程转换到就绪状态或阻塞状态时，在该线程表中存放重新启动该线程所需的信息，与内核在进程表中存放进程的信息完全一样。

当某个线程做了一些会引起在本地阻塞的事情之后，例如，等待进程中另一个线程完成某项工作，它调用一个**运行时系统**的过程，这个过程检查该线程是否必须进入阻塞状态。如果是，它在线程表中保存该线程的寄存器（即它本身的），查看表中可运行的就绪线程，并把新线程的保存值重新装入机器的寄存器中。只要堆栈指针和程序计数器（program
counter，IP）一被切换，新的线程就又自动投入运行。如果机器有一条保存所有寄存器的指令和另一条装入全部寄存器的指令，那么整个线程的切换可以在几条指令内完成。进行类似于这样的线程切换至少比陷入内核要快一个数量级（或许更多），这是使用用户级线程包的一个强有力的理由。

不过，线程与进程有一个关键的差别。在线程完成运行时，例如，在它调用 thread_yield 时，thread_yield 代码可以把该线程的信息保存在线程表中，进而，它可以调用线程调度程序来选择另一个要运行的线程。保存该线程状态的过程和使用的调度程序都只是本地过程，所以启动它们比进行内核调用效率更高。另一方面，不需要陷入内核，不需要上下文切换，也不需要对内存高速缓存进行刷新，这就使得线程调度非常快捷。

用户级线程还有其他优点。它允许每个进程都有自己定制的调度算法。例如，在某些应用程序中，那些有垃圾收集线程的应用程序就不用担心线程会在不合适的时刻停止，这是一个长处。用户级线程还具有较好的可扩展性，这是因为在内核空间中内核线程始终需要一些固定表格空间和堆栈空间，如果内核线程的数量非常大，就会出现问题（线程能够利用的表空间和堆栈空间比内核级线程多）。

尽管用户级线程包有更好的性能，但它也存在一些明显的问题。其中第一个问题是如何实现阻塞系统调用。假设在还没有任何击键之前，一个线程读取键盘。让该线程实际进行该系统调用是不可接受的，因为这会停止所有的线程。使用线程的一个主要目标是，首先要允许每个线程使用阻塞调用，但是还要避免被阻塞的线程影响其他的线程。通过阻塞系统调用，这个目标不是轻易地能够实现的。

系统调用可以全部改成非阻塞的（例如，如果没有被缓冲的字符，对键盘的 read 操作可以只返回 0 字节），但是这需要修改操作系统，所以这个办法也不吸引人。而且，用户级线程的一个长处就是它可以在现有的操作系统上运行。另外，改变 read 操作的语义需要修改许多用户程序。

在这个过程中，还有一种可能的替代方案，就是如果某个调用会阻塞，就提前通知。在某些 UNIX 版本中，有一个系统调用 select 可以允许调用者通知预期的 read 是否会阻塞。若有这个调用，那么库过程 read 就可以被新的操作替代，首先进行 select 调用，然后只有在安全的情形下（即不会阻塞）才进行 read 调用。如果 read 调用会被阻塞，有关的调用就不进行，代之以运行另一个线程。到了下次有关的运行系统取得控制权之后，就可以再次检查看看现在进行read调用是否安全。这个处理方法需要重写部分系统调用库，所以效率不高也不优雅，不过没有其他的可选方案了。在系统调用周围从事检查的这类代码称为**包装器**（**jacket** 或 **wrapper**）。

与阻塞系统调用问题有些类似的是断页中断问题，我们将在第 3 章讨论这些问题。此刻可以认为，把计算机设置成这样一种工作方式，即并不是所有的程序都一次性放在内存中共。如果某个程序调用或者跳转到了一条不在内存的指令上，就会发生页面故障，而操作系统将到磁盘上取回这个丢失的指令（和该指令的“邻居们”），这就称为页面故障。在对所需的指令进行定位和读入时，相关的进程就被阻塞。如果有一个线程引起页面故障，内核由于甚至不知道有线程存在，通常会把整个进程阻塞直到磁盘 I/O 完成为止，尽管其他的线程是可以运行的。

用户级线程包的另一个问题是，如果一个线程开始运行，那么在该进程中的其他线程就不能运行，除非第一个线程自动放弃 CPU。在一个单独的进程内部，没有时钟中断，所以不可能用轮转调度（轮流）的方式调度线程。除非某个线程能够按照自己的意志进入运行时系统，否则调度程序就没有任何机会。

对线程永久运行问题的一个可能的解决方案是让运行时系统每秒请求一次时钟信号（中断）以对其进行控制，但是这样也很生硬且难以编写程序。不可能总是高频率地发生周期性的时钟中断，即使可能，总的开销也是可观的。而且，线程可能也需要时钟中断，这就会扰乱运行时系统使用的时钟。

**再者，也许针对用户级线程的最大负面争论意见是，程序员通常在经常发生线程阻塞的应用中才希望使用多个线程。**例如，在多线程 Web 服务器里。这些线程持续地进行系统调用，而一旦发生内核陷阱进行系统调用，如果原有的线程已经阻塞，就很难让内核进行线程的切换，如果要让内核消除这种情形，就要持续进行 select 系统调用，以便检查 read 系统调用是否安全。对于那些基本上是 CPU 密集型而且极少有阻塞的应用程序而言，使用多线程的目的又何在呢？由于这样的做法并不能得到任何益处，所以没有人会真正提出使用多线程来计算前 n 个素数或者下象棋等一类工作。



##### 2.2.5	在内核中实现线程

现在考虑内核支持和管理线程的情形。如图 2-16b 所示，此时不再需要运行时系统了。另外，每个进程中也没有线程表。相反，在内核中有用来记录系统中所有线程的线程表。当某个线程希望创建一个新线程或者撤销一个已有线程时，它进行一个系统调用，这个系统调用通过对线程表的更新完成线程创建或撤销工作。

内核的线程表保存了每个线程的寄存器、状态和其他信息。这些信息和在用户空间中（在运行时系统中）的线程是一样的，但是现在保存在内核中。这些信息是传统内核所维护的每个单线程进程信息（即进程状态）的子集。另外，内核还维护了传统的进程表，以便跟踪进程的状态。

所有能够阻塞线程的调用都以系统调用的形式实现，这与调用一个运行时系统的过程相比，代价是相当可观的。当一个线程阻塞时，内核根据其选择，可以运行同一个进程中的另一个线程（若有一个就绪线程）或者运行另一个进程中的线程。而在用户级线程中，运行时系统始终运行自己进程中的线程，直到内核剥夺它的 CPU（或者没有可运行的线程存在了）为止。

由于在内核中创建或撤销线程的代价比较大，某些系统采取 “环保” 的处理方式，回收其线程。当某个线程被撤销时，就把它标志为不可运行的，但是其内核数据结构没有受到影响。稍后，在必须创建一个新线程时，就重新启动某个旧线程，从而节省了一些开销。在用户级线程中线程回收也是可能的，但是由于其线程管理的代价很小，所以没有必要进行这项工作。

内核线程不需要任何新的、非阻塞系统调用。另外，如果某个进程中的线程引起了页面故障，内核可以很方便地检查该进程是否有任何其他可运行的线程，如果有，在等待所需要的页面从磁盘读入时，就选择一个可运行的线程运行。这样做的主要缺点是系统调用的代价比较大，所以如果线程的操作（创建、终止等）比较多，就会带来很大的开销。

虽然使用内核线程可以解决很多问题，但是也不会解决所有的问题。例如，当一个多线程进程创建新的进程时，会发生什么？新进程是拥有与原进程相同数量的线程，还是只有一个线程？在很多情况下，最好的选择取决于进程计划下一步做什么。如果它要调用 exec 来启动一个新的程序，或许一个线程是正确的选择；但是如果它继续执行，则最好复制所有的线程。



##### 2.2.6	混合实现

人们已经研究了各种试图将用户级线程的优点和内核级线程的优点结合起来的方法。一种方法是使用内核级线程，然后将用户级线程与某些或者全部内核线程多路复用起来，如图 2-17 所示。如果采用这种方法，编程人员可以决定有多少个内核级线程和多少个用户级线程彼此多路复用。这一模型带来最大的灵活度。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE40.jpg"/>
</div>

采用这种方法，内核只识别内核级线程，并对这些线程进行调度。这些线程中的某些线程可能具有多个在它们之上复用的用户级线程。 这些用户级线程的创建，销毁和调度就像在没有多线程功能的操作系统上运行的进程中的用户级线程一样。 在此模型中，每个内核级线程都有一组轮流使用它的用户级线程。



##### 2.2.7	调度程序激活机制

尽管内核级线程在一些关键点上优于用户级线程，但无可争议的是内核级线程的速度慢。因此，研究人员一直在寻找在保持其优良特性的前提下改进其速度的方法。下面将介绍 Anderson 等人（1992）设计的一种方法，称为**调度程序激活**（scheduler activation）机制。Edler 等人（1988）以及 Scott 等人（1990）就相关的工作进行了深入讨论。

调度程序激活工作的目标是模拟内核线程的功能，但是为线程包提供通常在用户空间中才能实现的更好的性能和更大的灵活性。特别地，如果用户线程从事某种系统调用时是安全的，那就不应该进行专门的非阻塞调用或者进行提前检查。无论如何，如果线程阻塞在某个系统调用或页面故障上，只要在同一个进程中有任何就绪的其他线程，就应该可以运行这些其他线程。

由于避免了在用户空间和内核空间之间的不必要转换，从而提高了效率。例如，如果某个线程由于等待另一个线程的工作而阻塞，此时没有理由请求内核，这样就减少了内核-用户转换的开销。用户空间的运行时系统可以阻塞同步的线程而另外调度一个新线程。

当使用调度程序激活机制时，内核给每个进程安排一定数量的虚拟处理器，并且让（用户空间）运行时系统将线程分配到处理器上。这一机制也可以用在多处理器中，此时虚拟处理器可能成为真实的 CPU。分配给一个进程的虚拟处理器的初始数量是一个，但是该进程可以申请更多的处理器并且在不用时退回。内核也可以取回已经分配出去的虚拟处理器，以便把它们分给需要更多处理器的进程。

使该机制工作的基本思路是，当内核了解到一个线程被阻塞之后（例如，由于执行了一个阻塞系统调用或者产生了一个页面故障），内核通知该进程的运行时系统，并且在堆栈中以参数形式传递有问题的线程编号和所发生事件的一个描述。内核通过在一个已知的起始地址启动运行时系统，从而发出了通知，这是对 UNIX 中信号的一种粗略模拟。这个机制称为**上行调用**（upcall）。

一旦如此激活，运行时系统就重新调度其线程，这个过程通常是这样的：把当前线程标记为阻塞并从就绪表中取出另一个线程，设置其寄存器，然后再启动之。稍后，当内核知道原来的线程又可运行时（例如，原先试图读取的管道中有了数据，或者已经从磁盘中读入了故障的页面），内核就又一次上行调用运行时系统，通知它这一事件。此时该运行时系统按照自己的判断，或者立即重启动被阻塞的线程，或者把它放入就绪表中稍后运行。

在某个用户线程运行的同时发生一个硬件中断时，被中断的 CPU 切换进内核态。如果被中断的进程对引起该中断的事件不感兴趣，比如，是另一个进程的 I/O 完成了，那么在中断处理程序结束之后，就把被中断的线程恢复到中断之前的状态。不过，如果该进程对中断感兴趣，比如，是该进程中的某个线程所需要的页面到达了，那么被中断的线程就不再启动，代之为挂起被中断的线程。而运行时系统则启动对应的虚拟 CPU，此时被中断线程的状态保存在堆栈中。随后，运行时系统决定在该 CPU 上调度哪个线程：被中断的线程、新就绪的线程还是某个第三种选择。

调度程序激活机制的一个目标是作为上行调用的信赖基础，这是一种违反分层次系统内在结构的概念。通常，n 层提供 n + 1 层可调用的特定服务，但是 n 层不能调用 n + 1 层中的过程。上行调用并不遵守这个基本原理。



##### 2.2.8	弹出式线程

在分布式系统中经常使用线程。一个有意义的例子是如何处理到来的消息，例如服务请求。传统的方法是将进程或线程阻塞在一个 recieve 系统调用上，等待消息到来。当消息到达时，该系统调用接收消息，并打开消息检查其内容，然后进行处理。

不过，也可能有另一种完全不同的处理方式，在该处理方式中，一个消息的到达导致系统创建一个处理该消息的线程，这种线程称为**弹出式线程**，如图 2-18 所示。弹出式线程的关键好处是，由于这种线程相当新，没有历史——没有必须存储的寄存器、堆栈诸如此类的内容，每个线程从全新开始，每一个线程彼此之间都完全一样。这样，就有可能快速创建这类线程。对该新线程指定所要处理的消息。使用弹出式线程的结果是，消息到达与处理开始之间的时间非常短。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE41.jpg"/>
</div>

在使用弹出式线程之前，需要提前进行计划。例如，线程在哪个进程中运行？如果系统支持在内核上下文中运行线程，线程就有可能在那里运行（这是图 2-18 中没有画出内核的原因）。在内核空间中运行弹出式线程通常比在用户空间中容易且快捷，而且内核空间中的弹出式线程可以很容易访问所有的内核表格和 I/O 设备，这些也许在中断处理时有用。而另一方面，出错的内核线程会比出错的用户线程造成更大的损害。例如，如果某个线程运行时间太长，又没有办法抢占它，就可能造成进来的信息永久丢失。



##### 2.2.9	使单线程代码多线程化

许多已有的程序是为单线程进行编写的。把这些改写成多线程需要比直接写多线程程序更高的技巧。下面考察一些其中易犯的错误。

先考察代码，一个线程的代码就像进程一样，通常包含多个过程，会有局部变量、全局变量和过程参数。局部变量和参数不会引起任何问题，但是有一个问题是，对线程而言是全局变量，并不是对整个程序也是全局的。有许多变量之所以是全局的，是因为线程中的许多过程都使用它们（如同它们也可能使用任何全局变量一样），但是其他线程在逻辑上和这些变量无关。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE42.jpg"/>
</div>

作为一个例子，考虑由 UNIX 维护的 errno 变量。当进程（或线程）进行系统调用失败时，错误码会放入 errno。在图 2-19 中，线程 1 执行系统调用 access 以确定是否允许它访问某个特定文件。操作系统把返回值放到全局变量 errno 里。当控制权返回到线程 1 之后，并在线程 1 读取 errno 之前，调度程序确认线程 1 此刻已用完 CPU 时间，并决定切换到线程 2。线程 2 执行一个 open 调用，结果失败，导致重写 errno，于是给线程 1 的返回值会永远丢失。随后在线程 1 执行时，它将读取错误的返回值并导致错误操作。

对于这个问题有各种解决方案。一种解决方案是全面禁止全局变量。不过这个想法不一定合适，因为它同许多已有的软件冲突。另一种解决方案是为每个线程赋予其私有的全局变量，如图 2-20 所示。在这个方案中，每个线程有自己的 errno 以及其他全局变量的私有副本，这样就避免了冲突。在效果上，这个方案创建了新的作用域层，这些变量对一个线程中所有过程都是可见的。而在原先的作用域层里，变量只对一个过程可见，并在程序中处处可见。

访问私有的全局变量需要有些技巧，不过，多数程序设计语言具有表示局部变量和全局变量的方式，而没有中间的形式。有可能为全局变量分配一块内存，并将它转送给线程中的每个过程作为额外的参数。尽管这不是一个漂亮的方案，但却是一个可用的方案。

还有另一种方案，可以引入新的库过程，以便创建、设置和读取这些线程范围的全局变量。首先一个调用也许是这样的：

```c
create_global("bufptr"); 
```



该调用在堆上或在专门为调用线程所保留的特殊存储区上替一个名为 bufptr 的指针分配存储空间。无论该存储空间分配在何处，只有调用线程才可访问其全局变量。如果另一个线程创建了同名的全局变量，由于它在不同的存储单元上，所以不会与已有的那个变量产生冲突。

访问全局变量需要两个调用：一个用于写入全局变量，另一个用于读取全局变量。对于写入，类似有

```c
set_global("bufptr", &buf); 
```



它把指针的值保存在先前通过调用 create_global 创建的存储单元中。如果要读出一个全局变量，调用的形式类似于

```c
bufptr = read_global("bufptr"); 
```



这个调用返回一个存储在全局变量中的地址，这样就可以访问其中的数据了。

试图将单一线程程序转化为多线程程序的另一个问题是，有许多库过程并不是可重入的。也就是说，它们不是被设计成下列工作坊式的：对于任何给定的过程，当前面的调用尚没有结束之前，可以进行第二次调用。例如，可以将通过网络发送消息恰当地设计为，在库内部地一个固定缓冲区中进行消息组合，然后陷入内核将其发送。但是，如果一个线程在缓冲区中编好了消息，然后被时钟中断强迫切换到第二个线程，而第二个线程立即用它自己的消息重写了该缓冲区，那会怎样呢？

类似的还有内存分配过程，例如 UNIX 中的 malloc，它维护着内存使用情况的关键表格，如可用内存块链表。在 malloc 忙于更新表格时，有可能暂时处于一种不一致的状态，指针的指向不定。如果在表格处于一种不一致的状态时发生了线程切换，并且从一个不同的线程中来了一个新的调用，就可能会由于使用了一个无效指针而导致程序崩溃。要有效解决这些问题意味着重写整个库，而这有可能引入一些微妙的错误，所以这么做是一件很复杂的事情。

另一种解决方案是，为每个过程提供一个包装器，该包装器设置一个二进制位从而标志某个库处于使用中。在先前的调用还没有完成之前，任何试图使用该库的其他线程都会被阻塞。尽管这个方式可以工作，但是它会极大地降低系统潜在的并行性。

接着考虑信号。有些信号逻辑上是线程专用的，但是另一些却不是。例如，如果某个线程调用 alarm，信号送往进行该调用的线程是有意义的。但是，当线程完全在用户空间实现时，内核根本不知道有线程存在，因此很难将信号发送给正确的线程。如果一个进程一次仅有一个警报信号等待处理，而其中的多个线程又独立地调用 alarm，那么情况就更加复杂了。

有些信号，如键盘中断，则不是线程专用的。谁应该捕捉它们？一个指定的线程？所有的线程？还是新创建的弹出式线程？进而，如果某个线程修改了信号处理程序，而没有通知其他线程，会出现什么情况？如果某个线程想捕捉一个特定的信号（比如，用户击键 CTRL+C），而另一个线程却想用这个信号终止进程，又会发生什么情况？如果有一个或多个线程运行标准的库过程以及其他用户编写的过程，那么情况还会更复杂。很显然，这些想法是不兼容的。一般而言，在单线程环境中信号已经是很难管理的了，到了多线程环境中并不会使这一情况变得容易处理。

由多线程引入的最后一个问题是堆栈的管理。在很多系统中，当一个进程的堆栈溢出时，内核只是自动为该进程提供更多的堆栈。当一个进程有多个线程时，就必须有多个堆栈。如果内核不了解所有的堆栈，就不能使它们自动增长，直到造成堆栈出错。事实上，内核有可能还没有意识到内存错误是和某个线程栈的增长有关系的。

这些问题当然不是不可克服的，但是却说明了给已有的系统引入线程而不进行实质性的重新设计系统是根本不行的。至少可能需要重新定义系统调用的语义，并且不得不重写库。而且所有这些工作必须与在一个进程中有一个线程的原有程序向后兼容。



##### 2.3	进程间通信

进程经常需要与其他进程通信。例如，在一个 shell 管道中，第一个进程的输出必须传送给第二个进程，这样沿着管道传递下去。因此在进程之间需要通信，而且最好使用一种结构良好的方式而不要使用中断。在下面几节中，我们就来讨论一些有关**进程间通信**（Inter Process Communication，IPC）的问题。

简要地说，有三个问题。第一个问题与上面的叙述有关，即一个进程如何把信息传递给另一个。第二个问题是确保两个或多个进程不会互相干扰，例如，在飞机订票系统中的两个进程为不同的客户试图争夺飞机上的最后一个座位。第三个问题与正确的顺序有关（如果该顺序是有关联的话），比如，如果进程 A 产生数据而进程 B 打印数据，那么 B 在打印之前必须等待，直到 A 已经产生一些数据。我们将从下一节开始考察所有这三个问题。

有必要说明，这三个问题中的两个问题对于线程来说同样是适用的。第一个问题（即传递信息）对线程而言比较容易，因为他们共享一个地址空间（在不同地址空间需要通信的线程属于不同进程之间通信的情形）。但是另外两个问题（两个进程需要梳理清楚使其不相互干扰并保持恰当的顺序）同样适用于线程。同样的问题可用同样的方法解决。下面开始讨论进程间通信问题，不过请记住，同样的问题和解决方法也适用于线程。



##### 2.3.1	竞争条件

在一些操作系统中，协作的进程可能共享一些彼此都能读写的公用存储区。这个公用存储区可能在内存中（可能是在内核的数据结构中），也可能是一个共享文件。这里共享存储区的位置并不影响通信的本质及其带来的问题。为了理解实际中进程间通信如何工作，我们考虑一个简单但很普遍的例子：一个假脱机打印程序。当一个进程需要打印一个文件时，它将文件名放在一个特殊的**假脱机目录**（spooler directory）下。下一个进程（**打印机守护进程**）则周期性地检查是否有文件需要打印，若有就打印并将该文件名从目录下删掉。

设想假脱机目录中有许多槽位，编号依次为 0，1，2，…，每个槽位存放一个文件名。同时假设有两个共享变量：out，指向下一个要打印的文件；in，指向目录中下一个空闲槽位。可以把这两个变量保存在一个所有进程都能访问的文件中，该文件的长度为两个字。在某一时刻，0 号至 3 号槽位空（其中的文件已经打印完毕），4 号至 6 号槽位被占用（其中存有排好队列的要打印的文件名）。几乎在同一时刻，进程 A 和进程 B 都决定将一个文件排队打印，这种情况如图 2-21 所示。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE43.jpg"/>
</div>

在 Murphy 法则（任何可能出错的地方终奖出错）失效时，可能发生以下的情况。进程 A 读到 in 的值为 7，将 7 存在一个局部变量 next_free_slot 中。此时发生一次时钟中断，CPU 认为进程 A 已运行了足够长的时间，决定切换到进程 B。进程 B 也读取 in，同样得到值为 7，于是将 7 存在 B 的局部变量 next_free_slot 中。在这一时刻两个进程都认为下一个可用槽位是 7。

进程 B 现在继续运行，它将其文件名存在槽位 7 中并将 in 的值更新为 8。然后它离开，继续执行其他操作。

最后进程 A 接着从上次中断的地方再次运行。它检查变量 next_free_slot，发现其值为 7，于是将打印文件名存入 7 号槽位，这样就把进程 B 存在那里的文件名覆盖掉。然后它将 next_free_slot 加 1，得到值为 8，就将 8 存到 in 中。此时，假脱机目录内部是一致的，所以打印机守护进程发现不了任何错误，但进程 B 却永远得不到任何打印输出。类似这样的情况，即两个或多个进程读写某些共享数据，而最后的结果取决于进程运行的精确时序，称为**竞争条件**（race condition）。调试包含有竞争条件的程序是一件很头痛的事。大多数的测试运行结果都很好，但在极少数情况下会发生一些无法解释的奇怪现象。不幸的是，多核增长带来的并行使得竞争条件越来越普遍。



##### 2.3.2	临界区

怎样避免竞争条件？实际上凡涉及共享内存、共享文件以及共享任何资源的情况都会引发与前面类似的错误，要避免这种错误，关键是要找出某种途径来阻止多个进程同时读写共享的数据。换言之，我们需要的是**互斥**（mutual exclusion），即以某种手段确保当一个进程在使用一个共享变量或文件时，其他进程不能做同样的操作。前述问题的症结就在于，在进程 A 对共享变量的使用未结束之前进程 B 就使用它。为实现互斥而选择适当的原语是任何操作系统的主要设计内容之一，也是后面几节中要详细讨论的主题。

避免竞争条件的问题也可以用一种抽象的方式进行描述。在一部分时间里，一个进程忙于做内部计算或另外一些不会引发竞争条件的操作。然而，在某些时候进程可能需要访问共享内存或共享文件，或执行另外一些会导致竞争的操作。我们把程序中访问共享内存的程序片段称作**临界区域**（critical region）或**临界区**（critical section）。如果我们能够适当地安排，使得两个进程不可能同时处于临界区中，就能够避免竞争条件。

尽管这样的要求避免了竞争条件，但它还不能保证使用共享数据的并发进程能够正确和高效地进行协作。对于一个好的解决方案，需要满足以下 4 个条件：

1) 任何两个进程不能同时处于其临界区。

2) 不应对 CPU 的速度和数量做任何假设。

3) 临界区外运行的进程不得阻塞其他进程。

4) 不得使进程无限期等待进入临界区。

从抽象的角度看，人们所希望的进程行为如图 2-22 所示。图 2-22 中进程 A 在 T~1~ 时刻进入临界区。稍后，在 T~2~ 时刻进程 B 试图进入临界区，但是失败了，因为另一个进程已经在该临界区内，而一个时刻只允许一个进程在临界区内。随后，B 被暂时挂起直到 T~3~ 时刻 A 离开临界区为止，从而允许 B 立即进入。最后，B 离开（在时刻 T~4~），回到了在临界区中没有进程的原始状态。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE44.jpg"/>
</div>





##### 2.3.3	忙等待的互斥

本节将讨论几种互斥的方案。在这些方案中，当一个进程在临界区中更新共享内存时，其他进程将不会进入其临界区，也不会带来任何麻烦。



**1.屏蔽中断**

在单处理器系统中，最简单的方法是使每个进程在刚刚进入临界区后立即屏蔽所有中断，并在就要离开之前再打开中断。屏蔽中断后，时钟中断也被屏蔽。CPU 只有发生时钟中断或其他中断时才会进行进程切换，这样，在屏蔽中断之后 CPU 将不会被切换到其他进程。于是，一旦某个进程屏蔽中断之后，它就可以检查和修改共享内存，而不必担心其他进程介入。

这个方案并不好，因为把屏蔽中断的权利交给用户进程是不明智的。设想一下，若个进程屏蔽中断之后不再打开中断，其结果将会如何？整个系统可能会因此终止。而且，如果系统是多处理器（有两个或更多的处理器），则屏蔽中断仅仅对执行 disable 指令的那个 CPU 有效。其他 CPU 仍将继续运行，并可以访问共享内存。

另一方面，对内核来说，当它在更新变量或列表的几条指令期间将中断屏蔽是很方便的。当就绪进程队列之类的数据状态不一致时发生中断，则可能导致竞争条件。所以结论是：屏蔽中断对于操作系统本身而言是一项很有用的技术，但对于用户进程则不是一种合适的通用互斥机制。

由于多核芯片的数量越来越多，即使在低端 PC 上也是如此。因此，通过屏蔽中断来达到互斥的可能性——甚至在内核中——变得日益减少了。双核现在已经相当普遍，四核当前在高端机器中存在，而且离八或十六（核）也不久远了。在一个多核系统中（例如，多处理器系统），屏蔽一个 CPU 的中断不会阻止其他 CPU 干预第一个 CPU 所做的操作。结果是人们需要更加复杂的计划。



**2.锁变量**

作为第二种尝试，可以寻找一种软件解决方案。设想有一个共享（锁）变量，其初始值为 0。当一个进程想进入其临界区，它首先测试这把锁。如果该锁的值为 0，则该进程将其设置为 1 并进入临界区。若这把锁的值已经为 1，则该进程将等待直到其值变为 0。于是，0 就表示临界区内没有进程，1 表示已经有某个进程进入临界区。

但是，这种想法也包含了与假脱机目录一样的疏漏。假设一个进程读出锁变量的值并发现它为 0，而恰好在它将其值设置为 1 之前，另一个进程被调度运行，将该锁变量设置为 1。当第一个进程再次运行时，它同样也将该锁设置为 1，则此时同时有两个进程进入临界区中。

可能读者会想，先读出锁变量，紧接着在其改变其值之前再检查一遍它的值，这样便可以解决问题。但这实际上无济于事，如果第二个进程恰好在第一个进程完成第二次检查之后修改了锁变量的值，则同样还会发生竞争条件。



**3.严格轮换法**

第三种互斥的方法如图 2-23 所示。几乎与本书中所有其他程序一样，这里的程序段用 C 语言编写。之所以选择 C 语言是由于实际的操作系统普遍用 C 语言编写（或偶尔用 C++），而基本上不用像 Java、Modula3 或 Pascal 这样的语言。对于编写操作系统而言，C 语言是强大、有效、可预知和有特性的语言。而对于 Java，它就不是可预知的，因为它在关键时刻会用完存储器，而在不合适的时候会调用垃圾收集程序回收内存。在 C 语言中，这种情形就不可能发生，因为 C 语言中不需要进行空间回收。有关 C、C++、Java 和其他四种语言的定量比较可参阅（Prechelt，2000）。

在图 2-23 中，整型变量 turn，初始值为 0，用于记录轮到哪个进程进入临界区，并检查或更新共享内存。开始时，进程 0 检查 turn，发现其值为 0，于是进入临界区。进程 1 也发现其值为 0，所以在一个等待循环中不停地测试 turn，看其值何时变为 1。连续测试一个变量直到某个值出现为止，称为**忙等待**（busy waiting）。由于这种方式浪费 CPU 时间，所以通常应该避免。只有在有理由认为等待时间是非常短的情形下，才使用忙等待。用于忙等待的锁，称为**自旋锁**（spin lock）。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE45.jpg"/>
</div>

进程 0 离开临界区时，它将 turn 的值设置为 1，以便允许进程 1 进入其临界区。假设进程 1 很快便离开了临界区，则此时两个进程都处于临界区之外，turn 的值又被设置为 0。现在进程 0 很快就执行完其整个循环，它退出临界区，并将 turn 的值设置为 1。此时，turn 的值为 1，两个进程都在其临界区外执行。

突然，进程 0 结束了非临界区的操作并且返回到循环的开始。但是，这时它不能进入临界区，因为 turn 的当前值为 1，而此时进程 1 还在忙于非临界区的操作，进程 0 只有继续 while 循环，直到进程 1 把 turn 的值改为 0。这说明，在一个进程比另一个慢了很多的情况下，轮流进入临界区并不是一个好办法。

这种情况违反了前面叙述的条件 3：进程 0 被一个临界区之外的进程阻塞。再回到前面假脱机目录的问题，如果现在将临界区与读写假脱机目录相联系，则进程 0 有可能因为进程 1 在做其他事情而被禁止打印另一个文件。

实际上，该方案要求两个进程严格地轮流进入它们的临界区，如假脱机文件等。任何一个进程都不可能在一轮中打印两个文件。尽管该算法的确避免了所有的竞争条件，但由于它违反了条件 3，所以不能作为一个很好的备选方案。



**4.Peterson 解法**

荷兰数学家 T. Dekker 通过将锁变量与警告变量的思想相结合，最早提出了一个不需要严格轮换的软件互斥算法。关于 Dekker 的算法，请参阅（Dijkstra，1965）。

1981年，G. L. Peterson 发现了一种简单得多的互斥算法，这使得 Dekker 的方法不再有任何新意。Peterson 的算法如图 2-24 所示。该算法由两个用 ANSI C 编写的过程组成。ANSI C 要求为所定义和使用的所有函数提供函数原型。不过，为了节省篇幅，这里和后续的例子中我们都不会给出函数原型。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE46.jpg"/>
</div>

在使用共享变量（即进入其临界区）之前，各个进程使用其进程号 0 或 1 作为参数来调用 enter_region。该调用在需要时将使进程等待，直到能安全地进入临界区。在完成对共享变量的操作之后，进程将调用 leave_region，表示操作已完成，若其他的进程希望进入临界区。则现在就可以进入。

现在来看看这个方案是如何工作的。一开始，没有任何进程处于临界区中，现在进程 0 调用 enter_region。它通过设置其数组元素和将 turn 置为 0 来标识它希望进入临界区。由于进程 1 并不想进入临界区，所以 enter_region 很快便返回。如果进程 1 现在调用 enter_region，进程 1 将在此处挂起直到 interested[0] 变成 FALSE，该事件只有在进程 0 调用 leave_region 退出临界区时才会发生。

现在考虑两个进程几乎同时调用 enter_region 的情况。它们都将自己的进程号存入 turn，但只有后被保存进去的进程号才有效，前一个因被重写而丢失。假设进程 1 是后存入的，则 turn 为 1。当两个进程都运行到 while 语句时，进程 0 将循环 0 次并进入临界区，而进程 1 则将不停地循环且不能进入临界区，直到进程 0 退出临界区为止。



**5.TSL 指令**

现在来看需要硬件支持的一种方案。某些计算机中，特别是那些设计为多处理器的计算机，都有下面一条指令：

TSL RX, LOCK

称为**测试并加锁**（test and set lock），它将一个内存字 lock 读到寄存器 RX 中，然后在 lock 的内存地址上存一个非零值。读字和写字操作保证是不可分割的，即该指令结束之前其他处理器均不允许访问该内存字。执行 TSL 指令的 CPU 将锁住内存总线，以禁止其他 CPU 在本指令结束之前访问内存。

着重说明一下，锁住存储总线不同于屏蔽中断。屏蔽中断，然后在读内存字之后跟着写操作并不能阻止总线上的第二个处理器在读操作和写操作之间访问该内存字。事实上，在处理器 1 上屏蔽中断对处理器 2 根本没有任何影响。让处理器 2 原理内存直到处理器 1 完成的唯一方法就是锁住总线，这需要一个特殊的硬件设施（基本上，一根总线就可以确保总线由锁住它的处理器使用，而其他的处理器不能用）。

为了使用 TSL 指令，要使用一个共享变量 lock 来协调对共享内存的访问。当 lock 为 0 时，任何进程都可以使用 TSL 指令将其设置为 1，并读写共享内存。当操作结束时，进程用一条普通的 move 指令将 lock 的值重新设置为 0。

这条指令如何防止两个进程同时进入临界区呢？解决方案如图 2-25 所示。假定（但很典型）存在如下共 4 条指令的汇编语言子程序。第一条指令将 lock 原来的值复制到寄存器中并将 lock 设置为 1，随后这个原来的值与 0 相比较。如果它非零，则说明以前已被加锁，则程序将回到开始并再次测试。经过或长或短的一段时间后，该值将变为 0（当前处于临界区中的进程退出临界区时），于是过程返回，此时已加锁。要清除这个锁非常简单，程序只需将 0 存入 lock 即可，不需要特殊的同步指令。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE47.jpg"/>
</div>

现在有一种很明确的解法了。进程在进入临界区之前先调用 enter_region，这将导致忙等待，直到锁空闲为止，随后它获得该锁并返回。在进程从临界区返回时它调用 leave_region，这将把 lock 设置为 0。与基于临界区问题的所有解法一样，进程必须在正确的时间调用 enter_region 和 leave_region，解法才能奏效。如果一个进程有欺诈行为，则互斥将会失败。换言之，只有进程合作，临界区才能工作。

一个可替代 TSL 的指令是 XCHG，它原子性地交换了两个位置的内容，例如，一个寄存器与一个存储器字。代码如图 2-26 所示，而且就像可以看到的那样，它本质上与 TSL 的解决办法一样。所有的 Intel x86 CPU 在低层同步中使用 XCHG 指令。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE48.jpg"/>
</div>





##### 2.3.4	睡眠与唤醒

Peterson 解法和 TSL 或 XCHG 解法都是正确的，但它们都有忙等待的缺点。这些解法在本质上是这样的：当一个进程想进入临界区时，先检查是否允许进入，若不允许，则该进程将原地等待，直到允许为止。

这种方法不仅浪费了 CPU 时间，而且还可能引起预想不到的结果。考虑一台计算机有两个进程，H 优先级较高，L 优先级较低。调度规则规定，只要 H 处于就绪态它就可以运行。在某一时刻，L 处于临界区中，此时 H 变到就绪态，准备运行（例如，一条 I/O 操作结束）。现在 H 开始忙等待，但由于当 H 就绪时 L 不会被调度，也就无法离开临界区，所以 H 将永远忙等待下去。这种情况有时被称作**优先级反转问题**（priority inversion problem）。

现在来考察几条进程间通信原语，它们在无法进入临界区时将阻塞，而不是忙等待。最简单的是 sleep 和 wakeup。sleep 是一个将引起调用进程阻塞的系统调用，即被挂起，直到另外一个进程将其唤醒。wakeup 调用有一个参数，即要被唤醒的进程。另一种方法是让 sleep 和 wakeup 各有一个参数，即有一个用于匹配 sleep 和 wakeup 的内存地址。

**生产者-消费者问题**

作为使用这些原语的一个例子，我们考虑**生产者-消费者**（producer-consumer）问题，也称作**有界缓冲区**（bounded-buffer）问题。两个进程共享一个公共的固定大小的缓冲区。其中一个是生产者，将信息放入缓冲区；另一个是消费者，从缓冲区中取出信息。（也可以把这个问题一般化为 m 个生产者和 n 个消费者问题，但是这里只讨论一个生产者和一个消费者的情况，这样可以简化解决方案。）

问题在于当缓冲区已满，而此时生产者还想向其中放入一个新的数据项的情况。其解决办法是让生产者睡眠，待消费者从缓冲区中取出一个或多个数据项时再唤醒它。同样地，当消费者试图从缓冲区中取数据而发现缓冲区为空时，消费者就睡眠，直到生产者向其中放入一些数据时再将其唤醒。

这个方法听起来很简单，但它包含与前边假脱机目录问题一样的竞争条件。为了跟踪缓冲区中的数据项数，需要一个变量 count。如果缓冲区最多存放 N 个数据项，则生产者代码将首先检查 count 是否达到 N，若是，则生产者睡眠；否则生产者向缓冲区中放入一个数据项并增量 count 的值。

消费者的代码与此类似：首先测试 count 是否为0，若是，则睡眠；否则从中取走一个数据项并递减 count 的值。每个进程同时也检测另一个进程是否应被唤醒，若是则唤醒之。生产者和消费者的代码如图 2-27 所示。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE49.jpg"/>
</div>

为了在 C 语言中表示 sleep 和 wakeup 这样的系统调用。我们将以库函数调用的形式来表示。尽管它们不是标准 C 库的一部分，但在实际上任何系统中都具有这些库函数。未列出的过程 insert_item 和 remove_item 用来记录将数据项放入缓冲区和从缓冲区取出数据等事项。

现在回到竞争条件的问题。这里有可能会出现竞争条件，其原因是对 count 的访问未加限制。有可能出现以下情况：缓冲区为空，消费者刚刚读取 count 的值发现它为 0。此时调度程序决定暂停消费者并启动运行生产者。生产者向缓冲区中加入一个数据项，count 加 1。现在 count 的值变成了 1。它推断认为由于 count 刚才为 0，所以消费者此时一定在睡眠，于是生产者调用 wakeup 来唤醒消费者。

但是，消费者此时在逻辑上并未睡眠，所以 wakeup 信号丢失。当消费者下次运行时，它将测试先前读到的 count 值，发现它为 0，于是睡眠。生产者迟早会填满整个缓冲区，然后睡眠。这样一来，两个进程都将永远睡眠下去。

问题的实质在于发给一个（尚）未睡眠进程的 wakeup 信号丢失了。如果它没有丢失，则一切都很正常。一种快速的弥补方法是修改规则，加上一个**唤醒等待位**。当一个 wakeup 信号发送给一个清醒的进程信号时，将该位置 1。随后，当该进程要睡眠时，如果唤醒等待位为 1，则将该位清除，而该进程仍然保持清醒。唤醒等待位实际上就是存储 wakeup 唤醒信号的一个小猪存钱罐。

尽管在这个简单例子中用唤醒等待位的方法解决了问题，但是我们可以很容易就构造出一些例子，其中有三个或更多的进程，这时一个唤醒等待位就不够使用了。于是我们可以再打一个补丁，加入第二个唤醒等待位，甚至是 8 个、32 个等，但原则上讲，这并没有从根本上解决问题。



##### 2.3.5	信号量

信号量是 E. W. Dijkstra 在 1965 年提出的一种方法，它使用一个整型变量来累计唤醒次数，供以后使用。在他的建议中引入了一个新的变量类型，称作**信号量**（semaphore）。一个信号量的取值可以为 0（表示没有保存下来的唤醒操作）或者为正值（表示有一个或多个唤醒操作）。

Dijkstra 建议设立两种操作：down 和 up（分别为一般化后的 sleep 和 wakeup）。对一信号量执行 down 操作，则是检查其值是否大于 0。若该值大于 0，则将其值减 1（即用掉一个保存的唤醒信号）并继续；若该值为 0，则进程将睡眠，而且此时 down 操作并未结束。检查数值、修改变量值以及可能发生的睡眠操作均作为一个单一的、不可分割的**原子操作**完成。保证一旦一个信号量操作开始，则在该操作完成或阻塞之前，其他进程均不允许访问该信号量。这种原子性对于解决同步问题和避免竞争条件是绝对必要的。**所谓原子操作，是指一组相关联的操作要么都不间断地执行，要么都不执行**。原子操作在计算机科学的其他领域也是非常重要的。所谓原子操作是指不会被线程调度机制打断的操作；这种操作一旦开始，就一直运行到结束，中间不会有任何 context switch （切换到另一个线程）。

up 操作对信号量的值增 1。如果一个或多个进程在该信号量上睡眠，无法完成一个先前的 down 操作，则由系统选择其中的一个（如随机挑选）并允许该进程完成它的 down 操作。于是，对一个有进程在其上睡眠的信号量执行一次 up 操作之后，该信号量的值仍旧是 0，但在其上睡眠的进程却少了一个。信号量的值增 1 和唤醒一个进程同样也是不可分割的。不会有某个进程因执行 up 而阻塞，正如在前面的模型中不会有进程因执行 wakeup 而阻塞一样。

顺便提一下，在 Dijkstra 原来的论文中，他分别使用名称 P 和 V 而不是 down 和 up，荷兰语中，Proberen 的意思是尝试，Verhogen 的含义是增加或升高。由于对于不讲荷兰语的读者来说采用什么记号并无大的干系，所以，这里将使用 down 和 up 名称。它们在程序设计语言 Algol 68 中首次引入。 



**用信号量解决生产者—消费者问题**

用信号量解决丢失的 wakeup 问题，如图 2-28 所示。为确保信号量能正确工作，最重要的是要采用一种不可分割的方式来实现它。通常是将 up 和 down 作为系统调用实现，而且操作系统只需在执行以下操作时暂时屏蔽全部中断：测试信号量、更新信号量以及在需要时使某个进程睡眠。由于这些动作只需要几条指令，所以屏蔽中断不会带来什么副作用。如果使用多个 CPU，则每个信号量应由一个锁变量进行保护。通过 TSL 或 XCHG 指令来确保同一时刻只有一个 CPU 在对信号量进行操作。

读者必须搞清楚，使用 TSL 或 XCHG 指令来防止几个 CPU 同时访问一个信号量，这与生产者或消费者使用忙等待来等待对方腾出或填充缓冲区是完全不同的。信号量操作仅需几个毫秒，而生产者或消费者可能需要任意长的时间。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE50.jpg"/>
</div>

该解决方案使用了三个信号量：一个称为 full，用来记录充满的缓冲槽数目；一个称为 empty，记录空的缓冲槽数目；一个称为 mutex（Mutual exclusion；Mutual：相互的，彼此的 exclusion：排斥，排除），用来确保生产者和消费者不会同时访问缓冲区。full 的初值为 0，empty 的初值为缓冲区中槽的数目，mutex 初值为 1。供两个或多个进程使用的信号量，其初值为 1，保证同时只有一个进程可以进入临界区，称作**二元信号量**（binary semaphore）。如果每个进程在进入临界区前都执行一个 down 操作，并在刚刚退出时执行一个 up 操作，就能够实现互斥。

在有了进程间通信原语之后，我们观察一下图 2-5 中的中断顺序。在使用信号量的系统中，隐藏中断的最自然的方法是为每一个 I/O 设备设置一个信号量，其初值为 0。在启动一个 I/O 设备之后，管理进程就立即对相关联的信号量执行一个 down 操作，于是进程立即被阻塞。当中断到来时，中断处理程序随后对相关信号量执行一个 up 操作，从而将相关的进程设置为就绪状态。在该模型中，图 2-5 中的第 5 步包括在设备的信号量上执行 up 操作，这样在第 6 步中，调度程序将能执行设备管理程序。当然，如果这时有几个进程就绪，则调度程序下次可以选择一个更为重要的进程来运行。本章的后续内容中，我们将看到调度算法是如何进行的。

图 2-28 的例子实际上是通过两种不同的方式来使用信号量的，两者之间的区别是很重要的。信号量 mutex 用于互斥，它用于保证任一时刻只有一个进程读写缓冲区和相关的变量。互斥是避免混乱所必需的操作。在下一节中，我们将讨论互斥量及其实现方法。

信号量的另一种用途是用于实现同步（synchronization）。信号量 full 和 empty 用来保证某种事件的顺序发生或不发生。在本例中，它们保证当缓冲区满的时候生产者停止运行，以及当缓冲区空的时候消费者停止运行。这种用法与互斥是不同的。



##### 2.3.6	互斥量

如果不需要信号量的计数能力，有时可以使用信号量的一个简化版本，称为**互斥量**（mutex）。互斥量仅仅适用于管理共享资源或一小段代码。由于互斥量在实现时既容易又高效，这使得互斥量在实现用户空间线程包时非常有用。

互斥量是一个可以处于两态之一的变量：解锁和加锁。这样，只需要一个二进制位表示它，不过实际上，常常使用一个整型量，0 表示解锁，而其他所有的值则表示加锁。互斥量使用两个过程。当一个线程（或进程）需要访问临界区时，它调用 mutex_lock。如果该互斥量当前是解锁的（即临界区可用），此调用成功，调用线程可以自由进入该临界区。

另一方面，如果该互斥量已经加锁，调用线程被阻塞，直到该临界区中的线程完成并调用 mutex_unlock。如果多个线程被阻塞在该互斥量上，将随机选择一个线程并允许它获得锁。

由于互斥量非常简单，所以如果有可用的 TSL 或 XCHG 指令，就可以很容易地在用户空间中实现它们。**用于用户级线程包的 mutex_lock 和 mutex_unlock 代码**如图 2-29 所示。与 XCHG 解法本质上是相同的。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE51.jpg"/>
</div>

mutex_lock 的代码与图 2-25 中 enter_region 的代码很相似，但有一个关键的区别。当 enter_region 进入临界区失败时，它始终重复测试锁（忙等待）。实际上，由于时钟超时的作用，会调度其他进程进行，这样迟早拥有锁的进程会进入运行并释放锁。

在（用户）线程中，情形有所不同，因为没有时钟停止运行时间过长的线程。结果是通过忙等待的方式来试图获得锁的线程将永远循环下去，绝不会得到锁，因为这个运行的线程不会让其他线程运行从而释放锁。

以上就是 enter_region 和 mutex_lock 的差别所在。在后者取锁失败时，它调用 thread_yield 将 CPU 放弃给另一个线程。这样，就没有忙等待。在该线程下次运行时，它再一次对锁进行测试。

由于 thread_yield 只是在用户空间中对线程调度程序的一个调用，所以它的运行非常快捷。这样，mutex_lock 和 mutex_unlock 都不需要任何内核调用。通过使用这些过程，用户线程完全可以实现在用户空间中的同步，这些过程仅仅需要少量的指令。

上面所叙述的互斥量系统是一套调用框架。对于软件来说，总是需要更多的特性，而同步原语也不例外。例如，有时线程包提供一个调用 mutex_trylock，这个调用或者获得锁或者返回失败码，但并不阻塞线程。这就给了调用线程一个灵活性，用以决定下一步做什么，是使用替代方法还只是等待下去。

到目前为止，我们掩盖了一个问题，不过现在还是有必要把这个问题提出来。在用户级线程包中，多个线程访问同一个互斥量是没有问题的，因为所有的线程都在一个公共地址空间中操作。但是，对于大多数早期解决方案，诸如 Peterson 算法和信号量等，都有一个未说明的假定前提，即这些多个进程至少应该访问一些共享内存，也许仅仅是一个字。如果进程有不相交的地址空间，如我们始终提到的，那么在 Peterson 算法、信号量或公共缓冲区中，它们如何共享 turn 变量呢？

有两种方案。第一种，有些共享数据结构，如信号量，可以存放在内核中，并且只能通过系统调用来访问。这种处理方式化解了上述问题。第二种，多数现代操作系统（包括 UNIX 和 Windows）提供一种方法，让进程与其他进程共享其部分地址空间。在这种方法中，缓冲区和其他数据结构可以共享。在最坏的情形下，如果没有可共享的途径，则可以使用共享文件。

如果两个或多个进程共享其全部或大部分地址空间，进程和线程之间的差别就变得模糊起来，但无论怎样，两者的差别还是有的。共享要给公共地址空间的两个进程仍旧有各自的打开文件、定时器以及其他一些单个进程的特性，而在单个进程中的多个线程，则共享进程全部的特性。另外，共享一个公共地址空间的多个进程绝不会拥有用户级线程的效率，这一点是不容置疑的，这是因为内核还同其管理密切相关。



**1.快速用户区互斥量 futex**

随着并行的增加，有效的同步和锁机制对性能而言非常重要。如果等待时间短的话，自旋锁会很快，但如果等待时间长，则会浪费 CPU 周期。如果有很多竞争，那么阻塞此进程，并仅当锁被释放的时候让内核解除阻塞会更加有效。然而，这却带来了相反的问题：它在竞争激烈的情况下效果不错，但如果一开始只有很小的竞争，那么不停地内核切换将花销很大。更糟的是，预测锁竞争的数量并不容易。

一个引人注意的致力于结合两者优点的解决方案称作 “futex”，即 “fast userspace mutex”（快速用户空间互斥）。futex 是 Linux 的一个特性，它实现了基本的锁（很像互斥锁），但避免了陷入内核，除非它真的不得不这样做。因为来回切换到内核花销很大，所以这样做可观地改善了性能。一个 futex 包含两个部分：一个内核服务和一个用户库。内核服务提供一个等待队列，它允许多个进程在一个锁上等待。它们将不会运行，除非内核明确地对它们解除阻塞。将一个进程放到等待队列需要（代价很大的）系统调用，我们应该避免这种情况。因此，没有竞争时，futex 完全在用户空间工作。特别地，这些进程共享通用的锁变量——一个对齐的 32 位整数的锁的专业术语。假设锁初始值为 1，即假设这意味着锁是释放状态。线程通过执行原子操作 “减少并检验” 来夺取锁（Linux 的原子函数包含封装在 C 语言函数中的内联汇编并定义在头文件中）。接下来，这个线程检查结果，看锁是否被释放。如果未处于被锁状态，那么一切顺利，我们的线程成功夺取该锁。然而，如果该锁被另一个线程持有，那么线程必须等待。这种情况下，futex 库不自旋，而是使用一个系统调用把这个线程放在内核里的等待队列上。可以期望的是，切换到内核的开销已是合乎情理的了，因为无论如何线程被阻塞了。当一个线程使用完该锁，它通过原子操作 “增加并检验” 来释放锁，并检查结果，看是否仍有进程阻塞在内核等待队列上。如果有，它会通知内核可以对等待队列里得一个或多个进程解除阻塞。如果没有锁竞争，内核则不需要参与其中。



**2.pthread 中的互斥量**

Pthread 提供许多可以用来同步线程的函数。其基本机制是使用要给可以被锁定和解锁的互斥量来保护每个临界区。一个线程如果想要进入临界区，它首先尝试锁住相关的互斥量。如果互斥量没有加锁，那么这个线程可以立即进入，并且该互斥量被自动锁定以防止其他线程进入。如果互斥量已经被加锁，则调用线程被阻塞，直到该互斥量被解锁。如果多个线程在等待同一个互斥量，当它被解锁时，这些等待的线程中只有一个被允许运行并将互斥量重新锁定。这些互斥锁不是强制性的，而是由程序员来保证线程正确地使用它们。

与互斥量相关的主要函数调用如图 2-30 所示。就像所期待的那样，可以创建和撤销互斥量。实现它们的函数调用分别是 pthread_mutex_init 与 pthread_mutex_destroy。也可以通过 pthread_mutex_lock 来给互斥量加锁，如果该互斥量已被加锁时，则会阻塞调用者。还有一个调用可以用来尝试锁住一个互斥量，当互斥量已被加锁时会返回错误代码而不是阻塞调用者。这个调用就是 pthread_mutex_trylock。如果需要的话，该调用允许一个线程有效地忙等待。最后，pthread_mutex_unlock 用来给一个互斥量解锁，并在一个或多个线程等待它的情况下正确地释放一个线程。互斥量也可以有属性，但是这些属性只在某些特殊的场合下使用。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE58.jpg"/>
</div>

除互斥量之外，pthread 提供了另一种同步机制：**条件变量**。互斥量在允许或阻塞对临界区的访问上是很有用的，条件变量则允许线程由于一些未达到的条件而阻塞。绝大部分情况下这两种方法是一起使用的。现在让我们进一步地研究线程、互斥量、条件变量之间的关联。 

举一个简单的例子，再次考虑一下生产者—消费者问题：一个线程将产品放在一个缓冲区内，由另一个线程将它们取出。如果生产者发现缓冲区中没有空槽可以使用了，它不得不阻塞起来直到有一个空槽可以使用。生产者使用互斥量可以进行原子性检查，而不受其他线程干扰。但是当发现缓冲区已经满了以后，生产者需要一种方法来阻塞自己并在以后被唤醒。这便是条件变量做的事了。

图 2-31 给出了与条件变量相关的最重要的 pthread 调用。就像你可能期待的那样，这里有专门的调用用来创建和撤销条件变量。它们可以有属性，并且有不同的调用来管理它们（图中没有给出）。条件变量上的主要操作是 pthread_cond_wait 和 pthread_cond_signal，前者阻塞调用线程直到另一其他线程向它发信号（使用后一个调用）。当然，阻塞与等待的原因不是等待与发信号协议的一部分。被阻塞的线程经常是在等待发信号的线程去做某些工作、释放某些资源或是进行其他的一些活动。只有完成后被阻塞的线程才可以继续运行。条件变量允许这种等待与阻塞原子性地进行。当有多个线程被阻塞并等待同一个信号时，可以使用 pthread_cond_broadcast 调用。

条件变量与互斥量经常一起使用。这种模式用于让一个线程锁住一个互斥量，然后当它不能获得它期待的结果时等待一个条件变量。最后另一个线程会向它发信号，使它可以继续执行。pthread_cond_wait 原子性地调用并解锁它持有的互斥量。由于这个原因，互斥量是参数之一。

值得注意的是，条件变量（不像信号量）不会存在内存中。如果将一个信号量传递给一个没有线程在等待的条件变量，那么这个信号就会丢失。程序员必须小心使用避免丢失信号。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE52.jpg"/>
</div>

作为如何使用一个互斥量与条件变量的例子，图 2-32 展示了一个非常简单只有一个缓冲区的生产者—消费者问题。当生产者填满缓冲区时，它在生产下一个数据项之前必须等待，直到消费者清空了它。类似地，当消费者移走一个数据项时，它必须等待，直到生产者生产了另外一个数据项。尽管很简单，这个例子却说明了基本的机制。使一个线程睡眠的语句应该总是要检查这个条件，以保证线程在继续执行前满足条件，因为线程可能已经因为一个 UNIX 信号或其他原因而被唤醒。



##### 2.3.7	管程

有了信号量和互斥量之后，进程间通信看来就很容易了，实际是这样的吗？答案是否定的。请仔细考察图 2-28 中向缓冲区放入数据项以及从中删除数据项之前的 down 操作。假设将生产者代码中的两个 down 操作交换一下次序，将使得 mutex 的值在 empty 之前而不是在其之后被减 1。如果缓冲区完全满了，生产者将阻塞，mutex 值为 0。这样一来，当消费者下次试图访问缓冲区时，它将对 mutex 执行一个 down 操作，由于 mutex 值为 0，则消费者也将阻塞。两个进程都将永远地阻塞下去，无法再进行有效的工作，这种不幸的状况称作死锁（dead lock）。我们将在第 6 章中详细讨论死锁问题。

指出这个问题是为了说明使用信号量时要非常小心。一处很小的错误将导致很大的麻烦。这就像用汇编语言编程一样，甚至更糟，因为这里出现的错误都是竞争条件、死锁以及其他一些不可预测和不可再现的行为。

为了更易于编写正确的程序，Brinch Hansen （1973）和 Hoare（1974）提出了一种高级同步原语，称为**管程**（monitor）。在下面的介绍中会发现，他们两人提出的方案略有不同。一个管程是一个由过程、变量及数据结构等组成的一个集合，它们组成一个特殊的模块或软件包。进程可在任何需要的时候调用管程中的过程，但它们不能在管程之外声明的过程中直接访问管程内的数据结构。图 2-33 展示了用一种抽象的、类 Pascal 语言描述的管程。这里不能使用 C 语言，因为管程是语言概念而 C 语言并不支持它。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE53.jpg"/>
</div>

管程有一个很重要的特性，即任一时刻管程中只能有一个活跃进程，这一特性使管程能有效地完成互斥。管程是编程语言的组成部分，编译器知道它们的特殊性，因此可以采用与其他过程调用不同的方法来处理对管程的调用。典型的处理方法是，当一个进程调用管程过程时，该过程中的前几条指令将检查在管程中是否有其他的活跃进程。如果有，调用进程将被挂起，直到另一个进程离开管程将其唤醒。如果没有活跃进程在使用管程，则该调用进程可以进入。

进入管程时的互斥由编译器负责，但通常的做法是用一个互斥量或二元信号量。因为是由编译器而非程序员来安排互斥，所以出错的可能性要小得多。在任一时刻，写管程的人无须关心编译器是如何实现互斥的。他只需知道将所有的临界区转换成管程过程即可，决不会有两个进程同时执行临界区中的代码。

尽管管程提供了一种实现互斥的简便途径，但这还不够，还需要一种办法使得进程在无法继续运行时被阻塞。在生产者-消费者问题中，很容易将针对缓冲区满和缓冲区空的测试放到管程过程中，但是生产者在发现缓冲区满的时候如何阻塞呢？

解决的方法是引入**条件变量**（condition variables）以及相关的两个操作：wait 和 signal。当一个管程过程发现它无法继续运行时（例如，生产者发现缓冲区满），它会在某个条件变量上（如 full）执行 wait 操作。该操作导致调用进程自身阻塞，并且还将另一个以前等在管程之外的进程调入管程。在前面介绍 pthread 时我们已经看到条件变量及其操作了。

另一个进程，比如消费者，可以唤醒正在睡眠的伙伴进程，这可以通过对其伙伴正在等待的一个条件变量执行 signal 完成。为了避免管程中同时有两个活跃进程，我们需要一条规则来通知在 signal 之后该怎么办。Hoare 建议让新唤醒的进程运行，而挂起另一个进程。Brinch Hansen 则建议执行 signal 的进程必须立即退出管程，即 signal 语句只可能作为一个管程过程的最后一条语句。这里将采纳 Brinch Hansen 的建议，因为它在概念上更简单，并且更容易实现。如果在一个条件变量上有若干进程正在等待，则在对该条件变量执行 signal 操作后，系统调度程序只能在其中选择一个使其恢复运行。

顺便提一下，还有一个 Hoare 和 Brinch Hansen 都没有提及的第三种方法，该方法让发信号者继续运行，并且只有在发信号者退出管程之后，才允许等待的进程开始运行。

条件变量不是计数器，条件变量也不能像信号量那样积累信号以便以后使用。所以，如果向一个条件变量发送信号，但是在该条件变量上并没有等待进程，则该信号会永远丢失。换句话说，wait 操作必须在 signal 之前。这条规则使得实现简单了许多。实际上这不是一个问题，因为在需要时，用变量很容易跟踪每个进程的状态。一个原本要执行 signal 的进程，只要检查这些变量便可以知道该操作是否有必要。

在图 2-34 中给出了用类 Pascal 语言，通过管程实现的生产者-消费者问题的解法框架。使用类 Pascal 语言的优点在于清晰、简单，并且严格符合 Hoare/Brinch Hansen 模型。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE54.jpg"/>
</div>

读者可能会觉得 wait 和 signal 操作看起来像前面提到的 sleep 和 wakeup，而且已经看到后者存在严重的竞争条件。是的，它们确实很像，但是有个很关键的区别：sleep 和 wakeup 之所以失败是因为当一个进程想睡眠时另一个进程试图去唤醒它。使用管程则不会发生这种情况。对管程过程的自动互斥保证了这一点：如果管程过程中的生产者发现缓冲区满，它将能够完成 wait 操作而不用担心调度程序可能会在 wait 完成之前切换到消费者。甚至，在 wait 执行完成而且把生产者标志为不可运行之前，根本不会允许消费者进入管程。

尽管 Pidgin Pascal 是一种想象的语言，但还是有一些真正的编程语言支持管程，不过它们不一定是 Hoare 和 Brinch Hansen 所设计的模型。其中一种语言是 Java。Java 是一种面向对象的语言，它支持用户级线程，还允许将方法（过程）划分为类。只要将关键字 synchronized 加入到方法声明中，Java 保证一旦某个线程执行该方法，就不允许其他线程执行该对象中的任何 synchronized 方法。没有关键字 synchronized，就不能保证没有交错执行。

使用 Java 管程解决生产者-消费者问题的解法如图 2-35 所示。该解法中有 4 个类。**外部类**（outer class）ProducerConsumer 创建并启动两个线程，p 和 c。第二个类和第三个类 producer 和 consumer 分别包含生产者和消费者的代码。最后，类 our_monitor 是管程，它有两个同步线程，用于在共享缓冲区中插入和取出数据项。与前面的例子不同，我们在这里给出了 insert 和 remove 的全部代码。

在前面所有的例子中，生产者和消费者线程在功能上与它们的等同部分是相同的。生产者有一个无限循环，该无限循环产生数据并将数据放入公共缓冲区中；消费者也有一个等价的无限循环，该无限循环从公共缓冲区取出数据并完成一些有趣的工作。

该程序中比较有意思的部分是类 our_monitor，它包含缓冲区、管理变量以及两个同步方法。当生产者在 insert 内活动时，它确信消费者不能在 remove 中活动，从而保证更新变量和缓冲区的安全，且不用担心竞争条件。变量 count 记录在缓冲区中数据项的数量。它的取值可以取从 0 到 N-1 之间任何值。变量 lo 是缓冲区槽的序号，指出将要取出的下一个数据项。类似地，hi 是缓冲区中下一个将要放入的数据项序号。允许 lo = hi，其含义是在缓冲区中有 0 个或 N 个数据项。count 的值说明了究竟是哪一种情形。

Java 中的同步方法与其他经典管程有本质差别：Java 没有内嵌的条件变量。反之，Java 提供了两个过程 wait 和 notify ，分别与 sleep 和 wakeup 等价，不过，当它们在同步方法中使用时，它们不受竞争条件约束。理论上，方法 wait 可以被中断，它本身就是与中断有关的代码。Java 需要显式表示异常处理。在本文的要求中，只要认为 go_to_sleep 就是去睡眠即可。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE55.jpg"/>
</div>

通过临界区互斥的自动化，管程比信号量更容易保证并行编程的正确性。但管程也有缺点。我们之所以使用类 Pascal 和 Java，而不像在本书中其他例子那样使用 C 语言，并不是没有原因的。正如前面提到过的，管程是一个编程语言概念，编译器必须要识别管程并用某种方式对其互斥做出安排。C、Pascal 以及多数其他语言都没有管程，所以指望这些编译器遵守互斥规则是不合理的。实际中，如何能让编译器知道哪些过程属于管程，哪些不属于管程呢？

在上述语言中同样也没有信号量，但增加信号量是很容易的：读者需要做的就是向库里加入两段短小的汇编程序代码，以执行 up 和 down 系统调用。编译器甚至用不着知道它们的存在。当然，操作系统必须知道信号量的存在，或至少有一个基于信号量的操作系统，读者仍旧可以使用 C 或 C++ （甚至是汇编语言，如果读者乐意的话）来编写用户程序，但是如果使用管程，读者就需要一种带有管程的语言。

与管程和信号量有关的另一个问题是，这些机制都是设计用来解决访问公共内存的一个或多个 CPU 上的互斥问题的。通过将信号量放在共享内存中并用 TSL 或 XCHG 指令来保护它们，可以避免竞争。**如果一个分布式系统具有多个 CPU，并且每个 CPU 拥有自己的私有内存，它们通过一个局域网相连，那么这些原语将失效**。这里的结论是：信号量太低级了，而管程在少数几种编程语言之外又无法使用，并且，这些原语均未提供机器间的信息交换方法。所以还需要其他的方法。



##### 2.3.8	消息传递

上面提到的其他的方法就是**消息传递**（message passing）。这种进程间通信的方法使用两条原语 send 和 recieve，它们像信号量而不像管程，是系统调用而不是语言成分。因此，可以很容易地将它们加入到库例程中去。例如：

send(destination, &message);

和

recieve(source, &message);

前一个调用向一个给定的目标发送一条消息，后一个调用从一个给定的源（或者是任意源，如果接收者不介意的话）接收一条消息。如果没有消息可用，则接收者可能被阻塞，直到一条消息到达，或者，带着一个错误码立即返回。



**1.消息传递系统的设计要点**

消息传递系统面临着许多信号量和管程所未涉及的问题和设计难点，特别是位于网络中不同机器上的通信进程的情况。例如，消息有可能被网络丢失。为了防止消息丢失，发送方和接受方可以达成如下一致：一旦接收到消息，接收方马上回送一条特殊的**确认**（acknowledgement）消息。如果发送方在一段时间间隔内未收到确认，则重发消息。

现在考虑消息本身被正确接收，而返回给发送者的确认信息丢失的情况。发送者将重发信息，这样接收者将接收到两次相同的消息。对于接收者来说，如何区分新的消息和一条重发的老消息是非常重要的。通常采用在每条原始消息中嵌入一个连续的序号来解决此问题。如果接收者收到一条消息，它具有与前面某一条消息一样的序号，就知道这条消息是重复的，可以忽略。不可靠消息传递中的成功通信问题是计算机网络的主要研究内容。更多的信息可以参考相关文献 Tanenbaum（1996）和 Wetherall（2010）。

消息系统还需要解决进程命名的问题，在 send 和 receive 调用中所指定的进程必须是没有二义性的。**身份认证**（authentication）也是一个问题，比如，客户端怎么知道它是在与一个真正的文件服务器通信，而不是与一个冒充者通信？

对于发送者和接收者在同一台机器上的情况，也存在若干设计问题。其中一个设计问题就是性能问题。将消息从一个进程复制到另一个进程通常比信号量操作和进入管程要慢。



**2.用消息传递解决生产者-消费者问题**

现在我们来考察如何用消息传递而不是共享内存来解决生产者-消费者问题。在图 2-36 中给出了一种解法。假设所有的消息都有同样的大小，并且在尚未接收到发出的消息时，由操作系统自动进行缓冲。在该解决方案中共使用 N 条消息，这就类似于一块共享内存缓冲区中的 N 个槽。消费者首先将 N 条空消息发送给生产者。当生产者向消费者传递一个数据项时，它取走一条空消息并送回一条填充了内容的消息。这样，系统中消息的总数在时间上保持恒定，因此可以将它们存储在预先已知的给定数量的内存中。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE56.jpg"/>
</div>

如果生产者的速度比消费者快，则所有的消息最终都将被填满，等待消费者，生产者将被阻塞，等待返回一条空消息。如果消费者速度快，则情况正好相反：所有的消息均为空，等待生产者来填充它们，消费者被阻塞，以等待一条填充过的消息。

消息传递方式可以有许多变体，下面首先介绍如何对消息进行编址。一种方法是为每个进程分配一个唯一的地址，让消息按进程的地址编址。另一种方法是引入一种新的数据结构，称作**信箱**（mailbox）。信箱是一个用来对一定数量的消息进行缓冲的地方，信箱中消息数量的设置方法也有多种，典型的方法是在信箱创建时确定消息的数量。当使用信箱时，在 send 和 receive 调用中的地址参数就是信箱的地址，而不是进程的地址。当一个进程试图向一个满的信箱发消息时，它将被挂起，直到信箱内有消息被取走，从而为新消息腾出空间。

对于生产者-消费者问题，生产者和消费者均应创建足够容纳 N 条消息的信箱。生产者向消费者信箱发送包含实际数据的消息，消费者则向生产者信箱发送空的消息。当使用信箱时，缓冲机制的作用是很清楚的：目标信箱容纳那些已被发送但尚未被目标进程接收的消息。

使用信箱的另一种极端方法是彻底取消缓冲。采用这种方法时，如果 send 在 receive 之前执行，则发送进程被阻塞，直到 receive 发生。在执行 receive 时，消息可以直接从发送者复制到接收者，不用任何中间缓冲。类似地，如果先执行 receive，则接收者会被阻塞，直到 send 发生。这种方案常被称为**会合**（rendezvous）。与带有缓冲的消息方案相比，该方案实现起来更容易一些，但却降低了灵活性，因为发送者和接收者一定要以步步紧接的方式运行。

通常在并行程序设计系统中使用消息传递。例如，一个著名的消息传递系统是**消息传递接口**（Message-Passing Interface，MPI），它广泛应用在科学计算中。有关该系统的更多信息，可参考 Gropp 等人（1994）和 Snir 等人（1996）的文献。



##### 2.3.9	屏障


略



##### 2.3.10	避免锁：读—复制—更新

最快的锁是根本没有锁。问题在于在没有锁的情况下，我们是否允许对共享数据结构的并发读写进行访问。在通常情况下，答案显然是否定的。假设进程 A 正在对一个数字数组进行排序，而进程 B 正在计算其均值。因为 A 在数组中将数值前后来回移动，所以 B 可能多次遇到某些数值，而某些数值则根本没有遇到过。得到的结果可能是任意值，而它几乎肯定是错的。

然而，在某些情况下，我们可以允许写操作来更新数据结构，即便还有其他的进程正在使用它。窍门在于确保每个读操作要么读取旧的数据版本，要么读取新的数据版本，但绝不能是新旧数据的一些奇怪组合。举例说明，考虑图 2-38 中的树。读操作从根部到叶子遍历整个树。在图的上半部分，加入一个新的节点 X。为了实现这一操作，我们要让这个节点在树中可见之前使它 “恰好正确”：我们对节点 X 中的所有值进行初始化，包括它的子节点指针。然后通过原子写操作，使 X 成为 A 的子节点。所有的读操作都不会读到前后不一致的版本。在图的下半部分，我们接着移除 B 和 D。首先，将 A 的左子节点指针指向 C。所有原本在 A 中的读操作将会后续读到节点 C，而永远不会读 B 和 D。也就是说，它们将只会读到新版数据。同样，所有当前在 B 和 D 中的读操作将继续依照原始的数据结构指针并且读取旧版数据。所有操作均正确进行，我们不需要锁住任何东西。而不需要锁住数据结构就能移去 B 和 D 的主要原因就是**读-复制-更新**（Read-Copy-Update，RCU)，将更新过程中的移除和再分配过程分离开来。

当然，还有一个问题。只要还不能确定没有对 B 和 D 更多的读操作，我们就不能真正释放它们。但是应该等待多久呢？一分钟？或者十分钟？我们不得不等到最后一个读操作读完这些节点。RCU 谨慎地决定读操作持有一个数据结构引用的最大时间。在这段时间之后，就能安全地将内存回收。特别地，读者通过**读端临界区**访问数据结构，它可以包含任何代码，只要该代码不阻塞或者休眠。这样的话，就知道了需要等待的最大时长。特别地，我们定义一个任意时间段的**宽限期**（grace period），在这个时期内，每个线程至少有一次在读端临界区之外。如果等待至少一个宽限期的时间段后进行回收，这一切就会令人满意。由于读端临界区中的代码不允许阻塞或者休眠，因此一个简单的准则就是一直等到所有的线程执行完一次上下文切换。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE57.jpg"/>
</div>





#### 2.4	调度

当计算机系统是多道程序设计系统时，通常就会有多个进程或线程同时竞争 CPU。只要有两个或更多的进程处于就绪状态，这种情形就会发生。如果只有一个 CPU 可用，那么就必须选择下一个要运行的进程。在操作系统中，完成选择工作的这一部分称为**调度程序**（scheduler），该程序使用的算法称为**调度算法**（scheduling algorithm）。

**尽管有一些不同，但许多适用于进程调度的处理方法也同样适用于线程调度。当内核管理线程的时候，调度经常是按线程级别的，与线程所属的进程基本或根本没有关联。**下面我们将首先关注适用于进程或线程两者的调度问题，然后会明确地介绍线程调度以及它所产生的独特问题。第 8 章将讨论多核芯片的问题。



##### 2.4.1	调度简介

让我们回到早期以磁带上的卡片作为输入的批处理系统时代，那时的调度算法很简单：依次运行磁带上的每一个作业。对于多道程序设计系统，调度算法要复杂一些，因为经常有多个用户等候服务。有些大型机系统仍旧将批处理和分时服务结合使用，需要调度程序决定下一个运行的是一个批处理作业还是终端上的一个交互用户。（顺便提及，一个批处理作业可能需要连续运行多个程序的请求，不过在本节中，我们仅假设它是运行单个程序的请求。）由于在这些机器中，CPU 是稀缺资源，所以好的调度程序可以在提高性能和用户的满意度方面取得很大的成果。因此，大量的研究工作都花费在创造聪明而有效的调度算法上了。

在个人计算机出现之后，整个情形向两个方面发展。首先，在多数时间内只有一个活动进程。一个用户进入文字处理软件编辑一个文件时，一般不会同时在后台编译一个程序。在用户向文字处理软件键入一条命令时，调度程序不用做多少工作来判定哪个进程要运行——唯一的候选者是文字处理软件。

其次，同 CPU 是稀缺资源时的年代相比，现在计算机速度极快。个人计算机的多数程序受到的是用户当前输入速率（键入或敲击鼠标）的限制，而不是 CPU 处理速率的限制。即便对于编译（这是过去 CPU 周期的主要消耗者）现在大多数情况下也只要花费仅仅几秒钟。甚至两个实际同时运行的程序，诸如一个文字处理软件和一个电子表单，由于用户在等待两者完成工作，因此很难说需要哪一个先完成。这样的结果是，调度程序在简单的 PC 上并不重要。当然，总有应用程序会实际消耗掉 CPU，例如，为绘制一小时高精度视频而调整 107 892 帧（NTSC 制）或 90 000 帧（PAL 制）中的每一帧颜色就需要大量工业强度的计算能力。然而，类似的应用程序不在我们的考虑范围。

对于网络服务器，情况略微有些改变。这里，多个进程经常竞争 CPU，因此调度功能再一次变得至关重要。例如，当 CPU 必须在运行一个收集每日统计数据的进程和服务用户需求的进程之间进行选择的时候，如果后者首先占用了 CPU，用户将会更高兴。

“资源充足” 这个论据在很多移动设备上也不成立，比如智能手机（可能除了最先进的几款）以及传感器网络的节点。这些情况下，CPU 依然薄弱，内存也偏小。此外，因为电池寿命短是这些设备最重要的约束之一，所以一些调度算法（scheduler）在努力优化电量损耗。

另外，为了选取正确的进程运行，调度程序还要考虑 CPU 的利用率，因为进程切换的代价是比较高的。首先用户态必须切换到内核态；然后要保存当前进程的状态，包括在进程表中存储寄存器值以便以后重新装载。在许多系统中，内存映像（例如，页表内的内存访问位）也必须保存；接着，通过运行调度算法选定一个新进程；之后，应该将新进程的内存映像重新装入 MMU；最后新进程开始运行。除此之外，进程切换还要使整个内存高速缓存失效，强迫缓存从内存中动态重新装入两次（进入内核一次，离开内核一次）。总之，如果每秒钟切换进程的次数太多，会耗费大量 CPU 时间，所以有必要提醒注意。

**1.进程行为**

几乎所有进程的（磁盘或网络）I/O 请求和计算都是交替突发的，如图 2-39 所示。典型地，CPU 不停顿地运行一段时间，然后发出一个系统调用以便读写文件。在完成系统调用之后，CPU 又开始计算，直到它需要读更多的数据或写更多的数据为止。请注意，某些 I/O 活动可以看作计算。例如，当 CPU 向视频 RAM 复制数据以更新屏幕时，因为使用了 CPU，所以这是计算，而不是 I/O 活动。按照这种观点，当一个进程等待外部设备完成工作而被阻塞时，才是 I/O 活动。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE59.jpg"/>
</div>

图 2-39 中有一件值得注意的事，即某些进程（图 2-39a 的进程）花费了绝大多数时间在计算上，而其他进程（图 2-39b 的进程）则在等待 I/O 上花费了绝大多数时间。前者称为计算密集型（compute-bound），后者称为 I/O 密集型（I/O-bound）。典型的计算密集型进程具有较长时间的 CPU 集中使用和较小频度的 I/O 等待。I/O 密集型进程具有较短时间的 CPU 集中使用和频繁的 I/O 等待。它是 I/O 类的，因为这种进程在 I/O 请求之间较少进行计算，并不是因为它们有特别长的 I/O 请求。在 I/O 开始后无论处理数据是多还是少，它们都花费同样的时间提出硬件请求读取磁盘块。

有必要指出，随着 CPU 变得越来越快，更多的进程倾向为 I/O 密集型。这种现象之所以发生是因为 CPU 的改进比磁盘的改进快得多，其结果是，未来对 I/O 密集型进程的调度处理似乎更为重要。这里的基本思想是，如果需要运行 I/O 密集型进程，那么就应该让它尽快得到机会，以便发出磁盘请求并保持磁盘始终忙碌。从图 2-6 中可以看到，如果进程是 I/O 密集型的，则需要多运行一些这类进程以保持 CPU 的充分利用。

**2.何时调度**

有关调度处理的一个关键问题是何时进行调度决策。存在着需要调度处理的各种情形。第一，在创建一个新进程之后，需要决定是运行父进程还是运行子进程。由于这两种进程都处于就绪状态，所以这是一种正常的调度决策，可以任意决定，也就是说，调度程序可以合法选择先运行父进程还是先运行子进程。

第二，在一个进程退出时必须做出调度决策。一个进程不再运行（因为它不再存在），所以必须从就绪进程集中选择另外某个进程。如果没有就绪的进程，通常会运行一个系统提供的空闲进程。

第三，当一个进程阻塞在 I/O 和信号量上或由于其他原因阻塞时，必须选择另一个进程运行。有时，阻塞的原因会成为选择的因素。例如，如果 A 是一个重要的进程，并正在等待 B 退出临界区，让 B 随后运行将会使得 B 退出临界区，从而可以让 A 运行。不过问题是，通常调度程序并不拥有做出这种相关考虑的必要信息。

第四，在一个 I/O 中断发生时，必须做出调度决策。如果中断来自 I/O 设备，而该设备现在完成了工作，某些被阻塞的等待该 I/O 的进程就成为可运行的就绪进程了。是否让新就绪的进程运行，这取决于调度程序的决定，或者让中断发生时运行的进程继续运行，或者应该让某个其他进程运行。

如果硬件时钟提供 50Hz、60Hz 或其他频率的周期性中断，可以在每个时钟中断或者在每 k 个时钟中断时做出调度决策。根据如何处理时钟中断，可以把调度算法分为两类。**非抢占式**调度算法挑选一个进程，然后让该进程运行直至被阻塞（阻塞在 I/O 上或等待另一个进程），或者直到该进程自动释放 CPU。即使该进程运行了若干个小时，它也不会被强迫挂起。这样做的结果是，在时钟中断发生时不会进行调度。在处理完时钟中断后，如果没有更高优先级的进程等待到时，则被中断的进程会继续执行。

相反，**抢占式**调度算法挑选一个进程，并且让该进程运行某个固定时段的最大值。如果在该时段结束时，该进程仍在运行，它就被挂起，而调度程序挑选另一个进程运行（如果存在一个就绪进程）。进行抢占式调度处理，需要在时间间隔的末端发生时钟中断，以便把 CPU 控制返回给调度程序。如果没有可用的时钟，那么非抢占式调度就是唯一的选择了。

**3.调度算法分类**

毫无疑问，不同的环境需要不同的调度算法。之所以出现这种情形，是因为不同的应用领域（以及不同的操作系统）有不同的目标。换句话说，在不同的系统中，调度程序的优化是不同的。这里有必要划分出三种环境：

1) 批处理。

2) 交互式。

3) 实时。

批处理系统在商业领域仍在广泛应用，用来处理薪水册、存货清单、账目收入、账目支出、利息计算（在银行）、索赔处理（在保险公司）和其他的周期性的作业。在批处理系统中，不会有用户不耐烦地在终端旁等待一个短请求的快捷响应。因此，非抢占式算法，或对每个进程都有长时间周期的抢占式算法，通常都是可接受的。这种处理方式减少了进程的切换从而改善了性能。这些批处理算法实际上相当普及，并经常可以应用在其他场合，这使得人们值得去学习它们，甚至是对于那些没有接触过大型机计算的人们。

在交互式用户环境中，为了避免一个进程霸占 CPU 拒绝为其他进程服务，抢占是必需的。即便没有进程想永远运行，但是，某个进程由于一个程序错误也可能无限期地排斥所有其他进程。为了避免这种现象发生，抢占也是必要的。服务器也归于此类，因为通常它们要服务多个突发的（远程）用户。

然而在有实时限制的系统中，抢占有时是不需要的，因为进程了解它们可能会长时间得不到运行，所以通常很快地完成各自的工作并阻塞。实时系统与交互式系统的差别是，实时系统只运行那些用来推进现有应用的程序，而交互式系统是通用的，它可以运行任意的非协作甚至是有恶意的程序。

**4.调度算法的目标**

为了设计调度算法，有必要考虑什么是一个好的调度算法。某些目标取决于环境（批处理、交互式或实时），但是还有一些目标是适用于所有情形的。在图 2-40 中列出了一些目标，我们将在下面逐一讨论。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE60.jpg"/>
</div>

在所有的情形中，公平是很重要的。相似的进程应该得到相似的服务。对一个进程给予较其他等价的进程更多的 CPU 时间是不公平的。当然，不同类型的进程可以采用不同方式处理。可以考虑一下在核反应堆计算机中心安全控制与发放薪水处理之间的差别。

与公平有关的是系统策略的强制执行。如果局部策略是，只要需要就必须运行安全控制进程（即便这意味着推迟 30 秒钟发薪），那么调度程序就必须保证能够强制执行该策略。

另一个共同的目标是保持系统的所有部分尽可能忙碌。如果 CPU 和所有 I/O 设备能够始终运行，那么相对于让某些部件空转而言，每秒钟就可以完成更多的工作。例如，在批处理系统中，调度程序控制哪个作业调入内存运行。在内存中既有一些 CPU 密集型进程又有一些 I/O 密集型进程是一个较好的想法，好于先调入和运行所有的 CPU 密集型作业，然后在它们完成之后再调入和运行所有 I/O 密集型作业的做法。如果使用后面一种策略，在 CPU 密集型进程运行时，它们就要竞争 CPU，而磁盘却在空转。稍后，当 I/O 密集型作业来了之后，它们要为磁盘而竞争，而 CPU 又空转了。显然，通过仔细组合进程，可以保持整个系统运行得更好一些。

运行大量批处理作业的大型计算中心的管理者们为了掌握其系统的工作状态，通常检查三个指标：吞吐量、周转时间以及 CPU 利用率。**吞吐量**（throughout）是系统每小时完成的作业数量。把所有的因素考虑进去之后，每小时完成 50 个作业好于每小时完成 40 个作业。**周转时间**（turnaround time）是指从一个批处理作业提交时刻开始直到该作业完成时刻为止的统计平均时间。该数据度量了用户要得到输出所需的平均等待时间。其规则是：小就是好的。

能够使吞吐量最大化的调度算法不一定就有最小的周转时间。例如，对于确定的短作业和长作业的一个组合，总是运行短作业而不运行长作业的调度程序，可能会获得出色的吞吐性能（每小时大量的短作业），但是其代价是对于长的作业周转时间很差。如果短作业以一个稳定的速率不断到达，长作业可能根本运行不了，这样平均周转时间是无限长，但是得到了高的吞吐量。

**CPU 利用率**常常用于对批处理系统的度量。尽管这样，CPU 利用率并不是一个好的度量参数。真正有价值的是，系统每小时可完成多少作业（吞吐量），以及完成作业需要多长时间（周转时间）。把 CPU 利用率作为度量依据，就像用引擎每小时转动了多少次来比较汽车的好坏一样。另一方面，知道什么时候 CPU 利用率接近 100% 比知道什么时候要求得到更多的计算能力要有用。

对于交互式系统，则有不同的指标。最重要的是最小**响应时间**，即从发出命令到得到响应之间的时间。在有后台进程运行（例如，从网络上读取和存储电子邮件）的个人计算机上，用户请求启动一个程序或打开一个文件应该优先于后台的工作。能够让所有的交互式请求首先运行的则是好服务。

一个相关的问题是**均衡性**。用户对做一件事情需要多长时间总是有一种固有的（不过通常不正确）看法。当认为一个请求很复杂需要较多的时间时，用户会接受这个看法，但是当认为一个请求很简单，但也需要较多的时间时，用户就会急躁。例如，如果点击一个图标花费了60秒钟发送完成一份传真，用户大概会接受这个事实，因为他没有期望花 5 秒钟得到传真，他知道这需要些时间。

另一方面，当传真发送完成，用户点击断开电话连接的图标时，该用户就有不一样的期待了。如果 30 秒之后还没有完成断开操作，用户就可能会抱怨，而 60 秒之后，他就要气得要命了。之所以有这种行为，其原因是：一般用户认为拿起听筒并建立通话连接所需的时间要比挂掉电话所需的时间长。在有些情形下（如本例），调度程序对响应时间指标起不了作用；但是在另外一些情形下，调度程序还是能够做一些事的，特别是在出现差的进程顺序选择时。

实时系统有着与交互式系统不一样的特性，所以有不同的调度目标。实时系统的特点是或多或少必须满足截止时间。例如，如果计算机正在控制一个以正常速率产生数据的设备，若一个按时运行的数据收集进程出现失败，会导致数据丢失。所以，实时系统最主要的要求是满足所有的（或大多数）截止时间要求。

在多数实时系统中，特别是那些涉及多媒体的实时系统中，可预测性是很重要的。偶尔不能满足截止时间要求的问题并不严重，但是如果音频进程运行的错误太多，那么音质就会下降得很快。视频品质也是一个问题，但是人的耳朵比眼睛对抖动要敏感得多。为了避免这些问题，进程调度程序必须是高度可预测和有规律的。本章介绍批处理系统和交互式系统中的调度算法。本书不介绍实时系统的调度算法。



##### 2.4.2	批处理系统中的调度

现在从一般的调度处理问题转向特定的调度算法。在这一节中，我们将考察在批处理系统中使用的算法，随后将讨论交互式和实时系统中的调度算法。有必要指出，某些算法既可以用在批处理系统中，也可以用在交互式系统中。我们将稍后讨论这个问题。

**1.先来先服务**

在所有调度算法中，最简单的是非抢占式的**先来先服务**（first-come first-served）算法。使用该算法，进程按照它们请求 CPU 的顺序使用 CPU。基本上，有一个就绪进程的单一队列。上午，当第一个作业从外部进入系统后，就立即开始并允许运行它所期望的时间长度，该作业不会因为运行太长时间而被中断。当其他作业进入时，它们排到就绪队列尾部。当正在运行的进程被阻塞时，就绪队列中的第一个进程接着运行。当在被阻塞的进程变为就绪时，就像一个新来到的作业一样，排到就绪队列的末尾，即排在所有进程最后。

这个算法的主要优点是易于理解并且便于在程序中运用。就难以得到的体育或音乐会票的分配问题而言，这对那些愿意在早上两点就去排队的人们也是公平的。在这个算法中，一个单链表记录了所有就绪进程。要选取一个进程运行，只要从该队列的头部移走一个进程即可；要添加一个新的作业或阻塞一个进程，只要把该作业或进程附加在相应队列的末尾即可。还有比这更简单的理解和实现吗？

不过，先来先服务也有明显的缺点。假设有一个一次运行 1 秒钟的计算密集型进程和很少使用 CPU 但是每个都要进行 1000 次磁盘读操作才能完成的大量 I/O 密集型进程存在。计算密集进程运行 1 秒钟，接着读一个磁盘块。所有的 I/O 进程开始运行并读磁盘。当该计算密集进程获得其磁盘块时，它运行下一个 1 秒钟，紧跟随着的是所有 I/O 进程。

这样做的结果是，每个 I/O 进程在每秒钟内读到一个磁盘块，要花费 1000 秒钟才能完成操作。如果有一个调度算法每 10ms 抢占计算密集型进程，那么 I/O 进程将在 10 秒钟内完成而不是 1000 秒钟，而且还不会对计算密集型进程产生多少延迟。

**2.最短作业优先**

现在来看一种适用于运行时间可以预知的另一个非抢占式的批处理调度算法。例如，一家保险公司，因为每天都做类似的工作，所以人们可以相当精确地预测处理 1000 个索赔的一批作业需要多少时间。当输入队列中有若干个同等重要的作业被启动时，调度程序应使用**最短作业优先**（shortest job first）算法，请看图 2-41。这里有 4 个作业 A、B、C、D，运行时间分别为 8、4、4、4 分钟。若按图中的次序运行，则 A 的周转时间为 8 分钟，B 为 12 分钟，C 为 16 分钟，D 为 20 分钟，平均为 14 分钟。

现在考虑使用最短作业优先算法运行这 4 个作业，如图 2-41b 所示。目前周转时间分别为 4、8、12 和 20 分钟，平均为 11 分钟。可以证明最短作业优先是最优的。考虑有4个作业的情况，其运行时间分别为 a、b、c、d。第一个作业在时间 a 结束，第二个在时间 a + b 结束，以此类推。平均周转时间为（4a + 3b + 2c + d）/4。显然 a 对平均值影响最大，所以它应是最短作业，其次是 b，再次是 c，最后的 d 只影响它自己的周转时间。对任意数目作业的情况，道理完全一样。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE61.jpg"/>
</div>

有必要指出，只有在所有的作业都可同时运行的情形下，最短作业优先算法才是最优化的。作为一个反例，考虑 5 个作业，从 A 到 E，运行时间分别是 2、4、1、1 和 1。它们的到达时间是 0、0、3、3 和 3。开始，只能选择 A 或 B，因为其他三个作业还没有到达。使用最短作业优先，将按照 A、B、C、D、E 的顺序运行作业，其平均等待时间是 4.6。但是，按照 B、C、D、E、A 的顺序运行作业，其平均等待时间则是 4.4。

**3.最短剩余时间优先**

最短作业优先的抢占式版本是**最短剩余时间优先**（shortest remaining time next）算法。使用这个算法，调度程序总是选择剩余运行时间最短的那个进程运行。再次提醒，有关的运行时间必须提前掌握。当一个新的作业到达时，其整个时间同当前进程的剩余时间做比较。如果新的进程比当前运行进程需要更少的时间，当前进程就被挂起，而运行新的进程。这种方式可以使新的短作业获得良好的服务。



##### 2.4.3	交互时系统中的调度

现在考察用于交互时系统中的一些调度算法，它们在个人计算机、服务器和其他类系统中都是常用的。

##### 1.轮转调度

一种最古老、最简单、最公平且使用最广的算法是**轮转调度**（round robin）。每个进程被分配一个时间段，称为**时间片**（quantum），即允许该进程在该时间段中运行。如果在时间片结束时该进程还在运行，则将剥夺 CPU 并分配给另一个进程。如果该进程在时间片结束前阻塞或结束，则 CPU 立即进行切换。时间片轮转调度很容易实现，调度程序所要做的就是维护一张可运行进程列表，如图 2-41a 所示。当一个进程用完它的时间片后，就被移到队列的末尾，如图 2-41b 所示。

时间片轮转调度中惟一有趣的一点是时间片的长度。从一个进程切换到另一个进程是需要一定时间进行管理事务处理的—保存和装入寄存器值及内存映像、更新各种表格和列表、清除和重新调入内存高速缓存等。假如**进程切换**（process  switch），有时称为**上下文切换**（context switch），需要 1ms，包括切换内存映像、清除和重新调入高速缓存等。再假设时间片设为 4ms。有了这些参数，则 CPU 在做完 4ms 有用的工作之后，CPU 将花费（即浪费）1ms 来进行进程切换。因此，CPU 时间的 20% 浪费在管理开销上。很清楚，这一管理时间太多了。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE62.jpg"/>
</div>

为了提高 CPU 的效率，我们可以将时间片设置成，比方说，100ms，这样浪费的时间只有 1%。但是，如果在一段非常短的时间间隔内到达 50 个请求，并且对 CPU 有不同的需求，那么，考虑一下，在一个服务器系统中会发生什么呢？50 个进程会放在可运行进程的列表中。如果 CPU 是空闲的，第一个进程会立即开始执行，第二个直到 100ms 以后才会启动，以此类推。假设所有其他进程都用足了它们的时间片的话，最不幸的是最后一个进程在获得运行机会之前将不得不等待 5 秒钟。大部分用户会认为 5 秒的响应对于一个短命令来说是缓慢的。如果一些在就绪队列后边的请求仅需要几毫秒的 CPU 时间，上面的情况会变得尤其糟糕。如果使用较短的时间片的话，它们将会获得更好的服务。

另一个因素是，如果时间片设置长于平均的 CPU 突发时间，那么不会经常发生抢占。相反，在时间片耗费完之前多数进程会完成一个阻塞操作，引起进程的切换。抢占的消失改善了性能，因为进程切换只会发生在确实逻辑上有需要的时候，即进程被阻塞不能够继续运行。

可以归结如下结论：时间片设得太短会导致过多的进程切换，降低了 CPU 效率；而设得太长又可能引起对短的交互请求的响应时间变长。将时间片设为 20ms~50ms 通常是一个比较合理的折中。

**2. 优先级调度**

轮转调度做了一个隐含的假设，即所有的进程同等重要，而拥有和操作多用户计算机系统的人对此常有不同的看法。例如，在一所大学里，等级顺序可能是教务长首先，然后是教授、秘书、后勤人员，最后是学生。这种将外部因素考虑在内的需要就导致了**优先级调度**。其基本思想很清楚：每个进程被赋予一个优先级，允许优先级最高的可运行进程先运行。

即使在只有一个用户的 PC 机上，也会有多个进程，其中一些比另一些更重要。例如，与在屏幕上实时显示视频电影的进程相比，在后台发送电子邮件的守护进程应该被赋予较低的优先级。

为了防止高优先级进程无休止地运行下去，调度程序可以在每个时钟滴答（即每个时钟中断）降低当前进程的优先级。如果这个动作导致该进程的优先级低于次高优先级的进程，则进行进程切换。另一种方法是，给每个进程赋予一个允许运行的最大时间片，当用完这个时间片时，次高优先级的进程便获得运行机会。

优先级可以是静态赋予或动态赋予。在一台军用计算机上，可以把将军所启动的进程设为优先级 100，上校为 90，少校为 80，上尉为 70，中尉为 60，以此类推。或者，在一个商业计算中心，高优先级作业每小时费用为 100 美元，中优先级每小时 75 美元，低优先级每小时 50 美元。UNIX 系统中有一条命令 nice，它允许用户为了照顾别人而自愿降低自己进程的优先级。但从未有人用过它。

为达到某种目的，优先级也可以由系统动态确定。例如，有些进程为 I/O 密集型，其多数时间用来等待 I/O 结束。当这样的进程需要 CPU 时，应立即分配给它 CPU，以便启动下一个 I/O 请求，这样就可以在另一个进程计算的同时执行 I/O 操作。使这类 I/O 密集型进程长时间等待 CPU 只会造成它无谓地长时间占用内存。使 I/O 密集型进程获得较好服务的一种简单算法是，将其优先级设为 1/f，f  为该进程在上一时间片中所占的部分。一个在其 50ms 的时间片中只使用 1ms 的进程将获得优先级 50，而在阻塞之前用掉 25ms 的进程将具有优先级 2，而使用掉全部时间片的进程将得到优先级 1。

可以很方便地将一组进程按优先级分成若干类，并且在各类之间采用优先级调度，而在各类进程的内部采用轮转调度。图 2-43 给出了一个有 4 类优先级的系统，其调度算法如下：只要存在优先级为第 4 类的可运行进程，就按照轮转法为每个进程运行一个时间片，此时不理会较低优先级的进程。若第 4 类进程为空，则按照轮转法运行第 3 类进程。若第 4 类和第 3 类均为空，则按轮转法运行第 2 类进程。如果不偶尔对优先级进行调整，则低优先级进程很可能会产生饥饿现象。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE63.jpg"/>
</div>







**3.多级队列**

CTSS（Compatible Time Sharing System），MIT 在 IBM 7094 上开发的兼容分时系统（Corbato 等人，1963），是最早使用优先级调度的系统之一。但是在 CTSS 中存在进程切换速度太慢的问题，其原因是 IBM 7094 内存中只能放进一个进程，每次切换都需要将当前进程换出到磁盘，并从磁盘上读入一个新进程。CTSS 的设计者很快便认识到，为 CPU 密集型进程设置较长的时间片比频繁地分给它们很短的时间片要更为高效（减少交换次数）。另一方面，如前所述，长时间片的进程又会影响到响应时间，其解决方法是设立优先级类。属于最高优先级类的进程运行一个时间片，属于次高优先级类的进程运行 2 个时间片，再次一级运行 4 个时间片，以此类推。当一个进程使用完分配的时间片后，它被移到下一类。

作为一个例子，考虑有一个进程需要连续计算 100 个时间片。它最初被分配 1 个时间片，然后被换出。下次它将获得 2 个时间片，接下来分别是 4、8、16、32 和 64。当然最后一次它只使用 64 个时间片中的 37 个便可以结束工作。该进程需要 7 次交换（包括最初的装入），而如果采用纯粹的轮转算法则需要 100 次交换。而且，随着进程优先级的不断降低，它的运行频率逐渐放慢，从而为短的交互进程让出 CPU。

对于那些刚开始运行一段长时间，而后来又需要交互的进程，为了防止其永远处于被惩罚状态，可以采取下面的策略。只要终端上有回车键（Enter 键）按下，则属于该终端的所有进程都被移到最高优先级，这样做的原因是假设此时进程即将需要交互。但可能有一天，一台 CPU 密集的重载机器上有几个用户偶然发现，只需坐在那里随机地每隔几秒钟敲一下回车键即可以大大提高响应时间。于是他们又告诉他们的朋友。。。。这个故事的寓意是：在实践上可行比理论上可行要困难得多。

**4.最短进程优先**

略

**5.保证调度**

略

**6.彩票调度**

略

**7.公平分享调度**

略



##### 2.4.4   实时系统中的调度

略



##### 2.4.5	策略和机制

到目前为止，我们隐含地假设系统中所有进程分属不同地用户，并且，进程间相互竞争 CPU。通常情况下确实如此，但有时也有这样的情况：一个进程有许多子进程并在其控制下运行。例如，一个数据库系统可能有许多子进程，每一个子进程可能处理不同的请求，或每一个子进程实现不同的功能（如请求分析，磁盘访问等）。主进程完全可能掌握哪一个子进程最重要（或最紧迫）而哪一个最不重要。但是，以上讨论的调度算法中没有一个算法从用户进程接收有关的调度决策信息，这就导致了调度程序很少能够做出最优的选择。

解决问题的方法是将**调度机制**（scheduling mechanism）与**调度策略**（scheduling policy）分离这个一贯的原则（Levin 等人，1975）。也就是将调度算法以某种形式参数化，而参数可以由用户进程填写。再次考虑数据库的例子。假设内核使用优先级调度算法，并提供了一条可供进程设置（并改变）优先级的系统调用。这样，尽管父进程本身并不参与调度，但它可以控制如何调度子进程的细节。在这里，调度机制位于内核，而调度策略则由用户进程决定。策略与机制分离是一种关键性思路。



##### 2.4.6	线程调度

当若干进程都有多个线程时，就存在两个层次的并行：进程和线程。在这样的系统中调度处理有本质差别，这取决于所支持的是用户级线程还是内核级线程（或两者都支持）。

首先考虑用户级线程。由于内核并不知道有线程存在，所以内核还是和以前一样地操作，选取一个进程，假设为 A，并给予 A 以时间片控制。A 中的线程调度程序决定哪个线程运行，假设为 A1。由于多道线程并不存在时钟中断，所以这个线程可以按其意愿任意运行多长时间。如果该线程用完了进程的全部时间片，内核就会选择另一个进程运行。

在进程 A 终于又一次运行时，线程 A1 会接着运行。该线程会继续耗费 A 进程的所有时间，直到它完成工作。不过，该线程的这种不合群的行为不会影响到其他的进程。其他进程会得到调度程序所分配的合适份额，不会考虑进程 A 内部所发生的事。

现在考虑 A 线程每次 CPU 计算的工作比较少的情况，例如，在 50ms 的时间片中有 5ms 的计算工作。于是，每个线程运行一会儿，然后把 CPU 交回给线程调度程序。这样在内核切换到进程 B 之前，就会有序列 A1，A2，A3，A1，A2，A3，A1，A2，A3，A1。这种情形可用图 2-44a 表示。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE64.jpg"/>
</div>

运行时系统使用的调度算法可以是上面介绍的算法中的任意一种。从实用考虑，轮转调度和优先级调度更为常用。唯一的局限是，缺乏一个时钟中断运行过长的线程，但由于线程之间的合作关系，这通常也不是问题。

现在考虑使用内核级线程的情形。内核选择一个特定的线程运行。它不用考虑该线程属于哪个进程，不过如果有必要的话，它可以这样做。对被选择的线程赋予一个时间片，而且如果超过了时间片，就会强制挂起该线程。一个线程在 50ms 的时间片内，5ms 之后被阻塞，在 30ms 的时间段中，线程的顺序可能是 A1，B1，A2，B2，A3，B3（**图是错的**），在这种参数和用户线程状态下，这些情形是不可能出现的。这种情形部分通过图 2-44b 刻画。

用户级线程和内核级线程之间的差别在于性能。用户级线程的线程切换需要少量的机器指令，而内核级线程需要完整的上下文切换，修改内存映像，使高速缓存失效，这导致了若干数量级的延迟。另一方面，在使用内核级线程时，一旦线程阻塞在 I/O 上就不需要像在用户级线程中那样将整个进程挂起。

从进程 A 的一个线程切换到进程 B 的一个线程，其代价高于运行进程 A 的第 2 个线程（因为必须修改内存映像，清除内存高速缓存的内容），内核对此是了解的，并可运用这些信息做出决定。例如，给定两个在其他方面同等重要的线程，其中一个线程与刚好阻塞的线程属于同一个进程，而另一个线程属于其他的进程，那么应该倾向前者。

另一个重要因素是用户级线程可以使用专为应用程序定制的线程调度程序。例如，考虑图 2-8 中的 Web 服务器。假设一个工作线程刚刚被阻塞，而分派线程和另外两个工作线程是就绪的。那么，应该运行哪一个线程呢？由于运行时系统了解所有线程的作用，所以会直接选择分派线程接着运行，这样分派线程就会启动另一个工作线程运行。在一个工作线程经常阻塞在磁盘 I/O 上的环境中，这个策略将并行度最大化。而在内核级线程中，内核从来不了解每个线程的作用（虽然它们被赋予了不同的优先级）。不过，一般而言，应用定制的线程调度程序能够比内核更好地满足应用的需要。



#### 2.5   经典的IPC问题

操作系统文献中有许多广为讨论和分析的有趣问题，它们与同步方法的使用相关。以下几节将讨论其中两个最著名的问题。

##### 2.5.1   哲学家就餐问题

略



##### 2.5.2	读者—写者问题

略



#### 2.6	有关进程与线程的研究

略



#### 2.7	小结

为了隐藏中断的影响，操作系统提供了一个并行执行串行过程的概念模型。进程可以动态地创建和终止，每个进程都有自己的地址空间。

对于某些应用而言，在一个进程中使用多个线程是有益的。这些线程被独立调度并且有独立的栈，但是在一个进程中的所有线程共享一个地址空间。线程可以在用户态实现，也可以在内核态实现。

进程之间通过进程间通信原语来交换信息，如信号量、管程和消息。这些原语用来确保不会有两个进程同时在临界区中，以避免出现混乱。一个进程可以处在运行、就绪或阻塞状态，当该基础你好或其他进程执行某个进程间通信原语时，可以改变其状态。线程间的通信也类似。

进程间通信原语可以用来解决诸如生产者—消费者问题、哲学家就餐问题、读者—写者问题和睡眠理发师问题等。但即便有了这些原语，也要仔细设计才能避免出错和死锁。

目前已经有大量成熟的调度算法。一些算法主要用于批处理系统中，如最短作业优先调度算。其他算法在批处理系统和交互式系统中都很常见，如轮转调度、优先级调度、多级队列调度、有保证调度、彩票调度以及公平分享调度等。有些系统清晰地分离了调度策略和调度机制，使用户可以配置调度算法。





### 第 3 章	内存管理

内存（RAM）是计算机中一种需要认真管理的重要资源。就目前来说，虽然一台普通家用计算机的存储容量已经是 20 世纪 60 年代早期全球最大的计算机 IBM 7094 的存储容量的 10 000 倍以上，但是程序大小的增长速度比内存容量的增长速度要快得多。正如帕金森定律所指出的：“不管存储器有多大，程序都可以把它填满。”在这一章中，我们将讨论操作系统是怎样对存储器创建抽象模型以及怎样管理它们的。

每个程序员都梦想拥有这样的存储区：它是私有的、容量无限大的、速度无限快的，并且是永久性的（即断电时不会丢失数据）。当我们期望这样的存储器时，何不进一步要求它价格低廉呢？遗憾的是，目前的技术还不能为我们提供这样的存储器。也许你会有解决方案。

除此之外的选择是什么呢？经过多年探索，人们提出了**分层存储器体系**（memory hierarchy）的概念，即在这个体系中，计算机有若干兆（MB）快速、昂贵且易失性的高速缓存（cache），数千兆（GB）速度与价格适中且同样易失性的内存，以及几兆兆（TB）低速、廉价、非易失性的磁盘存储，另外还有诸如 DVD 和 USB 等可移动存储装置。操作系统的工作是将这个存储体系抽象为一个有用的模型并管理这个抽象模型。

操作系统中管理分层存储器体系的部分称为**存储管理器**（memory manager）。它的任务是有效地管理内存，即记录哪些内存是正在使用的，哪些内存是空闲的；在进程需要时为其分配内存，在进程使用完后释放内存。

本章我们会研究几个不同的存储管理方案，涵盖非常简单的方案到高度复杂的方案。由于最底层的高速缓存的管理由硬件来完成，本章将集中介绍针对编程人员的内存模型，以及怎样优化管理内存。至于永久性存储器—磁盘—的抽象和管理，则是下一章的主题。我们会从最简单的管理方案开始讨论，并逐步深入到更为缜密的方案。



#### 3.1	无存储器抽象

最简单的存储器抽象就是根本没有抽象。早期大型计算机（20 世纪 60 年代之前）、小型计算机（20 世纪 70 年代之前）和个人计算机（20 世纪 80 年代之前）都没有存储器抽象。每一个程序都直接访问物理内存。当一个程序执行如下指令：

```assembly
MOV REGISTER1, 1000 
```



计算机会将位置为 1000 的物理内存中的内容移到 REGISTER1 中。因此，那时呈现给编程人员的存储器模型就是简单的物理内存：从 0 到某个上限的地址集合，每一个地址对应一个可容纳一定数目二进制位的存储单元，通常是 8 个。

在这种情况下，要想在内存中同时运行两个程序是不可能的。如果第一个程序在 2000 的位置写入一个新的值，将会擦掉第二个程序存放在相同位置上的所有内容，所以同时运行两个程序是根本行不通的，这两个程序会立刻崩溃。

不过即使存储器模型就是物理内存，还是存在一些可行选项的。图 3-1 展示了三种变体。在图 3-1a 中，操作系统位于 RAM（随机访问存储器）的底部；在图 3-1b 中，操作系统位于内存顶端的 ROM（只读存储器）中；而在图 3-1c 中，设备驱动程序位于内存顶端的 ROM 中，而操作系统的其他部分则位于下面的 RAM 的底部。第一种方案以前被用在大型机和小型计算机上，现在很少使用了。第二种方案被用在一些掌上电脑和嵌入式系统中。第三种方案用于早期的个人计算机中（例如运行 MS-DOS 的计算机），在 ROM 中的系统部分称为 BIOS（Basic Input Output System，基本输入输出系统）。第一种方案和第三种方案的缺点是用户程序出现的错误可能摧毁操作系统，引发灾难性后果。

当按这种方式组织系统时，通常同一个时刻只能有一个进程在运行。一旦用户键入了一个命令，操作系统就把需要的程序从磁盘复制到内存中并执行；当进程运行结束后，操作系统在用户终端显示提示符并等待新的命令。收到新的命令后，它把新的程序装入内存，覆盖前一个程序。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE65.jpg"/>
</div>

在没有存储器抽象的系统中实现并行的一种方法是使用多线程来编程。由于在引入线程时就假设一个进程中的所有线程对同一内存映像都可见，那么实现并行也就不是问题了。虽然这个想法行得通，但却没有被广泛使用，因为人们通常希望能够在同一时间运行没有关联的程序，而这正是线程抽象所不能提供的。更进一步地，一个没有存储器抽象的系统也不大可能具有线程抽象的功能。

**在不使用存储器抽象的情况下运行多个程序**

但是，即使没有存储器抽象，同时运行多个程序也是可能的。操作系统只需要把当前内存中所有内容保存到磁盘文件中，然后把下一个程序读入到内存中再运行即可。只要在某一个时间内存中只有一个程序，那么就不会发生冲突。这样的交换概念会在下面讨论。

在特殊硬件的帮助下，即使没有交换功能，并发地运行多个程序也是可能的。IBM 360 的早期模型是这样解决的：内存被划分为 2KB 的块，每个块被分配一个 4 位的保护键，保护键存储在 CPU 的特殊寄存器中。一个内存为 1MB 的机器只需要 512 个这样的 4 位寄存器，容量总共为 256 字节。PSW（Program Status Word，程序状态字）中存有一个 4 位码。一个运行中的进程如果访问保护键与其 PSW 码不同的内存，360 的硬件会捕获到这一事件。因为只有操作系统可以修改保护键，这样就可以防止用户进程之间、用户进程和操作系统之间的互相干扰。

然而，这种解决方法有一个重要的缺陷。如图 3-2 所示，假设有两个程序，每个大小各为 16KB，如图 3-2a 和图 3-2b 所示。前者加了阴影表示它和后者使用不同的内存键。第一个程序一开始就跳转到地址 24，那里是一条 MOV 指令。第二个程序一开始跳转到地址 28，那里是一条 CMP 指令。与讨论无关的指令没有画出来。当两个程序被连续地装载到内存中从 0 开始的地址时，内存中的状态就如同图 3-2c 所示。在这个例子里，我们假设操作系统是在高地址处，图中没有画出来。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE66.jpg"/>
</div>

程序装载完毕之后就可以运行了。由于它们的内存键不同，它们不会破坏对方的内存。但在另一方面会发生问题。当第一个程序开始运行时，它执行了 JMP 24 指令，然后不出预料地跳转到了相应的指令，这个程序会正常运行。

但是，当第一个程序已经运行了一段时间后，操作系统可能会决定开始运行第二个程序，即装载在第一个程序之上的地址 16 384 处的程序。这个程序的第一条指令是 JMP 28，这条指令会使程序跳转到第一个程序的 ADD 指令，而不是事先设定的跳转到 CMP 指令。由于对内存地址的不正确访问，这个程序很可能在 1 秒之内就崩溃了。

这里关键的问题是这两个程序都引用了绝对物理地址，而这正是最需要避免的。我们希望每个程序都使用一套私有的本地地址来进行内存寻址。下面我们会展示这种技术是如何实现的。IBM 360 对上述问题的补救方案就是在第二个程序装载到内存的时候，使用**静态重定位**的技术修改它。它的工作方式如下：当一个程序被装载到地址 16384 时，常数 16384 被加到每一个程序地址上。虽然这个机制在不出错误的情况下是可行的，但这不是一种通用的解决办法，同时会减慢装载速度。而且，它要求给所有的可执行程序提供额外的信息来区分哪些内存字中存有（可重定位的）地址，哪些没有。毕竟，图 3-2b 中的 “28” 需要被重定位，但是像

```assembly
MOV REGISTER1，28 
```



这样把数 28 送到 REGISTER1 的指令不可以被重定位。装载器需要一定的方法来辨别地址和常数。

最后，正如我们在第 1 章中指出的，计算机世界的发展总是倾向于重复历史。虽然直接引用物理地址对于大型计算机、小型计算机、台式计算机和笔记本电脑来说已经成为很久远的记忆了（对此我们深表遗憾），但是缺少存储器抽象的情况在嵌入式系统和智能卡系统中还是很常见的。现在，像收音机、洗衣机和微波炉这样的设备都已经完全被（ROM 形式的）软件控制，在这些情况下，软件都采用访问绝对内存地址的寻址方式。在这些设备中这样能够正常工作是因为，所有运行的程序都是可以事先确定的，用户不可能在烤面包机上自由地运行他们自己的软件。

虽然高端的嵌入式系统（比如智能手机）有复杂的操作系统，但是一般的简单嵌入式系统并非如此。在某些情况下可以用一种简单的操作系统，它只是一个被链接到应用程序的库，该库为程序提供 I/O 和其他任务所需要的系统调用。操作系统作为库实现的常见例子如流行的 e-Cos 操作系统。



#### 3.2	一种存储器抽象：地址空间

总之，把物理地址暴露给进程会带来下面几个严重问题。第一，如果用户程序可以寻址内存的每个字节，它们就可以很容易地（故意地或偶然地）破坏操作系统，从而使系统慢慢地停止运行（除非使用特殊的硬件进行保护，如 IBM 360 的锁键模式）。即使在只有一个用户进程运行的情况下，这个问题也是存在的。第二，使用这种模型，想要同时运行（如果只有一个 CPU 就轮流执行）多个程序是很困难的。在个人计算机上，同时打开几个程序是很常见的（一个文字处理器，一个邮件程序，一个网络浏览器），其中一个当前正在工作，其余的在按下鼠标的时候才会被激活。在系统中没有对物理内存的抽象的情况下，很难实现上述情景，因此，我们需要其他办法。



**3.2.1   地址空间的概念**

要使多个应用程序同时处于内存中并且不互相影响，需要解决两个问题：保护和重定位。我们来看一个原始的对前者的解决办法，它曾被用在 IBM 360 上：给内存块标记上一个保护键，并且比较执行进程的键和其访问的每个内存字的保护键。然而，这种方法本身并没有解决后一个问题，虽然这个问题可以通过在程序被装载时重定位程序来解决，但这是一个缓慢且复杂的解决方法。

一个更好的办法是创造一个新的存储器抽象：地址空间。就像进程的概念创造了一类抽象的 CPU 以运行程序一样，地址空间为程序创造了一种抽象的内存。**地址空间**是一个进程可用于寻址内存的一套地址集合。每个进程都有一个自己的地址空间，并且这个地址空间独立于其他进程的地址空间（除了在一些特殊情况下进程需要共享它们的地址空间外）。

地址空间的概念非常通用，并且在很多场合中出现。比如电话号码，在美国和很多其他国家，一个本地电话号码通常是一个 7 位的数字。因此，电话号码的地址空间是从 0 000 000 到 9 999 999，虽然一些号码并没有被使用，比如以 000 开头的号码。随着手机、调制解调器和传真机数量的增长，这个空间变得越来越不够用了，从而导致需要使用更多位数的号码。x86 的 I/O 端口的地址空间从 0 到 16 383。IPv4 的地址是 32 位的数字，因此它们的地址空间从 0 到 232-1（也有一些保留数字）。

地址空间也可以是非数字的，以 “.com” 结尾的网络域名的集合也是地址空间。这个地址空间是由所有包含 2~63 个字符并且后面跟着 “.com” 的字符串组成的，组成这些字符串的字符可以是字母、数字和连字符。到现在你应该已经明白地址空间的概念了，它是很简单的。

比较难的是给每个程序一个自己独有的地址空间，使得一个程序中的地址 28 所对应的物理地址与另一个程序中的地址 28 所对应的物理地址不同。下面我们将讨论一个简单的方法，这个方法曾经很常见，但是在有能力把更复杂（而且更好）的机制运用在现代 CPU 芯片上之后，这个方法就不再使用了。

**基址寄存器与界限寄存器**

界限寄存器（Limit Registers）的使用方法：
    1.在 CPU 中设置一对下限寄存器和上限寄存器,存放正在执行的程序在主存中的下限和上限地址。
    2.可将一个寄存器作为基址寄存器，另一寄存器作为限长寄存器（指示存储区长度）每当 CPU 要访问主存，硬件自动将被访问的主存地址与界限寄存器的内容进行比较，以判断是否越界。如果未越界，则按此地址访问主存，否则将产生程序中断——越界中断（存储保护中断）。

这个简单的解决办法是使用**动态重定位**，简单地把每个进程的地址空间映射到物理内存的不同部分。从 CDC 6600（世界上最早的超级计算机）到 Intel 8088（原始 IBM PC 的心脏），所使用的经典办法是给每个 CPU 配置两个特殊硬件寄存器，通常叫作**基址寄存器**（BX）和**界限寄存器**。当使用基址寄存器和界限寄存器时，程序装载到内存中连续的空闲位置且装载期间无须重定位，如图 3-2c 所示。当一个进程运行时，程序的起始物理地址装载到基址寄存器中，程序的长度装载到界限寄存器中。在图 3-2c 中，当第一个程序运行时，装载到这些硬件寄存器中的基址和界限值分别是 0 和 16 384。当第二个程序运行时，这些值分别是 16 384 和 32 768。如果第三个 16KB 的程序被直接装载在第二个程序的地址之上并且运行，这时基址寄存器和界限寄存器里的值会是 32 768 和 16 384。

每次一个进程访问内存，取一条指令，读或写一个数据字，CPU 硬件会在把地址发送到内存总线前，自动把基址值加到进程发出的地址值上。同时，它检查程序提供的地址是否等于或大于界限寄存器里的值。如果访问的地址超过了界限，会产生错误并中止访问。这样，对图 3-2c 中第二个程序的第一条指令，程序执行

```
JMP 28 
```

指令，但是硬件把这条指令解释成

```
JMP 16412 
```

所以程序如我们所愿地跳转到了 CMP 指令。在图 3-2c 中第二个程序的执行过程中，基址寄存器和界限寄存器的设置如图 3-3 所示。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE67.jpg"/>
</div>

使用基址寄存器和界限寄存器是给每个进程提供私有地址空间的非常容易的方法，因为每个内存地址在送到内存之前，都会自动先加上基址寄存器的内容。在很多实际系统中，对基址寄存器和界限寄存器会以一定的方式加以保护，使得只有操作系统可以修改它们。在 CDC 6600 中就提供了对这些寄存器的保护，但在 Intel 8088 中则没有，甚至没有界限寄存器。但是，Intel 8088 提供了多个基址寄存器，使程序的代码和数据可以被独立地重定位，但是没有提供引用地址越界的预防机制。

使用基址寄存器和界限寄存器重定位的缺点是，每次访问内存都需要进行加法和比较运算。比较运算可以做得很快，但是加法运算由于进位传递时间的问题，在没有使用特殊电路的情况下会显得很慢。



##### 3.2.3	交换技术

如果计算机物理内存足够大，可以保存所有进程，那么之前提及的所有方案都或多或少是可行的。但实际上，所有进程所需的 RAM 数量总和通常要远远超出存储器能够支持的范围。在一个典型的 Windows、OS X 或 Linux 系统中，在计算机完成引导后会启动 50~100 个甚至更多的进程。例如，当一个 Windows 应用程序安装后，通常会发出一系列命令，使得在此后的系统引导中会启动一个仅仅用于查看该应用程序更新的进程。这样一个进程会轻易地占据 5~10MB 的内存。其他后台进程还会查看所收到的邮件和进来的网络连接，以及其他很多诸如此类的任务。并且，这一切都发生在第一个用户程序启动之前。当前重要的应用程序如 Photoshop 一启动就轻易地占据 500MB 内存，而开始处理数据后可能需要数千兆字节（GB）的空间。因此，把所有进程一直保存在内存中需要巨大的内存，如果内存不够，就做不到这一点。

有两种处理内存超载的通用方法。最简单的策略是**交换**（swapping）技术，即把一个进程完整调入内存，使该进程运行一段时间，然后把它存回磁盘。空闲进程主要存储在磁盘上，所以当它们不运行时就不会占用内存（尽管其中的一些进程会周期性地被唤醒以完成相关工作，然后就又进入睡眠状态）。另一种策略是**虚拟内存**（virtual memory），该策略甚至能使程序在只有一部分被调入内存的情况下运行。下面先讨论交换技术，3.3 节我们将考察虚拟内存。

交换系统的操作如图 3-4 所示。开始时内存中只有进程 A。之后创建进程 B 和 C 或者从磁盘将它们换入内存。图 3-4d 显示 A 被交换到磁盘。然后 D 被调入，B 被调出，最后 A 再次被调入。由于 A 的位置发生变化，所以在它换入的时候通过软件或者在程序运行期间（多数是这种情况）通过硬件对其地址进行重定位。例如，基址寄存器和界限寄存器就适用于这种情况。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE68.jpg"/>
</div>

交换在内存中共产生了多个空闲区（hole，也称为空洞），通过把所有的进程尽可能向下移动，有可能将这些小的空闲区合成一大块。该技术称为**内存紧缩**（memory compaction）。通常不进行这个操作，因为它要耗费大量的 CPU 时间。例如，一台有 16GB 内存的计算机可以每 8ns 复制 8 个字节，它紧缩全部内存大约要花费 16s。

有一个问题值得注意，即当进程被创建或换入时应该为它分配多大的内存。若进程创建时其大小是固定的并且不再改变，则分配很简单，操作系统准确地按其所需的大小进行分配，不多也不少。

但是如果进程的数据段可以增长，例如，很多程序设计语言都允许从堆中动态地分配内存，那么当进程空间试图增长时，就会出现问题。若进程与一个空闲区相邻，那么可把该空闲区分配给进程供其增大。另一方面，若进程相邻的是另一个进程，那么要么把需要增长的进程移到内存中一个足够大的区域中去，要么把一个或多个进程交换出去，以便生成一个足够大的空闲区。若一个进程在内存中不能增长，而且磁盘上的交换区也已满了，那么这个进程只有挂起直到一些空间空闲（或者可以结束该进程）。

如果大部分进程在运行时都要增长，为了减少因内存区域不够而引起的进程交换和移动所产生的开销，一种可用的方法是，当换入或移动进程时为它分配一些额外的内存。然而，当进程被换出到磁盘上时，应该只交换进程实际上使用的内存中的内容，将额外的内存交换出去是一种浪费。在图 3-5a 中读者可以看到一种已为两个进程分配了增长空间的内存配置。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE69.jpg"/>
</div>

如果进程有两个可增长的段，例如，供变量动态分配和释放的作为堆使用的一个数据段，以及存放普通局部变量与返回地址的一个栈段，则可使用另一种安排，如图 3-5b 所示。在此图中，我们看到所示的每个进程在其分配的内存顶部都有一个堆栈，该堆栈向下增长，而一个数据段恰好在程序文本上方，向上增长。在这两者之间的内存可以供两个段使用。如果用完了，进程或者必须移动到足够大的空闲区中（它可以被交换出内存直到内存中有足够的空间），或者结束该进程。



##### 3.2.3	空闲内存管理

在动态分配内存时，操作系统必须对其进行管理。一般而言，有两种方法跟踪内存使用情况：位图和空闲区链表。在本节和下一节中将介绍这两种方法。第 10 章将详细介绍 Linux 系统中使用的一些特定的内存分配器（如伙伴分配器和 slab 分配器）。

**1.使用位图的存储管理**

在使用位图方法时，内存可能被划分成小到几个字或大到几千字节的分配单元。每个分配单元对应于位图中的一位，0 表示空闲，1 表示占用（或者相反）。一块内存区和其对应的位图如图 3-6 所示。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE70.jpg"/>
</div>

分配单元的大小是一个重要的设计因素。分配单元越小，位图越大。然而即使只有 4 个字节大小的分配单元，32 位的内存也只需要位图中的 1 位。32n 位的内存需要 n 位的位图，所以位图只占用了 1/32 的内存。若选择比较大的分配单元，则位图更小。但若进程的大小不是分配单元的整数倍，那么在最后一个分配单元中就会有一定数量的内存被浪费了。

因为内存的大小和分配单元的大小决定了位图的大小，所以它提供了一种简单的利用一块固定大小的内存区就能对内存使用情况进行记录的方法。这种方法的主要问题是，在决定把一个占 k 个分配单元的进程调入内存时，存储管理器必须搜索位图，在位图中找出有 k 个连续 0 的串。**查找位图中指定长度的连续 0 串是耗时的操作（因为在位图中该串可能跨越字的边界），这是位图的缺点。**

**2.使用链表的存储管理**

另一种记录内存使用情况的方法是，维护一个记录已分配内存段和空闲内存段的链表。其中链表中的一个节点或者包含一个进程，或者是两个进程间的一块空闲区。可用图 3-6c 所示的段链表来表示图 3-6a 所示的内存布局。链表中的每一个结点都包含以下域：空间区（H）或进程（P）的指示标志、起始地址、长度和指向下一结点的指针。

在本例中，段链表是按照地址排序的，其好处是当进程终止或被换出时链表的更新非常直接。一个要终止的进程一般有两个邻居（除非它是在内存的最低端或最顶端），它们可能是进程也可能是空闲区，这就导致了图 3-7 所示的四种组合。在图 3-7a 中更新链表需要把 P 替换为 H；在图 3-7b 和图 3-7c 中两个结点被合并为一个，链表少了一个结点；在图 3-7d 中三个结点被合并为一个，从链表中删除了两个结点。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE71.jpg"/>
</div>

进程表中表示终止进程的结点中通常含有指向对应于其锻链表结点的指针，因此段链表使用双向链表可能要比图 3-6c 所示的单向链表更方便。这样的结构更易于找到上一个结点，并检查是否可以合并。

当按照地址顺序在链表中存放进程和空闲区时，有几种算法可以用来为创建的进程（或从磁盘换入的已存在的进程）分配内存。这里，假设存储管理器知道要为进程分配多少内存。最简单的算法是**首次适配**（first fit）算法。存储管理器沿着段链表进行搜索，直到找到一个足够大的空闲区，除非空闲区大小和要分配的空间大小正好一样，否则将该空闲区分为两部分，一部分供进程使用，另一部分形成新的空闲区。首次适配算法是一种速度很快的算法，因为它尽可能少地搜索链表结点。

对首次始配算法进行很小的修改就可以得到**下次适配**（next fit）算法。它的工作方式和首次适配算法相同，不同点是每次找到合适的空闲区时都记录当时的位置，以便在下次寻找空闲区时从上次结束的地方开始搜索，而不是像首次适配算法那样每次都从头开始。Bays（1977）的仿真程序证明下次适配算法的性能略低于首次适配算法。

另一个著名的并广泛应用的算法时**最佳适配**（best fit）算法。最佳适配算法搜索整个链表（从开始到结束），找出能够容纳进程的最小的空闲区。最佳适配算法试图找出最接近实际需要的空闲区，以最好地匹配请求和可用空闲区，而不是先拆分一个以后可能会用到的大的空闲区。

以图 3-6 为例来考察首次适配算法和最佳适配算法。假如需要一个大小为 2 的块，首次适配算法将分配在位置 5 的空闲区，而最佳适配算法将分配在位置 18 的空闲区。

因为每次调用最佳适配算法时都要搜索整个链表，所以它要比首次适配算法慢。让人感觉有点意外的是，它比首次适配算法或下次适配算法浪费更多的内存，因为它会产生大量无用的小空闲区。一般情况下，首次适配算法生成的空闲区更大一些。

最佳适配的空闲区会分裂出很多非常小的空闲区，为了避免这一问题，可以考虑**最差适配**（worst fit）算法，即总是分配最大的可用空闲区，使新的空闲区比较大从而可以继续使用。仿真程序表明最差适配算法也不是一个好主意。

如果为进程和空闲区维护各自独立的链表，那么这四个算法的速度都能得到提高。这样就能集中精力只检查空闲区而不是进程。但这种分配速度的提高的一个不可避免的代价就是增加复杂度和内存释放速度变慢，因为必须将一个回收的段从进程链表中删除并插入空闲区链表。

如果进程和空闲区使用不同的链表，则可以按照大小对空闲区链表排序，以便提高最佳适配算法的速度。在使用最佳适配算法搜索从小到大排列的空闲区链表时，只要找到一个合适的空闲区，则这个空闲区就是能容纳这个作业的最小的空闲区，因此是最佳适配。因为空闲区链表以单链表形式组织，所以不需要进一步搜索。空闲区链表按大小排序时，首次适配算法与最佳适配算法一样快，而下次适配算法在这里则毫无意义。

在与进程段分离的单独链表中保存空闲区时，可以作一个小小的优化，不必像图 3-6c 那样用单独的数据结构存放空闲区链表，而可以利用空闲区存储这些信息。每个空闲区的第一个字可以是空闲区大小，第二个字指向下一个空闲区。于是就不再需要图 3-6c 中所示的那些三个字加一位（P/H）的链表结点了。

另一种分配算法称为**快速适配**（quick fit）算法，它为那些常用大小的空闲区维护单独的链表。例如，有一个 n 项的表，该表的第一项是指向大小为 4KB 的空闲区链表表头的指针，第二项是指向大小为 8KB 的空闲区链表表头的指针，第三项是指向大小为 12KB 的空闲区链表表头的指针，以此类推。像 21KB 这样的空闲区可以放在 20KB 的链表中，也可以放在一个专门存放大小比较特别的空闲区的链表中。

快速适配算法查找一个指定大小的空闲区是十分快速的，但它和所有将空闲区按大小排序的方案一样，都有一个共同的缺点，即在一个进程终止或被换出时，寻找它的相邻块并查看是否可以合并的过程是非常费时的。如果不进行合并，内存将会很快分裂出大量的进程无法利用的小空闲区。



#### 3.3	虚拟内存

尽管基址寄存器和界限寄存器可以用于创建地址空间的抽象，还有另一个问题需要解决：管理软件的膨胀（bloatware）。虽然存储器容量增长快速，但是软件大小的增长更快。在 20 世纪 80 年代，许多大学用一台 4MB 的 VAX 计算机运行分时操作的系统，供十几个用户（已经或多或少足够满足需要了）同时运行。现在微软公司推荐 64 位 Windows 8 系统至少需要 2GB 内存，而多媒体的潮流则进一步推动了对内存的需求。

这一发展的结果是，需要运行的程序往往大到内存无法容纳，而且必然需要系统能够支持多个程序同时运行，即使内存可以满足其中单独一个程序的需要，总体来看它们仍然超出了内存大小。交换技术并不是一个具有吸引力的解决方案，因为一个典型 SATA 磁盘的峰值传输率高达每秒好几百兆，这意味着需要好几秒才能换出或换入一个 1GB 的程序。

程序大于内存的问题早在计算时代伊始就产生了，虽然只是有限的应用领域，像科学和工程计算（模拟宇宙的创建或模拟新型航空器都会花费大量内存）。在 20 世纪 60 年代所采取的解决方法是：把程序分割成许多片段，称为**覆盖**（overlay）。程序开始执行时，将覆盖管理模块装入内存，该管理模块立即装入并运行覆盖 0。执行完成后，覆盖 0 通知管理模块装入覆盖 1，或者占用覆盖 0 的上方位置（如果有空间），或者占用覆盖 0（如果没有空间）。一些覆盖系统非常复杂，运行多个覆盖块同时在内存中。覆盖快存放在磁盘上，在需要时由操作系统动态地换入换出。

虽然由系统完成实际的覆盖快换入换出操作，但是程序员必须把程序分割成多个片段。把一个大程序分割成小的、模块化的片段时非常费时和枯燥的，并且易于出错。很少程序擅长使用覆盖技术。因此，没过多久就有人找到一个办法，把全部工作都交给计算机去做。

采用的这个方法（Fotheringham，1961）称为**虚拟内存**（virtual memory）。虚拟内存的基本思想是：每个程序都拥有自己的地址空间，这个空间被分割成多个块，每一块称作一**页**或**页面**（page）。每一页有连续的地址范围。这些页被映射到物理内存，但并不是所有的页都必须同时在内存中才能运行程序。当程序引用其地址空间的一部分在物理内存中时，硬件将即时执行必要的映射。 当程序引用其地址空间中不在物理内存中的一部分时，将通知操作系统，由操作系统负责将缺失的部分装入物理内存并重新执行失败的指令。

从某个角度来讲，虚拟内存是对基址寄存器和界限寄存器的一种综合。8088 为正文和数据分离出专门的基址寄存器（但不包括界限寄存器）。而虚拟内存使得整个地址空间可以用相对较小的单元映射到物理内存，而不是为正文段和数据段分别进行重定位。下面会介绍虚拟内存是如何实现的。

虚拟内存很适合在多道程序设计系统中使用，许多程序的片段同时保存在内存中。第一个程序等待它的一部分读入内存时，可以把 CPU 交给另一个进程使用。



##### 3.3.1	分页

大部分虚拟内存系统中都使用一种称为分页（paging）的技术，我们现在就介绍这一技术。在任何一台计算机上，程序引用了一组内存地址。当程序执行指令

MOV REG, 1000

时，它把地址为 1000 的内存单元的内容复制到 REG 中（或者相反，这取决于计算机的型号）。地址可以通过索引、基址寄存器、段寄存器或其他方式产生。

由程序产生的这些地址称为**虚拟地址**（virtual address），它们构成了一个**虚拟地址空间**（virtual address space）。在没有虚拟内存的计算机上，系统直接将虚拟地址送到内存总线上，读写操作使用具有同样地址的物理内存字；而在使用虚拟内存的情况下，虚拟地址不是被直接送到内存总线上，而是被送到**内存管理单元**（Memory Management Unit，MMU），MMU 把虚拟地址映射为物理内存地址，如图 3-8 所示。

图 3-9 所示的简单例子说明了这种映射是如何工作的。在这个例子中，有一台可以产生 16 位地址的计算机，地址范围从 0 到 64K-1，且这些地址是虚拟地址。然而，这台计算机只有 32KB 的物理内存，因此，虽然可以编写 64KB 的程序，但它们却不能被完全调入内存运行。在磁盘上必须有一个最多 64KB 的程序核心映像的完整副本，以保证程序片段在需要时能被调入内存。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE72.jpg"/>
</div>

虚拟地址空间按照固定大小划分成被称为页面（page）的若干单元。在物理内存中对应的单元称为**页框**（page frame）。页面和页框的大小通常是一样的，在本例中是 4KB，但实际系统中的页面大小从 512 字节到 1GB。对应于 64KB 的虚拟地址空间和 32KB 的物理内存，可得到 16 个虚拟页面和 8 个页框。RAM 和磁盘之间的交换总是以整个页面为单元进行的。很多处理器根据操作系统认为适合的方式，支持对不同大小页面的混合使用和匹配。例如，x86-64 架构的处理器支持 4KB、2MB 和 1GB 大小的页面，因此，可以将一组 4KB 大小的页面用于用户程序，将一个 1GB 大小的页面用于内核程序。稍后将介绍为什么有时候用一个较大的页面好于用一堆较小的页面。

图 3-9 中的标记符号如下：标记 0K~4K 的范围表示该页的虚拟地址或物理地址是 0~4095， 4K~8K 的范围表示地址 4096~8191，等等。每一页包含了 4096 个地址，起始于 4096 的整数倍位置，结束于 4096 倍数缺 1 的位置。

当程序试图访问地址 0 时，例如执行下面这条指令

```assembly
MOV  REG, 0
```

将虚拟地址 0 送到 MMU。MMU 看到虚拟地址落在页面 0，根据其映射结果，这一页面对应的是页框 2（8192~12 287），因此MMU把地址变换为 8192，并把地址 8192 送到总线上。内存对 MMU 一无所知，它只看到一个读或写地址 8192 的请求并执行它。MMU 从而有效地把所有从 0~4095 的虚拟地址映射到了 8192~12 287 的物理地址。

同样地，指令

```assembly
MOV  REG, 8192 
```

被有效地转换为：

```assembly
MOV  REG, 24576 
```

因为虚拟地址 8192（在虚拟页面 2 中）被映射到物理地址 24 576（在物理页框 6 中）上。第三个例子，虚拟地址 20 500 在距虚拟页面 5（虚拟地址 20 480~24 575）起始地址 20 字节处，并且被映射到物理地址 12 288＋20＝12 308。

通过恰当地设置 MMU，可以把 16 个虚拟页面映射到 8 个页框中的任何一个。但是这并没有解决虚拟地址空间比物理内存大的问题。在图 3-9 中只有 8 个物理页框，于是只有 8 个虚拟页面被映射到了物理内存中，在图 3-9 中用叉号表示的其他页面并没有被映射。在实际的硬件中，用一个“在/不在”位（present/absent bit）记录页面在内存中的实际存在情况。

当程序访问了一个未映射的页面，例如执行指令

```assembly
MOV  REG，32780 
```

将会发生什么情况呢？虚拟页面 8（从 32 768 开始）的第 12 个字节所对应的物理地址是什么呢？MMU 注意到该页面没有被映射（在图中用叉号表示），于是使 CPU 陷入到操作系统，这个陷阱称为**缺页中断**或**缺页错误**（page fault）。操作系统找到一个很少使用的页框且把它的内容写入磁盘（如果它不在磁盘上）。随后把需要访问的页面读到刚才回收的页框中，修改映射关系，然后重新启动引起陷阱的指令。

例如，如果操作系统决定放弃页框 1，那么它将把虚拟页面 8 装入物理地址 4096，并对 MMU 映射做两处修改。首先，它要将虚拟页面 1 的表项标记为未映射，使以后任何对虚拟地址 4096~8191 的访问都导致陷阱。随后把虚拟页面 8 的表项的叉号改为 1，因此在引起陷阱的指令重新启动时，它将把虚拟地址 32 780 映射为物理地址 4108（4096+12）。

下面查看一下 MMU 的内部结构以便了解它是怎么工作的，以及了解为什么我们选用的页面大小都是 2 的整数次幂。在图 3-10 中可以看到一个虚拟地址的例子，虚拟地址 8196（二进制是0010000000000100）用图 3-9 所示的 MMU 映射机制进行映射，输入的 16 位虚拟地址被分为 4 位的页号和 12 位的偏移量。4 位的页号可以表示 16 个页面，12 位的偏移可以为一页内的全部 4096 个字节编址。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE73.jpg"/>
</div>

可用页号作为**页表**（page table）的索引，以得出对应于该虚拟页面的页框号。如果“在/不在”位是 0，则将引起一个操作系统陷阱。如果该位是 1，则将在页表中查到的页框号复制到输出寄存器的高 3 位中，再加上输入虚拟地址中的低 12 位偏移量。如此就构成了 15 位的物理地址。输出寄存器的内容随即被作为物理地址送到内存总线。



##### 3.3.2	页表

作为一种最简单的实现，虚拟地址到物理地址的映射可以概括如下：虚拟地址被分成虚拟页号（高位部分）和偏移量（低位部分）两部分。例如，对于 16 位地址和 4KB 的页面大小，高 4 位可以指定 16 个虚拟页面中的一页，而低 12 位接着确定了所选页面中的字节偏移量（0~4095）。但是使用 3 或者 5 或者其他位数拆分虚拟地址也是可行的。不同的划分对应不同的页面大小。

虚拟页号可用作页表的索引，以找到该虚拟页面对应的页表项。由页表项可以找到页框号（如果有的话）。然后把页框号拼接到偏移量的高位端，以替换掉虚拟页号，形成送往内存的物理地址。

页表的目的是把虚拟页面映射为页框。从数学角度说，页表是一个函数，它的参数是虚拟页号，结果是物理页框号。通过这个函数可以把虚拟地址中的虚拟页面域替换成页框域，从而形成物理地址。

在本章中，我们只关心虚拟内存和不完全虚拟化，换言之，不涉及虚拟机。我们在第 7 章中将会看到，每个虚拟机都需要自己的虚拟内存，因此页表组织变得很复杂，包括影子页表和嵌套页表。我们会看到，即便没有这些复杂的配置，页面调度和虚拟内存也相当复杂。

**页表项的结构**

下面将讨论单个页表项的细节。页表项的结构是与机器密切相关的，但不同机器的页表项存储的信息都大致相同。图 3-11 给出了页表项的一个例子。不同计算机的页表项大小可能不一样，但 32 位是一个常用的大小。最重要的域是**页框号**。毕竟页映射的目的是找到这个值，其次是 ”在/不在“ 位。这一位是 1 时表示该表项是有效的，可以使用；如果是 0，则表示该表项对应的虚拟页面现在不在内存中，访问该页面会引起一个缺页中断。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE74.jpg"/>
</div>

**保护**（protection）位指出一个页允许什么类型的访问。最简单的形式是这个域只有一位，0 表示读/写，1 表示只读。一个更先进的方法是使用三位，各位分别对应是否启动读、写、执行该页面。

为了记录页面的使用状况，引入了**修改**（modified）位和**访问**（referenced）位。在写入一页时由硬件自动设置修改位。该位在操作系统重新分配页框时是非常有用的。如果一个页面已经被修改过（即它是“脏”的），则必须把它写回磁盘。如果一个页面没有被修改过（即它是“干净”的），则只简单地把它丢弃就可以了，因为它在磁盘上的副本仍然是有效的。这一位有时也被称为脏位（dirty bit），因为它反映了该页面的状态。

不论是读还是写，系统都会在该页面被访问时设置**访问**位。它的值被用来帮助操作系统在发生缺页中断时选择要被淘汰的页面。不再使用的页面要比正在使用的页面更适合淘汰。这一位在即将讨论的很多页面置换算法中都会起到重要的作用。

最后一位用于禁止该页面被高速缓存。对那些映射到设备寄存器而不是常规内存的页面而言，这个特性是非常重要的。假如操作系统正在紧张地循环等待某个 I/O 设备对它刚发出的命令作出响应，保证硬件是不断地从设备中读取数据而不是访问一个旧的被高速缓存的副本是非常重要的。通过这一位可以禁止高速缓存。具有独立的 I/O 空间而不使用内存映射 I/O 的机器不需要这一位。

应该注意的是，当页面不在内存中时用于保存页面的磁盘地址不是页面表的一部分。 原因很简单。 页表仅包含硬件将虚拟地址转换为物理地址所需的信息。操作系统在处理缺页中断时需要把该页面的磁盘地址等信息保存在操作系统内部的软件表格中。硬件不需要它。

在深入到更多应用实现问题之前，值得再次强调的是：虚拟内存本质上是用来创造一个新的抽象概念——地址空间，这个概念是对物理内存的抽象，类似于进程是对物理处理器（CPU）的抽象。虚拟内存的实现，是将虚拟地址空间分解成页，并将每一页映射到物理内存的某个页框或者（暂时）解除映射。因此，本节的基本内容是操作系统创建的抽象，以及如何管理这个抽象。



##### 3.3.3	加速分页过程

我们已经了解了虚拟内存和分页的基础。现在可以更具体地讨论可能的实现了。在任何分页系统中，都需要考虑两个主要问题：

1) 虚拟地址到物理地址的映射必须非常快。

2) 如果虚拟地址空间很大，页表也会很大。

第一个问题是由于每次访问内存都需要进行虚拟地址到物理地址的映射，所有的指令最终都必须来自来存，并且很多指令也会访问内存中的操作数。因此，每条指令进行一两次或更多页表访问是必要的。如果执行一条指令需要 1ns，页表查询必须在 0.2ns 之内完成，以避免映射成为一个主要瓶颈。

第二个问题来自现代计算机使用至少 32 位的虚拟地址，而且 64 位变得越来越普遍。假设页面大小为 4KB，32 位的地址空间将有 100 万页，而 64 位地址空间简直多到超乎你的想象。如果虚拟地址空间中有 100 万页，那么页表必然有 100 万条表项。另外请记住，每个进程都需要自己的页表（因为它有自己的虚拟地址空间）。

对大而快速的页映射的需求成为构建计算机的重要约束。最简单的设计（至少从概念上）是使用由“快速硬件寄存器”阵列组成的单一页表，每一个表项对应一个虚拟页面，虚拟页号作为索引，如图3-10所示。当启动一个进程时，操作系统把保存在内存中的进程页表的副本载入到寄存器中。在进程运行过程中，不必再为页表而访问内存。这个方法的优势是简单并且在映射过程中不需要访问内存。而缺点是在页表很大时，代价高昂。而且每一次上下文切换都必须装载整个页表，这样会降低性能。

另一种极端方法是，整个页表都在内存中。那时所需的硬件仅仅是一个指向页表起始位置的寄存器。这样的设计使得在上下文切换时，进行 “虚拟地址到物理地址” 的映射只需重新装入一个寄存器。当然，这种做法的缺陷是在执行每条指令时，都需要一次或多次内存访问来完成页表项的读入，速度非常慢。

**1.转换检测缓冲区**

现在讨论加速分页机制和处理大的虚拟地址空间的实现方案，先介绍加速分页问题。大多数优化技术都是从内存中的页表开始的。这种设计对效率有着巨大的影响。例如，假设一条 1 字节指令要把一个寄存器中的数据复制到另一个寄存器。在不分页的情况下，这条指令只访问一次内存，即从内存中取指令。有了分页机制后，会因为要访问页表而引起更多次的内存访问。由于执行速度通常被 CPU 从内存中取指令和数据的速度所限制，所以两次访问内存才能实现一次内存访问会使性能下降一半（在这里是一级页表）。在这种情况下，没人会采用分页机制。

多年以来，计算机的设计者已经意识到了这个问题，并找到了一种解决方案。这种解决方案的建立基于这样一种观察：大多数程序总是对少量的页面进行多次的访问，而不是相反。因此，只有很少的页表项会被反复读取，而其他的页表项很少被访问。

上面提到的解决方案是为计算机设置一个小型的硬件设备，将虚拟地址直接映射到物理地址，而不必再访问页表。这种设备称为**转换检测缓冲区**（Translation Lookaside Buffer，TLB），有时又称为**相联存储器**（associate memory）或**快表**，如图 3-12 所示。它通常在 MMU 中，包含少量的表项，在此例中为 8 个，在实际中很少会超过 256 个。每个表项记录了一个页面的相关信息，包括虚拟页号、页面的修改位、保护码（读/写/执行权限）和该页所对应的物理页框。除了虚拟页号（不是必须放在页表中），这些域与页表中的域是一一对应的。另外还有一位用来记录这个表项是否有效（即是否在使用）。

例如，如果一个进程在虚拟地址 19、20 和 21 之间有一个循环，那么可以生成图 3-12 中的 TLB，这些 TLB 表项中有可读和可执行的保护码。当前主要使用的数据（假设是个数组）放在页面 129 和页面 130 中。页面 140 包含了用于数组计算的索引。最后，堆栈位于页面 860 和页面 861。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE75.jpg"/>
</div>



现在看一下 TLB 是如何工作的。将一个虚拟地址放入 MMU 中进行转换时，硬件首先通过将该虚拟页号与 TLB 中所有表项同时（即并行）进行匹配，判断虚拟页面是否在其中。如果发现了一个有效的匹配并且要进行的访问操作并不违反保护位，则将页框号直接从 TLB 中取出而不必再访问页表。如果虚拟页号确实是在 TLB 中，但指令试图在一个只读页面上进行写操作，则会产生一个保护错误，就像对页表进行非法访问一样。

当虚拟页号不在 TLB 中时会怎样呢？如果 MMU 检测到没有有效的匹配项，就会进行正常的页表查询。接着从 TLB 中淘汰一个表项，然后用新找到的页表项代替它。这样，如果这一页面很快被再次访问，第二次访问 TLB 时自然将会命中而不是未命中。当一个表项被清除出 TLB 时，将修改位复制到内存中的页表项，而除了访问位，其他的值不变。从页表中加载 TLB 时，所有字段都从内存中获取。

**2.软件 TLB 管理**

到目前为止，我们已经假设每一台具有虚拟内存的机器都具有由硬件识别的页表，以及一个 TLB。在这种设计中，对 TLB 的管理和 TLB 的失效处理都完全由 MMU 硬件来实现。只有在内存中没有找到某个页面时，才会陷入到操作系统中。

在过去，这样的假设是正确的。但是，许多现代的 RISC 机器，包括 SPARC、MIPS 以及（现在废弃的）HP PA，几乎所有的页面管理都是在软件中实现的。在这些机器上，TLB 表项被操作系统显式地装载。当发生 TLB 访问失效时，不再是由 MMU 到页表中查找并取出需要的页表项，而是生成一个 TLB 失效并将问题交给操作系统解决。系统必须先找到该页面，然后从 TLB 中删除一个项，接着装载一个新的项，最后再执行先前出错的指令。当然，所有这一切都必须在有限的几条指令中完成，因为 TLB 失效比缺页中断发生得更加频繁。

让人感到惊奇的是，如果 TLB 大到（如 64 个表项）可以减少失效率时，TLB 的软件管理就会变得足够有效。这种方法的最主要的好处是获得了一个非常简单的 MMU，这就在 CPU 芯片上为高速缓存以及其他改善性能的设计腾出了相当大的空间。Uhlig 等人（Uhlig，1994）在论文中讨论过软件 TLB 管理。

很早以前就已经开发了多种不同的策略来改善采用软件 TLB 管理机制的机器的性能。其中一种策略是在减少 TLB 失效的同时，又要在发生 TLB 失效时减少处理开销（Bala 等人，1994）。为了减少 TLB 失效，有时候操作系统能用 “直觉” 指出哪些页面下一步可能会被用到并预先为它们在 TLB 中装载表项。例如，当一个客户进程发送一条消息给同一台机器上的服务器进程，很可能服务器将不得不立即运行。了解了这一点，当执行处理 send 的陷阱时，系统也可以找到服务器的代码页、数据页以及堆栈页，并在有可能导致 TLB 失效前把它们装载到 TLB 中。

无论是用硬件还是用软件来处理 TLB 失效，一般方法都是找到页表并执行索引操作以定位将要访问的页面。用软件做这样的搜索的问题是，要查找的页表可能不在 TLB 中，这就会导致处理过程中的额外的 TLB 失效。可以通过在内存中的固定位置维护一个大的（如 4KB）TLB 表项的软件高速缓存（该高速缓存的页面一直保存在 TLB 中）来减少 TLB 失效。通过首先检查软件高速缓存，操作系统能够大量减少 TLB 失效。

当使用软件 TLB 管理时，一个基本要求是要理解两种不同的 TLB 失效的区别在哪里。当一个页面访问在内存中而不在 TLB 中时，将产生**软失效**（soft miss）。那么此时所要做的就是更新一下 TLB，不需要产生磁盘 I/O。典型的处理需要 10~20 个机器指令并花费几纳秒完成操作。相反，当页面本身不在内存中（当然也不在 TLB 中）时，将产生**硬失效**。此刻需要一次磁盘存取以装入该页面，这个过程大概需要几毫秒。硬失效的处理时间往往是软失效的百万倍。在页表结构中查找相应的映射被称为**页表遍历**。

实际中遇到的情况可能会更加复杂，未命中的情况可能既不是软失效也不是硬失效。一些未命中相比其他未命中会更 “软”（或更 “硬”）。举例来说，假设页表遍历没有在进程的页表中找到需要的页，从而引发了一个缺页错误，那么这时有三种可能。第一种，所需的页面可能就在内存中，但却未记录在该进程的页表里。比如该页面可能已由其他进程从硬盘中调入内存，这种情况下只需要把所需的页面正确映射到页表中，而不用再从硬盘调入。这是一种典型的软失效，称为**次要缺页错误**。第二种，如果需要从硬盘重新调入页面，这就是**严重缺页错误**。第三种，程序可能访问了一个非法地址，根本不需要向 TLB 中新增映射。此时，操作系统一般会通过报告**段错误**来终止该程序。只有第三种缺页属于程序错误，其他缺页情况都会被硬件或操作系统以降低性能为代价而自动修复。



##### 3.3.4	针对大内存的页表

在原有的内存页表的方案之上，引入 TLB 可以加快虚拟地址到物理地址的转换。不过这不是唯一需要解决的问题。另一个问题是怎样处理巨大的虚拟地址空间。下面将讨论两种解决方法。

**1.多级页表**

第一种方法是采用多级页表。一个简单的例子如图 3-13 所示。在图 3-13a 中，32 位的虚拟地址被划分为 10 位的 PT1 域、10 位的 PT2 域和 12 位的 Offset（偏移量）域。因为偏移量是 12 位，所以页面大小是 4KB，共有 2^20^ 个页面。

引入多级页表的原因是避免把全部页表一直保存在内存中。特别是那些从不需要的页表就不应该保留。比如一个需要 12MB 内存的进程，其最底端是 4MB 的程序正文段，后面是 4MB 的数据段，顶端是 4MB 的堆栈段，在数据段上方和堆栈段下方之间是大量根本没有使用的空闲区。

考察图 3-13b 中的二级页表是如何工作的。在左边是顶级页表，它有 1024 个表项，对应于 10 位的 PT1 域。当一个虚拟地址被送到 MMU 时，MMU 首先提取 PT1 域并把该值作为访问顶级页表的索引。因为整个 4GB（即 32 位）虚拟地址空间已经按 4KB 大小分块，所以顶级页表中这 1024 个表项的每一个都表示 4M 的块地址范围。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE76.jpg"/>
</div>

由索引顶级页表得到的表项中含有二级页表的地址或页框号。顶级页表的表项 0 指向程序正文的页表，表项 1 指向数据的页表，表项 1023 指向堆栈的页表，其他的表项（用阴影表示的）未用。现在把 PT2 域作为访问选定的二级页表的索引，以便找到该虚拟页面的对应页框号。

下面看一个示例，考虑 32 位虚拟地址 0x00403004（十进制4 206 596）位于数据部分12 292字节处。它的虚拟地址对应 PT1＝1，PT2＝3，Offset＝4。MMU 首先用 PT1 作为索引访问顶级页表得到表项 1，它对应的地址范围是 4M 到 8M-1。然后，它用 PT2 作为索引访问刚刚找到的二级页表并得到表项 3，它对应的虚拟地址范围是在它的 4M 块内的 12 288~16 383（即绝对地址 4 206 592~4 210 687）。这个表项含有虚拟地址 0x00403004 所在页面的页框号。如果该页面不在内存中，页表项中的 “在/不在” 位将是 0，引发一次缺页中断。如果该页面在内存中，从二级页表中得到的页框号将与偏移量(4)结合形成物理地址。该地址被放到总线上并送到内存中。

值得注意的是，虽然在图 3-13 中虚拟地址空间超过 100 万个页面，实际上只需要四个页表：顶级页表以及 0~4M（正文段）、4M ~ 8M（数据段）和顶端 4M（堆栈段）的二级页表。顶级页表中 1021 个表项的 “在/不在” 位都被设为 0，当访问它们时强制产生一个缺页中断。如果发生了这种情况，操作系统将注意到进程正在试图访问一个不希望被访问的地址，并采取适当的行动，比如向进程发出一个信号或杀死进程等。在这个例子中的各种长度选择的都是整数，并且选择 PT1 与 PT2 等长，但在实际中也可能是其他的值。

图 3-13 所示的二级页表可扩充为三级、四级或更多级。级数越多，灵活性就越大。举例来说，Intel 在 1985 年推出的 32 位处理器 80386 的寻址空间就多达 4GB。它采用包含**页目录**的二级页表机制，页目录中的项指向页表，页表项再指向真实大小为 4KB 的页框。页目录和页表都包含 1024 个表项，这样就可以像预期的一样，一共可以提供 2^10^ ×2^10^ ×2^12^ = 2^32^ 个可寻址字节。

十年后，高性能奔腾处理器推出了另一种寻址实现形式：**页目录指针表**。此外，它每一级的页表项由 32 位扩展到了 64 位，这样处理器就能寻址到 4GB 以外的地址空间。由于在每个页目录指针表中只有 4 条目录，因此每个页目录表中有 512 个条目，每个页表中也只有 512 个条目，这样总的寻址空间依然被限定在 4GB 以内。当 x86 系列支持 64 位后（最初由 AMD 实现），附加的一层表结构本可以被称作 “页目录指针表指针” 或类似的令人生厌的名字。这与芯片制造者的常用命名规则非常匹配，不过好在他们为其取了另一个名字—**4级页表**，这个名字可能不那么吸引人，但至少简短而明确。现在，这些处理器在页表中都使用 512 个条目，可寻址空间达到了 2^9^×2^9^×2^9^×2^9^×2^12^ = 2^48^ 字节，共 256TB 大小的内存空间可以够用相当长一段时间，因此芯片制造者没有再多加一层页。

**2.倒排页表**

针对页式调度层级不断增长的另一种解决方案是**倒排页表**（inverted page table），首先采用这种解决方案的处理器有 PowerPC、UltraSPARC 和 Itanium（有时也被称作 Itanic，这款处理器并没有达到 Intel 所期望的目标）。在这种设计中，实际内存中的每个页框对应一个表项，而不是每个虚拟页面对应一个表项。例如，对于 64 位虚拟地址，4KB（2^12^） 的页，4GB（2^32^） 的 RAM，一个倒排页表仅需要 1 048 576（2^20^） 个表项。表项记录了哪一个（进程，虚拟页面）对定于该页框。

虽然倒排页表节省了大量的空间（至少当虚拟地址空间比物理内存大得多的时候是这样的），但它也有严重的不足：从虚拟地址到物理地址的转换会变得很困难。当进程 n 访问虚拟页面 p 时，硬件不再能通过把 p 当作指向页表的一个索引来查找物理页框。取而代之的是，它必须搜索整个倒排页表来查找某一个表项（n，p）。此外，该搜索必须对每一个内存访问操作都要执行一次，而不仅仅是在发生缺页中断时执行。每次内存访问操作都要查找一个 256K 的表不是一种使机器快速运行的方法。

走出这种两难局面的办法是使用 TLB。如果 TLB 能够记录所有频繁使用的页面，地址转换就可能变得像通常的页表一样快。但是，当发生 TLB 失效时，需要用软件搜索整个倒排页表。实现该搜索的一个可行的方法是建立一张散列表，用虚拟地址来散列。当前所有在内存中的具有相同散列值的虚拟页面被链接在一起，如图 3-14 所示。如果散列表中的槽数与机器中物理页面数一样多，那么散列表的冲突链的平均长度将会是 1 个表项的长度，这将会大大提高映射速度。一旦页框号被找到，新的（虚拟页号，物理页框号）对就会被装载到 TLB 中。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE77.jpg"/>
</div>

倒排页表在 64 位机器中很常见，因为在 64 位机器中即使使用了大页面，页表项的数量还是很庞大的。例如，对于 4MB 页面和 64 位虚拟地址，需要 2^42^ 个页表项。处理大量虚拟内存的其他方法可参见 Talluri 等人（1995）的论文。



#### 3.4	**页面置换算法**

当发生缺页中断时，操作系统必须在内存中选择一个页面将其换出内存，以便为即将调入的页面腾出空间。如果要换出的页面在内存驻留期间已经被修改过，就必须把它写回磁盘以更新该页面在磁盘上的副本；如果该页面没有被修改过（如一个包含程序正文的页面），那么它在磁盘上的副本已经是最新的，不需要回写。直接用调入的页面覆盖被淘汰的页面就可以了。

当发生缺页中断时，虽然可以随机地选择一个页面来置换，但是如果每次都选择不常使用的页面会提升系统的性能。如果一个被频繁使用的页面被置换出内存，很可能它在很短时间内又要被调入内存，这会带来不必要的开销。人们已经从理论和实践两个方面对页面置换算法进行了深入的研究。下面我们将介绍几个最重要的算法。

有必要指出，“页面置换” 问题在计算机设计的其他领域中也同样会发生。例如，多数计算机把最近使用过的 32 字节或 64 字节的存储块保存在一个或多个高速缓存中。当这些高速缓存存满之后就必须选择一些块丢掉。除了花费时间较短外（有关操作必须在几纳秒内完成，而不是像页面置换那样在微秒级上完成），这个问题同页面置换问题完全一样。之所以花费时间较短，其原因是丢掉的高速缓存块可以从内存中获得，而内存既没有寻道时间也不存在旋转延迟。

第二个例子是 Web 服务器。服务器可以把经常访问的一些 Web 页面存放在存储器的高速缓存中。但是，当存储器高速缓存已满并且要访问一个不在高速缓存中的页面时，就必须要置换高速缓存中的某个 Web 页面。在高速缓存中的 Web 页面不会被修改，因此在磁盘中的 Web 页面的副本总是最新的，而在虚拟存储系统中，内存中的页面既可能是干净页面也可能是脏页面，除了这一点不同之外，置换 Web 页面和置换虚拟内存中的页面需要考虑的问题是类似的。

在接下来讨论的所有页面置换算法中都存在一个问题：当需要从内存中换出某个页面时，它是否只能是缺页进程自己的页面？这个要换出的页面是否可以属于另外一个进程？在前一种情况下，可以有效地将每一个进程限定在固定的页面数目内；后一种情况则不能。这两种情况都是可能的。在 3.5.1 节我们会继续讨论这一点。



##### 3.4.1   最优页面置换算法

很容易就可以描述出最好的页面置换算法，虽然此算法不可能实现。该算法是这样工作的：在缺页中断发生时，有些页面在内存中，其中有一个页面（包含紧接着的下一条指令的那个页面）将很快被访问，其他页面则可能要到 10、100 或 1000 条指令后才会被访问，每个页面都可以用在该页面首次被访问前所要执行的指令数作为标记。

最优页面置换算法规定应该置换标记最大的页面。如果一个页面在 800 万条指令内不会被使用，另外一个页面在 600 万条指令内不会被使用，则置换前一个页面，从而把因需要调入这个页面而发生的缺页中断推迟到将来，越久越好。计算机也像人一样，希望把不愉快的事情尽可能地往后拖延。

这个算法唯一的问题就是它是无法实现的。当缺页中断发生时，操作系统无法知道各个页面下一次将在什么时候被访问。（在最短作业优先调度算法中，我们曾遇到同样的情况，即系统如何知道哪个作业是最短的呢？）当然，通过首先在仿真程序上运行程序，跟踪所有页面的访问情况，然后在第二次运行时利用第一次运行时收集的信息是可以实现最优页面置换算法的。

用这种方式，可以通过最优页面置换算法对其他可实现算法的性能进行比较。如果操作系统达到的页面置换性能只比最优算法差 1%，那么即使花费大量的精力来寻找更好的算法最多也只能换来 1% 的性能提高。

为了避免混淆，读者必须清楚以上页面访问情况的记录只针对刚刚被测试过的程序和它的一个特定的输入，因此从中导出的性能最好的页面置换算法也只是针对这个特定的程序和输入数据的。虽然这个方法对评价页面置换算法很有用，但它在实际系统中却不能使用。下面将研究可以在实际系统中使用的算法。



##### 3.4.2   最近未使用页面置换算法

为使操作系统能够收集有用的统计信息，在大部分具有虚拟内存的计算机中，系统为每一页面设置了两个状态位。当页面被访问（读或写）时设置 R 位；当页面被写入（即修改）时设置 M 位。这些位包含在每个页表项中，如图 3-11 所示。每次访问内存时更新这些位，因此由硬件来设置它们是必要的。一旦设置某位为 1，它就一直保持 1 直到操作系统将它复位。

如果硬件没有这些位，则可以使用操作系统的缺页中断和时钟中断机制进行以下的模拟：当启动一个进程时，将其所有的页面都标记为不在内存；一旦访问任何一个页面就会引发一次缺页中断，此时操作系统就可以设置 R 位（在它的内部表中），修改页表项使其指向正确的页面，并设为 READ ONLY 模式，然后重新启动引起缺页中断的指令；如果随后对该页面的修改又引发一次缺页中断，则操作系统设置这个页面的 M 位并将其改为 READ/WRITE 模式。

可以用 R 位和 M 位来构造一个简单的页面置换算法：当启动一个进程时，它的所有页面的两个位都由操作系统设置成 0，R 位被定期地（比如在每次时钟中断时）清零，以区别最近没有被访问的页面和被访问的页面。

当发生缺页中断时，操作系统检查所有的页面并根据它们当前的 R 位和 M 位的值，把它们分为 4 类：

第 0 类：没有被访问，没有被修改。

第 1 类：没有被访问，已被修改。

第 2 类：已被访问，没有被修改。

第 3 类：已被访问，已被修改。

尽管第 1 类初看起来似乎是不可能的，但是一个第 3 类的页面在它的 R 位被时钟中断清零后就成了第 1 类。时钟中断不清除 M 位是因为在决定一个页面是否需要写回磁盘时将用到这个信息。清除 R 位而不清除 M 位产生了第 1 类页面。

NRU（Not Recently Used，最近未使用）算法随机地从类编号最小的非空类中挑选一个页面淘汰。这个算法隐含的意思是，在最近一个时钟滴答中（典型的时间是大约 20ms）淘汰一个没有被访问的已修改页面要比淘汰一个被频繁使用的 “干净” 页面好。NRU 的主要优点是易于理解和能够有效地被实现，虽然它的性能不是最好的，但是已经够用了。



##### 3.4.3   先进先出页面置换算法

另一种开销较小的页面置换算法是 FIFO（First-In First-Out，先进先出）算法。为了解释它是怎样工作的，设想有一个超市，它有足够的货架展示 k 种不同的商品。有一天，某家公司介绍了一种新的方便食品——即食的、冷冻干燥的、可以用微波炉加热的酸乳酪，这个产品非常成功，所以容量有限的超市必须撤掉一种旧的商品以便能够展示该新产品。

一种可能的解决方法就是找到该超市中库存时间最长的商品并将其替换掉（比如某种 120 年以前就开始卖的商品），理由是现在已经没有人喜欢它了。这实际上相当于超市有一个按照引进时间排列的所有商品的链表。新的商品被加到链表的尾部，链表头上的商品则被撤掉。

同样的思想也可以应用在页面置换算法中。由操作系统维护一个所有当前在内存中的页面的链表，最后进入的页面放在表尾，最早进入的页面放在表头。当发生缺页中断时，淘汰表头的页面并把新调入的页面加到表尾。当 FIFO 用在超市时，可能会淘汰剃须膏，但也可能淘汰面粉、盐或黄油这一类常用商品。因此，当它应用在计算机上时也会引起同样的问题，由于这一原因，很少使用纯粹的 FIFO 算法。



##### 3.4.4   第二次机会页面置换算法

FIFO 算法可能会把经常使用的页面置换出去，为了避免这一问题，对该算法做一个简单的修改：检查最老页面的 R 位。如果 R 位是 0，那么这个页面既老又没有被使用，可以立刻置换掉；如果是 1，就将 R 位清 0，并把该页面放到链表的尾端，修改它的装入时间使它就像刚装入的一样，然后继续搜索。

这一算法称为第二次机会（second chance）算法，如图 3-15 所示。在图 3-15a 中可以看到页面 A 到页面 H 按照进入内存的时间顺序保存在链表中。

假设在时刻 20 处发生了一次缺页中断。这时最老的页面是 A，它是在时刻 0 到达的。如果 A 的 R 位是 0，则将它淘汰出内存，或者把它写回磁盘（如果它已被修改过），或者只是简单地放弃（如果它是 “干净” 的）；另一方面，如果其 R 位已经设置了，则将 A 放到链表的尾部并且重新设置 “装入时间” 为当前时刻（20），然后清除 R 位。然后从 B 页面开始继续搜索合适的页面。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE78.jpg"/>
</div>

第二次机会算法就是寻找一个在最近的时钟间隔内没有被访问过的页面。如果所有的页面都被访问过了，该算法就简化为纯粹的 FIFO 算法。特别地，想象一下，假设图 3-15a 中所有页面的 R 位都被设置了，操作系统将会一个接一个地把每个页面都移动到链表的尾部并清除被移动的页面的 R 位。最后算法又将回到页面 A，此时它的 R 位已经被清除了，因此 A 页面将被淘汰，所以这个算法总是可以结束的。



##### 3.4.5   时钟页面置换算法

尽管第二次机会算法是一个比较合理的算法，但它经常要在链表中移动页面，既降低了效率又不是很有必要。一个更好的办法是把所有的页面都保存在一个类似钟面的环形链表中，一个表针指向最老的页面，如图 3-16 所示。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE79.jpg"/>
</div>

当发生缺页中断时，算法首先检查表针指向的页面，如果它的 R 位是 0 就淘汰该页面，并把新的页面插入这个位置，然后把表针前移一个位置；如果 R 位是 1 就清除 R 位并把表针前移一个位置。重复这个过程直到找到了一个 R 位为 0 的页面为止。了解了这个算法的工作方式，就明白为什么它被称为时钟（clock）算法了。



##### 3.4.6   最近最少使用页面置换算法

对最优算法的一个很好的近似是基于这样的观察：在前面几条指令中频繁使用的页面很可能在后面的几条指令中被使用。反过来说，已经很久没有使用的页面很有可能在未来较长的一段时间内仍然不会被使用。这个思想提示了一个可实现的算法：在缺页中断发生时，置换未使用时间最长的页面。这个策略称为 LRU（Least Recently Used，最近最少使用）页面置换算法。

虽然 LRU 在理论上是可以实现的，但代价很高。为了完全实现 LRU，需要在内存中维护一个所有页面的链表，最近最多使用的页面在表头，最近最少使用的页面在表尾。困难的是在每次访问内存时都必须要更新整个链表。在链表中找到一个页面，删除它，然后把它移动到表头是一个非常费时的操作，即使使用硬件实现也一样费时（假设有这样的硬件）。

然而，还是有一些使用特殊硬件实现 LRU 的方法。首先考虑一个最简单的方法，这个方法要求硬件有一个 64 位计数器 C，它在每条指令执行完后自动加 1，每个页表项必须有一个足够容纳这个计数器值的域。在每次访问内存后，将当前的 C 值保存到被访问页面的页表项中。一旦发生缺页中断，操作系统就检查所有页表项中计数器的值，找到值最小的一个页面，这个页面就是最近最少使用的页面。



##### 3.4.7   用软件模拟 LRU

前面一种 LRU 算法虽然在理论上是可以实现的，但只有非常少的计算机拥有这种硬件。因此，需要一个能用软件实现的解决方案。一种可能的方案称为 NFU（Not Frequently Used，最不常用）算法。该算法将每个页面与一个软件计数器相关联，计数器的初值为 0。每次时钟中断时，由操作系统扫描内存中所有的页面，将每个页面的 R 位（它的值是 0 或 1）加到它的计数器上。这个计数器大体上跟踪了各个页面被访问的频繁程度。发生缺页中断时，则置换计数器值最小的页面。

NFU 的主要问题是它从来不忘记任何事情。比如，在一个多次（扫描）编译器中，在第一次扫描中被频繁使用的页面在程序进入第二次扫描时，其计数器的值可能仍然很高。实际上，如果第一次扫描的执行时间恰好是各次扫描中最长的，含有以后各次扫描代码的页面的计数器可能总是比含有第一次扫描代码的页面的计数器小，结果是操作系统将置换有用的页面而不是不再使用的页面。

幸运的是只需对 NFU 做一个小小的修改就能使它很好地模拟 LRU。其修改分为两部分：首先，在 R 位被加进之前先将计数器右移一位；其次，将 R 位加到计数器最左端的位而不是最右端的位。

修改以后的算法称为**老化**（aging）算法，图 3-17 解释了它是如何工作的。假设在第一个时钟滴答后，页面 0～5 的 R 位值分别是 1、0、1、0、1、1（页面 0 为 1，页面 1 为 0，页面 2 为 1，以此类推）。换句话说，在时钟滴答 0 到时钟滴答 1 期间，访问了页 0、2、4、5，它们的 R 位设置为 1，而其他页面的 R 位仍然是 0。对应的 6 个计数器在经过移位并把 R 位插入其左端后的值如图 3-17a 所示。图中后面的 4 列是在下 4 个时钟滴答后的 6 个计数器的值。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE80.jpg"/>
</div>

发生缺页中断时，将置换计数器值最小的页面。如果一个页面在前面 4 个时钟滴答中都没有访问过，那么它的计数器最前面应该有 4 个连续的 0，因此它的值肯定要比在前面三个时钟滴答中都没有被访问过的页面的计数器值小。

该算法与 LRU 有两个区别。如图 3-17e 中的页面 3 和页面 5，它们都连续两个时钟滴答没有被访问过了，而在两个时钟滴答之前的时钟滴答中它们都被访问过。根据 LRU，如果必须置换一个页面，则应该在这两个页面中选择一个。然而现在的问题是，我们不知道在时钟滴答 1 到时钟滴答 2 期间它们中的哪一个页面是后被访问到的。因为在每个时钟滴答中只记录了一位，所以无法区分在一个时钟滴答中哪个页面在较早的时间被访问以及哪个页面在较晚的时间被访问，因此，我们所能做的就是置换页面 3，原因是页面 5 在更往前的两个时钟滴答中也被访问过而页面 3 没有。

LRU 和老化算法的第二个区别是老化算法的计数器只有有限位数（本例中是 8 位），这就限制了其对以往页面的记录。如果两个页面的计数器都是 0，我们只能在两个页面中随机选一个进行置换。实际上，有可能其中一个页面上次被访问是在 9 个时钟滴答以前，另一个页面是在 1000 个时钟滴答以前，而我们却无法看到这些。在实践中，如果时钟滴答是 20ms，8 位一般是够用的。假如一个页面已经有 160ms 没有被访问过，那么它很可能并不重要。



##### 3.4.8   工作集页面置换算法

在单纯的分页系统里，刚启动进程时，在内存中并没有页面。在 CPU 试图取第一条指令时就会产生一次缺页中断，使操作系统装入含有第一条指令的页面。其他由访问全局数据和堆栈引起的缺页中断通常会紧接着发生。一段时间以后，进程需要的大部分页面都已经在内存了，进程开始在较少缺页中断的情况下运行。这个策略称为**请求调页**（demand paging），因为页面是在需要时被调入的，而不是预先装入。

编写一个这样的测试程序很容易，它在一个大的地址空间中系统地读所有的页面，从而出现大量的缺页中断，因此会导致没有足够的内存来容纳这些页面。不过幸运的是，大部分进程不是这样工作的，它们都表现出了一种局部性访问行为，即在进程运行的任何阶段，它都只访问较少的一部分页面。例如，在一个多次扫描编译器中，各次扫描时只访问所有页面中的一小部分，并且是不同的部分。

一个进程当前正在使用的页面的集合称为它的**工作集**（Denning，1968a；Denning，1980）。如果整个工作集都被装入到了内存中，那么进程在运行到下一运行阶段（例如，编译器的下一遍扫描）之前，不会产生很多缺页中断。若内存太小而无法容纳下整个工作集，那么进程的运行过程中会产生大量的缺页中断，导致运行速度也会变得很缓慢，**因为通常只需要几个纳秒就能执行完一条指令，而通常需要十毫秒才能从磁盘上读入一个页面**。如果一个程序每 10ms 只能执行一到两条指令，那么它将会需要很长时间才能运行完。若每执行几条指令程序就发生一次缺页中断，那么就称这个程序发生了**颠簸**（Denning，1968b）。

在多道程序设计系统中，经常会把进程转移到磁盘上（即从内存中移走所有的页面），这样可以让其他的进程有机会占有 CPU。有一个问题是，当该进程再次调回来以后应该怎样办？从技术的角度上讲，并不需要做什么。该进程会一直产生缺页中断直到它的工作集全部被装入内存。然而，每次装入一个进程时都要产生 20、100 甚至 1000 次缺页中断，速度显然太慢了，并且由于 CPU 需要几毫秒时间处理一个缺页中断，因此有相当多的 CPU 时间也被浪费了。

所以不少分页系统都会设法跟踪进程的工作集，以确保在让进程运行以前，它的工作集就已在内存中了。该方法称为**工作集模型**（Denning，1970），其目的在于大大减少缺页中断率。在进程运行前预先装入其工作集页面也称为**预先调页**（prepaging）。请注意工作集是随着时间变化的。

人们很早就发现大多数程序都不是均匀地访问它们的地址空间的，而访问往往是集中于一小部分页面。一次内存访问可能会取出一条指令，也可能会取数据，或者是存储数据。在任一时刻 t，都存在一个集合，它包含所有最近 k 次内存访问所访问过的页面。这个集合 w(k, t) 就是工作集。因为最近 k＝1 次访问肯定会访问最近 k>1 次访问所访问过的页面，所以 w(k, t) 是 k 的单调非递减函数。随着 k 的变大，w(k, t) 是不会无限变大的，因为程序不可能访问比它的地址空间所能容纳的页面数目上限还多的页面，并且几乎没有程序会使用每个页面。图 3-18 描述了作为 k 的函数的工作集的大小。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE81.jpg"/>
</div>

事实上大多数程序会任意访问一小部分页面，但是这个集合会随着时间而缓慢变化，这个事实也解释了为什么一开始曲线快速地上升而 k 较大时上升会变慢。举例来说，某个程序执行占用了两个页面的循环，并使用四个页面上的数据，那么可能每执行 1000 条指令，它就会访问这六个页面一次，但是最近的对其他页面的访问可能是在 100 万条指令以前的初始化阶段。因为这是个渐进的过程，k 值的选择对工作集的内容影响不大。换句话说，k 的值有一个很大的范围，它处在这个范围中时工作集不会变。因为工作集随时间变化很慢，那么当程序重新开始时，就有可能根据它上次结束时的工作集对要用到的页面做一个合理的推测，预先调页就是在程序继续运行之前预先装入推测出的工作集的页面。

为了实现工作集模型，操作系统必须跟踪哪些页面在工作集中。通过这些信息可以直接推导出一个合理的页面置换算法：当发生缺页中断时，淘汰一个不在工作集中的页面。为了实现该算法，就需要一种精确的方法来确定哪些页面在工作集中。根据定义，工作集就是最近 k 次内存访问所使用过的页面的集合（有些设计者使用最近 k 次页面访问，但是选择是任意的）。为了实现工作集算法，必须预先选定 k 的值。一旦选定某个值，每次内存访问之后，最近 k 次内存访问所使用过的页面的集合就是唯一确定的了。

当然，有了工作集的定义并不意味着存在一种有效的方法能够在程序运行期间及时地计算出工作集。设想有一个长度为 k 的移位寄存器，每进行一次内存访问就把寄存器左移一位，然后在最右端插入刚才所访问过的页面号。移位寄存器中的 k 个页面号的集合就是工作集。理论上，当缺页中断发生时，只要读出移位寄存器中的内容并排序；然后删除重复的页面。结果就是工作集。然而，维护移位寄存器并在缺页中断时处理它所需的开销很大，因此该技术从来没有被使用过。

作为替代，可以使用几种近似的方法。一种常见的近似方法就是，不是向后找最近 k 次的内存访问，而是考虑其执行时间。例如，按照以前的方法，定义工作集为前 1000 万次内存访问所使用过的页面的集合，那么现在就可以这样定义：工作集即是过去 10ms 中的内存访问所用到的页面的集合。实际上，这样的模型很合适且更容易实现。要注意到，每个进程只计算它自己的执行时间。因此，如果一个进程在 T 时刻开始，在（T+100）ms 的时刻使用了 40ms CPU 时间，对工作集而言，它的时间就是 40ms。一个进程从它开始执行到当前所实际使用的 CPU 时间总数通常称作当前实际运行时间。通过这个近似的方法，进程的工作集可以被称为在过去的 t 秒实际运行时间中它所访问过的页面的集合。

现在让我们来看一下基于工作集的页面置换算法。基本思路就是找出一个不在工作集中的页面并淘汰它。在图 3-19 中读者可以看到某台机器的部分页表。因为只有那些在内存中的页面才可以作为候选者被淘汰，所以该算法忽略了那些不在内存中的页面。每个表项至少包含两条信息：上次使用该页面的近似时间和 R（访问）位。空白的矩形表示该算法不需要的其他域，如页框号、保护位、M（修改）位。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE82.jpg"/>
</div>

该算法工作方式如下。如前所述，假定使用硬件来置 R 位和 M 位。同样，假定在每个时钟滴答中，有一个定期的时钟中断会用软件方法来清除 R 位。每当缺页中断发生时，扫描页表以找出一个合适的页面淘汰之。

在处理每个表项时，都需要检查 R 位。如果它是 1，就把当前实际时间写进页表项的 “上次使用时间” 域，以表示缺页中断发生时该页面正在被使用。既然该页面在当前时钟滴答中已经被访问过，那么很明显它应该出现在工作集中，并且不应该被删除（假定 t 横跨多个时钟滴答）。

如果 R 是 0，那么表示在当前时钟滴答中，该页面还没有被访问过，则它就可以作为候选者被置换。为了知道它是否应该被置换，需要计算它的生存时间（即当前实际运行时间减去上次使用时间），然后与 t 做比较。如果它的生存时间大于 t，那么这个页面就不再在工作集中，而用新的页面置换它。扫描会继续进行以更新剩余的表项。

然而，如果 R 是 0 同时生存时间小于或等于 t，则该页面仍然在工作集中。这样就要把该页面临时保留下来，但是要记录生存时间最长（“上次使用时间” 的最小值）的页面。如果扫描完整个页表却没有找到适合被淘汰的页面，也就意味着所有的页面都在工作集中。在这种情况下，如果找到了一个或者多个 R＝0 的页面，就淘汰生存时间最长的页面。在最坏情况下，在当前时间滴答中，所有的页面都被访问过了（也就是都有 R＝1），因此就随机选择一个页面淘汰，如果有的话最好选一个干净页面。



##### 3.4.9   工作集时钟页面置换算法

当缺页中断发生后，需要扫描整个页表才能确定被淘汰的页面，因此基本工作集算法是比较费时的。有一种改进的算法，它基于时钟算法，并且使用了工作集信息，称为 **WSClock**（工作集时钟）算法（Carr 和 Hennessey，1981）。由于它实现简单，性能较好，所以在实际工作中得到了广泛应用。

与时钟算法一样，所需的数据结构是一个以页框为元素的循环表，参见图 3-20a。最初，该表是空的。当装入第一个页面后，把它加到该表中。随着更多的页面的加入，它们形成一个环。每个表项包含来自基本工作集算法的上次使用时间，以及 R 位（已标明）和 M 位（未标明）。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE83.jpg"/>
</div>

与时钟算法一样，每次缺页中断时，首先检查指针指向的页面。如果 R 位被置为 1，该页面在当前时钟滴答中就被使用过，那么该页面就不适合被淘汰。然后把该页面的 R 位置为 0，指针指向下一个页面，并重复该算法。该事件序列之后的状态参见图 3-20b。

现在来考虑指针指向的页面在 R=0 时会发生什么，参见图 3-20c。如果页面的生存时间大于 t 并且该页面是干净的，它就不在工作集中，并且在磁盘上有一个有效的副本。申请此页框，并把新页面放在其中，如图 3-20d 所示。另一方面，如果此页面被修改过，就不能立即申请页框，因为这个页面在磁盘上没有有效的副本。为了避免由于调度写磁盘操作引起的进程切换，指针继续向前走，算法继续对下一个页面进行操作。毕竟，有可能存在一个旧的且干净的页面可以立即使用。

原则上，所有的页面都有可能因为磁盘 I/O 在某个时钟周期被调度。为了降低磁盘阻塞，需要设置一个限制，即最大只允许写回 n 个页面。一旦达到该限制，就不允许调度新的写操作。

如果指针经过一圈返回它的起始点会发生什么呢？这里有两种情况：

1) 至少调度了一次写操作。

2) 没有调度过写操作。

对于第一种情况，指针仅仅是不停地移动，寻找一个干净页面。既然已经调度了一个或者多个写操作，最终会有某个写操作完成，它的页面会被标记为干净。置换遇到的第一个干净页面，这个页面不一定是第一个被调度写操作的页面，因为硬盘驱动程序为了优化性能可能已经把写操作重排序了。

对于第二种情况，所有的页面都在工作集中，否则将至少调度了一个写操作。由于缺乏额外的信息，一个简单的方法就是随便置换一个干净的页面来使用，扫描中需要记录干净页面的位置。如果不存在干净页面，就选定当前页面并把它写回磁盘。



##### 3.4.10   页面置换算法小结

我们已经考察了多种页面置换算法，本节将对这些算法进行总结。已经讨论过的算法在图 3-21 中列出。

最优算法在当前页面中置换最后要访问到的页面。不幸的是，没有办法来判定哪个页面是最后一个要访问的，因此实际上该算法不能使用。然而，它可以作为衡量其他算法的基准。

NRU 算法根据 R 位和 M 位的状态把页面分为四类。从编号最小的类中随机选择一个页面置换。该算法易于实现，但是性能不是很好，还存在更好的算法。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE84.jpg"/>
</div>

FIFO 算法通过维护一个页面的链表来记录它们装入内存的顺序。淘汰的是最老的页面，但是该页面可能仍在使用，因此 FIFO 算法不是一个好的选择。

第二次机会算法是对 FIFO 算法的改进，它在移出页面前先检查该页面是否正在被使用。如果该页面正在被使用，就保留该页面。这个改进大大提高了性能。时钟算法是第二次机会算法的另一种实现。它具有相同的性能特征，而且只需要更少的执行时间。

LRU 算法是一种非常优秀的算法，但是只能通过特定的硬件来实现。如果机器中没有该硬件，那么也无法使用该算法。NFU 是一种近似于 LRU 的算法，它的性能不是非常好，然而，老化算法更近似于 LRU 并且可以更有效地实现，是一个很好的选择。

最后两种算法都使用了工作集。工作集算法有合理的性能，但它的实现开销较大。工作集时钟算法是它的一种变体，不仅具有良好的性能，并且还能高效地实现。

总之，最好的两种算法是老化算法和工作集时钟算法，它们分别基于 LRU 和工作集。它们都具有良好的页面调度性能，可以有效地实现。也存在其他一些算法，但在实际应用中，这两种算法可能是最重要的。





#### 3.5	分页系统中的设计问题

在前几节里我们讨论了分页系统是如何工作的，并给出了一些基本的页面置换算法和如何实现它们。然而只了解基本机制是不够的。要设计一个系统，必须了解得更多才能使系统工作得更好。这两者之间的差别就像知道了怎样移动象棋的各种棋子与成为一个好棋手之间的差别。下面将讨论为了使分页系统达到较好的性能，操作系统设计者必须仔细考虑的一些其他问题。

##### 3.5.1   局部分配策略与全局分配策略

在前几节中，我们讨论了在发生缺页中断时用来选择一个被置换页面的几个算法。与这个选择相关的一个主要问题（到目前为止我们一直在小心地回避这个问题）是，怎样在相互竞争的可运行进程之间分配内存。

如图 3-22a 所示，三个进程 A、B、C 构成了可运行进程的集合。假如 A 发生了缺页中断，页面置换算法在寻找最近最少使用的页面时是只考虑分配给 A 的 6 个页面呢？还是考虑所有在内存中的页面？如果只考虑分配给 A 的页面，生存时间值最小的页面是 A5，于是将得到图 3-22b 所示的状态。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE85.jpg"/>
</div>

另一方面，如果淘汰内存中生存时间值最小的页面，而不管它属于哪个进程，则将选中页面 B3，于是将得到图 3-22c 所示的情况。图 3-22b 的算法被称为**局部**（local）页面置换算法，而图 3-22c 被称为**全局**（global）页面置换算法。局部算法可以有效地为每个进程分配固定的内存片段。全局算法在可运行进程之间动态地分配页框，因此分配给各个进程的页框数是随时间变化的。

全局算法在通常情况下工作得比局部算法好，当工作集的大小随进程运行时间发生变化时这种现象更加明显。若使用局部算法，即使有大量的空闲页框存在，工作集的增长也会导致颠簸。如果工作集缩小了，局部算法又会浪费内存。在使用全局算法时，系统必须不停地确定应该给每个进程分配多少页框。一种方法是监测工作集的大小，工作集大小由“老化”位指出，但这个方法并不能防止颠簸。因为工作集的大小可能在几微秒内就会发生改变，而老化位却要经历一定的时钟滴答数才会发生变化。

另一种途径是使用一个为进程分配页框的算法。其中一种方法是定期确定进程运行的数目并为它们分配相等的份额。例如，在有 12 416 个有效（即未被操作系统使用的）页框和 10 个进程时，每个进程将获得 1241 个页框，剩下的 6 个被放入一个公用池中，当发生缺页中断时可以使用这些页面。

这个算法看起来好像很公平，但是给一个 10KB 的进程和一个 300KB 的进程分配同样大小的内存块是很不合理的。可以采用按照进程大小的比例来为它们分配相应数目的页面的方法来取代上一种方法，这样 300KB 的进程将得到 10KB 进程 30 倍的份额。比较明智的一个可行的做法是对每个进程都规定一个最小的页框数，这样不论多么小的进程都可以运行。例如，在某些机器上，一条两个操作数的指令会需要多达 6 个页面，因为指令自身、源操作数和目的操作数可能会跨越页面边界，若只给一条这样的指令分配了 5 个页面，则包含这样的指令的程序根本无法运行。

如果使用全局算法，根据进程的大小按比例为其分配页面也是可能的，但是该分配必须在程序运行时动态更新。管理内存动态分配的一种方法是使用 **PFF**（Page Fault Frequency，缺页中断率）算法。它指出了何时增加或减少分配给一个进程的页面，但却完全没有说明在发生缺页中断时应该替换掉哪一个页面，它仅仅控制分配集的大小。

正如上面讨论过的，有一大类页面置换算法（包括 LRU 在内），缺页中断率都会随着分配的页面的增加而降低，这是 PFF 背后的假定。这一性质在图 3-23 中说明。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE86.jpg"/>
</div>

测量缺页中断率的方法是直截了当的：计算每秒的缺页中断数，可能也会将过去数秒的情况做连续平均。一个简单的方法是将当前这一秒的值加到当前的连续平均值上然后除以 2。虚线 A 对应于一个高得不可接受的缺页中断率，虚线 B 则对应于一个低得可以假设进程拥有过多内存的缺页中断率。在这种情况下，可能会从该进程的资源中剥夺部分页框。这样，PFF 尽力让每个进程的缺页中断率控制在可接受的范围内。

值得注意的是，一些页面置换算法既适用于局部置换算法，又适用于全局置换算法。例如，FIFO 能够将所有内存中最老的页面置换掉（全局算法），也能将当前进程的页面中最老的替换掉（局部算法）。 相似地，LRU 或是一些类似算法能够将所有内存中最近最少访问的页面替换掉（全局算法），或是将当前进程中最近最少使用的页面替换掉（局部算法）。在某些情况下，选择局部策略还是全局策略是与页面置换算法无关的。

另一方面，对于其他的页面置换算法，只有采用局部策略才有意义。特别是工作集和 WSClock 算法是针对某些特定进程的而且必须应用在这些进程的上下文中。实际上没有针对整个机器的工作集，并且试图使用所有工作集的并集作为机器的工作集可能会丢失一些局部特性，这样算法就不能达到好的性能。



##### 3.5.2   负载控制

即使是使用最优页面置换算法并对进程采用理想的全局页框分配，系统也可能会发生颠簸。事实上，一旦所有进程的组合工作集超出了内存容量，就可能发生颠簸。该现象的症状之一就是如 PFF 算法所指出的，一些进程需要更多的内存，但是没有进程需要更少的内存。在这种情况下，没有方法能够在不影响其他进程的情况下满足那些需要更多内存的进程的需要。唯一现实的解决方案就是暂时从内存中去掉一些进程。

减少竞争内存的进程数的一个好方法是将一部分进程交换到磁盘，并释放他们所占有的所有页面。例如，一个进程可以被交换到磁盘，而它的页框可以被其他处于颠簸状态的进程分享。如果颠簸停止，系统就能够这样运行一段时间。如果颠簸没有结束，需要继续将其他进程交换出去，直到颠簸结束。因此，即使是使用分页，交换也是需要的，只是现在交换是用来减少对内存潜在的需求，而不是收回它的页面。

将进程交换出去以减轻内存需求的压力是借用了两级调度的思想，在此过程中一些进程被放到磁盘，此时用一个短期的调度程序来调度剩余的进程。很明显，这两种思路可以被组合起来，将恰好足够的进程交换出去以获取可接受的缺页中断率。一些进程被周期性地从磁盘调入，而其他一些则被周期性地交换到磁盘。

不过，另一个需要考虑的因素是多道程序设计的道数。当内存中的进程数过低的时候，CPU 可能在很长的时间内处于空闲状态。考虑到该因素，在决定交换出哪个进程时不光要考虑进程大小和分页率，还要考虑它的特性（如它究竟是 CPU 密集型还是 I/O 密集型）以及其他进程的特性。



##### 3.5.3   页面大小

页面大小是操作系统可以选择的一个参数。例如，即使硬件设计只支持 4096 字节的页面，操作系统也可以很容易通过总是为页面对 0 和 1、2 和 3、4 和 5 等分配两个连续的 8192 字节的页框，而将其作为 8KB 的页面。

要确定最佳的页面大小需要在几个互相矛盾的因素之间进行权衡。从结果看，不存在全局最优。首先，有两个因素可以作为选择小页面的理由。随便选择一个正文段、数据段或堆栈段很可能不会恰好装满整数个页面，平均的情况下，最后一个页面中有一半是空的。多余的空间就被浪费掉了，这种浪费称为**内部碎片**（internal fragmentation）。在内存中有 n 个段、页面大小为 p 字节时，会有 np/2 字节被内部碎片浪费。从这方面考虑，使用小页面更好。

选择小页面还有一个明显的好处，考虑一个程序，它分成 8 个阶段顺序执行，每阶段需要 4KB 内存。如果页面大小是 32KB，那就必须始终给程序分配 32KB 内存。如果页面大小是 16KB，它就只需要 16KB。如果页面大小是 4KB 或更小，那么在任何时刻它只需要 4KB 内存。总的来说，大尺寸页面比小尺寸页面浪费了更多内存。

另一方面，页面小意味着程序需要更多的页面，这又意味着需要更大的页表。一个 32KB 的程序只需要 4 个 8KB 的页面，却需要 64 个 512 字节的页面。**内存与磁盘之间的传输一般是一次一页，传输中的大部分时间都花在了寻道和旋转延迟上，所以传输一个小页面所用的时间和传输一个大页面基本上是相同的**。装入 64 个 512 字节的页面可能需要 64×10ms，而装入 4 个8KB 的页面可能只需要 4×12ms。

此外，小页面能够更充分地利用 TLB 空间。假设程序使用的内存为 1MB，工作单元为 64KB。若使用 4KB 的页，则程序将至少占用 TLB 中的 16 个表项；而使用 2MB 的页时，1 个 TLB 表项就足够了（理论上，你还可以将数据和指令分离开来）。由于 TLB 表项相对稀缺，且对于性能而言至关重要，因此在条件允许的情况下使用大页面是值得的。为了进行必要的平衡，操作系统有时会为系统中的不同部分使用不同的页面大小。例如，内核使用大页面，而用户进程则使用小页面。

在某些机器上，每次 CPU 从一个进程切换到另一个进程时都必须把新进程的页表装入硬件寄存器中。这样，页面越小意味着装入页面寄存器花费的时间就会越长，而且页表占用的空间也会随着页面的减小而增大。

最后一点可以从数学上进行分析，假设进程平均大小是 s 个字节，页面大小是 p 个字节，每个页表项需要 e 个字节。那么每个进程需要的页数大约是 s/p，占用了 se/p 个字节的页表空间。内部碎片在最后一页浪费的内存是 p/2。因此，由页表和内部碎片损失造成的全部开销是以下两项之和：

开销＝se /p ＋p/2

在页面比较小的时候，第一项（页表大小）大。在页面比较大时第二项（内部碎片）大。最优值一定在页面大小处于中间的某个值时取得，通过对 p 一次求导并令右边等于零，得到方程：

-se / p2＋1/2＝0

从这个方程可以得出最优页面大小的公式（只考虑碎片浪费和页表所需的内存），结果是：

P=根号2se

对于 s = 1MB 和每个页表项 e = 8B，最优页面大小是 4KB。商用计算机使用的页面大小一般在 512B 到 64KB 之间，以前的典型值是 1KB，而现在更常见的页面大小是 4 KB 或 8KB。



##### 3.5.4   分离的指令空间和数据空间

大多数计算机只有一个地址空间，既存放程序也存放数据，如图 3-24a 所示。如果地址空间足够大，那么一切都好。然而，地址空间通常太小了，这就使得程序员对地址空间的使用出现困难。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE89.jpg"/>
</div>

首先在 PDP-11（16 位）上实现的一种解决方案是，为指令（程序正文）和数据设置分离的地址空间，分别称为 I **空间**和 D **空间**，如图 3-24b 所示。每个地址空间都从 0 开始到某个最大值，比较有代表性的是 2^16^-1 或者 2^32^-1。链接器必须知道何时使用分离的 I 空间和 D 空间，因为当使用它们时，数据被重定位到虚拟地址 0，而不是在程序之后开始。

在使用这种设计的计算机中，两种地址空间都可以进行分页，而且互相独立。它们分别有自己的页表，分别完成虚拟页面到物理页框的映射。当硬件进行取指令操作时，它知道要使用I空间和I空间页表。类似地，对数据的访问必须通过 D 空间页表。除了这一区别，拥有分离的 I 空间和 D 空间不会引入任何复杂的设计，而且它还能使可用的地址空间加倍。

尽管现在的地址空间已经很大，但其大小曾是一个很严重的问题。即便是在今天把地址空间划分成 I 和 D 层也很常见。现在的地址空间经常被划分到一级缓存里，而不再分给常规的地址空间。毕竟在一级缓存中，内存也是个稀缺品。



##### 3.5.5   共享页面

另一个设计问题是共享。在大型多道程序设计系统中，几个不同的用户同时运行同一个程序是很常见的。显然，由于避免了在内存中有一个页面的两份副本，共享页面效率更高。这里存在一个问题，即并不是所有的页面都适合共享。特别地，那些只读的页面（诸如程序文本）可以共享，但是数据页面则不能共享。

如果系统支持分离的 I 空间和 D 空间，那么让两个或者多个进程来共享程序就变得非常简单了，这些进程使用相同的 I 空间页表和不同的 D 空间页表。在一个比较典型的使用这种方式来支持共享的实现中，页表与进程表数据结构无关。每个进程在它的进程表中都有两个指针：一个指向 I 空间页表，一个指向 D 空间页表，如图 3-25 所示。当调度程序选择一个进程运行时，它使用这些指针来定位合适的页表，并使用它们来设立 MMU。即使没有分离的 I 空间和 D 空间，进程也可以共享程序（或者有时为库），但要使用更为复杂的机制。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE90.jpg"/>
</div>

在两个或更多进程共享某些代码时，在共享页面上存在一个问题。假设进程 A 和进程 B 同时运行一个编辑器并共享页面。如果调度程序决定从内存中移走 A，撤销其所有的页面并用一个其他程序来填充这些空的页框，则会引起 B 产生大量的缺页中断，才能把这些页面重新调入。

类似地，当进程 A 结束时，能够发现这些页面仍然在被使用是非常必要的，这样，这些页面的磁盘空间才不会被随意释放。查找所有的页表，考察一个页面是否共享，其代价通常比较大，所以需要专门的数据结构记录共享页面，特别地，如果共享的单元是单个页面（或一批页面），而不是整个页表。

共享数据要比共享代码麻烦，但也不是不可能。特别是在 UNIX 中，在进行 fork 系统调用后，父进程和子进程要共享程序文本和数据。在分页系统中，通常是让这些进程分别拥有它们自己的页表，但都指向同一个页面集合。这样在执行 fork 调用时就不需要进行页面复制。然而，所有映射到两个进程的数据页面都是**只读**的。

只要这两个进程都仅仅是读数据，而不做更改，这种情况就可以保持下去。但只要有一个进程更新了一点数据，就会触发只读保护，并引发操作系统陷阱。然后会生成一个该页的副本，这样每个进程都有自己的专用副本。两个复制都是可以读写的，随后对任何一个副本的写操作都不会再引发陷阱。这种策略意味着那些从来不会执行写操作的页面（包括所有程序页面）是不需要复制的，只有实际修改的数据页面需要复制。这种方法称为**写时复制**，它通过减少复制而提高了性能。



##### 3.5.6   共享库

可以使用其他的粒度取代单个页面来实现共享。如果一个程序被启动两次，大多数操作系统会自动共享所有的代码页面，而在内存中只保留一份代码页面的副本。代码页面总是只读的，因此这样做不存在任何问题。依赖于不同的操作系统，每个进程都拥有一份数据页面的私有副本，或者这些数据页面被共享并且被标记为只读。如果任何一个进程对一个数据页面进行修改，系统就会为此进程复制这个数据页面的一个副本，并且这个副本是此进程私有的，也就是说会执行 “写时复制”。

现代操作系统中，有很多大型库被众多进程使用，例如，处理浏览文件以便打开文件的对话框的库和多个图形库。把所有的这些库静态地与磁盘上的每一个可执行程序绑定在一起，将会使它们变得更加庞大。

一个更加通用的技术是使用**共享库**（在 Windows 中称作 **DLL** 或**动态链接库**）。为了清楚地表达共享库的思想，首先考虑一下传统的链接。当链接一个程序时，要在链接器的命令中指定一个或多个目标文件，可能还包括一些库文件。以下面的 UNIX 命令为例：

```
ld *.o -lc -lm 
```

这个命令会链接当前目录下的所有的 .o（目标）文件，并扫描两个库：/usr/lib/libc.a 和 /usr/lib/libm.a。任何在目标文件中被调用了但是没有被定义的函数（比如，printf），都被称作未定义外部函数（undefined externals）。链接器会在库中寻找这些**未定义外部函数**。如果找到了，则将它们加载到可执行二进制文件中。任何被这些未定义外部函数调用了但是不存在的函数也会成为未定义外部函数。例如，printf 需要 write，如果 write 还没有被加载进来，链接器就会查找 write 并在找到后把它加载进来。当链接器完成任务后，一个可执行二进制文件被写到磁盘，其中包括了所需的全部函数。在库中定义但是没有被调用的函数则不会被加载进去。当程序被装入内存执行时，它需要的所有函数都已经准备就绪了。

假设普通程序需要消耗 20~50MB 用于图形和用户界面函数。静态链接上百个包括这些库的程序会浪费大量的磁盘空间，在装载这些程序时也会浪费大量的内存空间，因为系统不知道它可以共享这些库。这就是引入共享库的原因。当一个程序和共享库（与静态库有些许区别）链接时，链接器没有加载被调用的函数，而是加载了一小段能够在运行时绑定被调用函数的存根例程（stub routine）。依赖于系统和配置信息，共享库或者和程序一起被装载，或者在其所包含函数第一次被调用时被装载。当然，如果其他程序已经装载了某个共享库，就没有必要再次装载它了——这正是关键所在。值得注意的是，当一个共享库被装载和使用时，整个库并不是被一次性地读入内存。而是根据需要，以页面为单位装载的，因此没有被调用到的函数是不会被装载到内存中的。

除了可以使可执行文件更小、节省内存空间之外，共享库还有一个优点：如果共享库中的一个函数因为修正一个 bug 被更新了，那么并不需要重新编译调用了这个函数的程序。旧的二进制文件依然可以正常工作。这个特性对于商业软件来说尤为重要，因为商业软件的源码不会分发给客户。例如，如果微软发现并修复了某个标准 DLL 中的安全错误，Windows 更新会下载新的 DLL 来替换原有文件，所有使用这个 DLL 的程序在下次启动时会自动使用这个新版本的 DLL。

不过，共享库带来了一个必须解决的小问题，如图 3-26 所示。我们看到有两个进程共享一个 20KB 大小的库（假设每一方框为 4KB）。但是，这个库被不同的进程定位在不同的地址上，大概是因为程序本身的大小不相同。在进程 1 中，库从地址 36K 开始；在进程 2 中则从地址 12K 开始。假设库中第一个函数要做的第一件事就是跳转到库的地址 16。如果这个库没有被共享，它可以在装载的过程中重定位，就会跳转（在进程 1 中）到虚拟地址的 36K+16。注意，库被装载到的物理地址与这个库是否为共享库是没有任何关系的，因为所有的页面都被 MMU 硬件从虚拟地址映射到了物理地址。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE91.jpg"/>
</div>

但是，由于库是共享的，因此在装载时再进行重定位就行不通了。毕竟，当进程 2 调用第一个函数时（在地址 12K），跳转指令需要跳转到地址 12K+16，而不是地址 36K+16。这就是那个必须解决的小问题。解决它的一个办法是写时复制，并为每一个共享这个库的进程创建新页面，在创建新页面的过程中进行重定位。当然，这样做和使用共享库的目的相悖。

一个更好的解决方法是：在编译共享库时，用一个特殊的编译选项告知编译器，不要产生使用绝对地址的指令。相反，只能产生使用相对地址的指令。例如，几乎总是使用向前（或向后）跳转 n 个字节（与给出具体跳转地址的指令不同）的指令。不论共享库被放置在虚拟地址空间的什么位置，这种指令都可以正确工作。通过避免使用绝对地址，这个问题就可以被解决。只使用相对偏移量的代码被称作**位置无关代码**（position-**independent code）。**



##### 3.5.7   内存映射文件

共享库实际上是一种更为通用的机制—**内存映射文件**（memory-mapped file）的一个特例。这种机制的思想是：进程可以通过发起一个系统调用，将一个文件映射到其虚拟地址空间的一部分。在多数实现中，在映射共享的页面时不会实际读入页面的内容，而是在访问页面时才会被每次一页地读入，磁盘文件则被当作后备存储。当进程退出或显式地解除文件映射时，所有被改动的页面会被写回到磁盘文件中。

内存映射文件提供了一种 I/O 的可选模型。可以把一个文件当作一个内存中的大字符数组来访问，而不用通过读写操作来访问这个文件。在一些情况下，程序员发现这个模型更加便利。

如果两个或两个以上的进程同时映射了同一个文件，它们就可以通过共享内存来通信。一个进程在共享内存上完成了写操作，此刻当另一个进程在映射到这个文件的虚拟地址空间上执行读操作时，它就可以立刻看到上一个进程写操作的结果。因此，这个机制提供了一个进程之间的高带宽通道，而且这种应用很普遍（甚至扩展到用来映射无名的临时文件）。很显然，如果内存映射文件可用，共享库就可以使用这个机制。



##### 3.5.8   清除策略

如果发生缺页中断时系统中有大量的空闲页框，此时分页系统工作在最佳状态。如果每个页框都被占用，而且被修改过的话，再换入一个新页面时，旧页面应首先被写回磁盘。为保证有足够的空闲页框，很多分页系统有一个称为**分页守护进程**（paging daemon）的后台进程，它在大多数时候睡眠，但定期被唤醒以检查内存的状态。如果空闲页框过少，分页守护进程通过预定的页面置换算法选择页面换出内存。如果这些页面装入内存后被修改过，则将它们写回磁盘。

在任何情况下，页面中原先的内容都被记录下来。当需要使用一个已被淘汰的页面时，如果该页框还没有被覆盖，将其从空闲页框缓冲池中移出即可恢复该页面。保存一定数目的页框供给比使用所有内存并在需要时搜索一个页框有更好的性能。分页守护进程至少保证了所有的空闲页框是“干净”的，所以空闲页框在被分配时不必再急着写回磁盘。

一种实现清除策略的方法就是使用一个双指针时钟。前指针由分页守护进程控制。当它指向一个脏页面时，就把该页面写回磁盘，前指针向前移动。当它指向一个干净页面时，仅仅指针向前移动。后指针用于页面置换，就像在标准时钟算法中一样。现在，由于分页守护进程的工作，后指针命中干净页面的概率会增加。



##### 3.5.9   虚拟内存接口

到现在为止，所有的讨论都假定虚拟内存对进程和程序员来说是透明的，也就是说，它们都可以在一台只有较少物理内存的计算机上看到很大的虚拟地址空间。对于不少系统而言这样做是对的，但对于一些高级系统而言，程序员可以对内存映射进行控制，并可以通过非常规的方法来增强程序的行为。这一节将简短地讨论一下这些问题。

允许程序员对内存映射进行控制的一个原因就是为了允许两个或者多个进程共享同一部分内存。如果程序员可以对内存区域进行命名，那么就有可能实现共享内存：通过让一个进程把一片内存区域的名称通知另一个进程，而使得第二个进程可以把这片区域映射到它的虚拟地址空间中去。通过两个进程（或者更多）共享同一部分页面，高带宽的共享就成为可能——一个进程往共享内存中写内容而另一个从中读出内容。De Bruijn（2011）描述了通信信道这种复杂例子。

页面共享也可以用来实现高性能的消息传递系统。一般地，传递消息的时候，数据被从一个地址空间复制到另一个地址空间，开销很大。如果进程可以控制它们的页面映射，就可以这样来发送一条消息：发送进程清除那些包含消息的页面的映射，而接收进程把它们映射进来。这里只需要复制页面的名字，而不需要复制所有数据。

另外一种高级存储管理技术是**分布式共享内存**（Feeley 等人，1995；Li，1986；Li 和 Hudak，1989；Zekauskas 等人，1994）。该方法允许网络上的多个进程共享一个页面集合，这些页面可能（而不是必要的）作为单个的线性共享地址空间。当一个进程访问当前还没有映射进来的页面时，就会产生缺页中断。在内核空间或者用户空间中的缺页中断处理程序就会对拥有该页面的机器进行定位，并向它发送一条消息，请求它清除该页面的映射，并通过网络发送出来。当页面到达时，就把它映射进来，并重新开始运行引起缺页中断的指令。在第 8 章中我们将详细讨论分布式共享内存。



#### 3.6   有关实现的问题

实现虚拟内存系统要在主要的理论算法（如第二次机会算法与老化算法，局部页面分配与全局页面分配，请求调页与预先调页）之间进行选择。但同时也要注意一系列实际的实现问题。在这一节中将涉及一些通常情况下会遇到的问题以及一些解决方案。

##### 3.6.1   与分页有关的工作

操作系统要在下面的四段时间里做与分页相关的工作：进程创建时，进程执行时，缺页中断时和进程终止时。下面将分别对这四个时期进行简短的分析。

当在分页系统中创建一个新进程时，操作系统要确定程序和数据在初始时有多大，并为它们创建一个页表。操作系统还要在内存中为页表分配空间并对其进行初始化。当进程被换出时，页表不需要驻留在内存中，但当进程运行时，它必须在内存中。另外，操作系统要在磁盘交换区中分配空间，以便在一个进程换出时在磁盘上有放置此进程的空间。操作系统还要用程序正文和数据对交换区进行初始化，这样当新进程发生缺页中断时，可以调入需要的页面。某些系统直接从磁盘上的可执行文件对程序正文进行分页，以节省磁盘空间和初始化时间。最后，操作系统必须把有关页表和磁盘交换区的信息存储在进程表中。

当调度一个进程执行时，必须为新进程重置 MMU，刷新 TLB，以清除以前的进程遗留的痕迹。新进程的页表必须成为当前页表，通常可以通过复制该页表或者把一个指向它的指针放进某个硬件寄存器来完成。有时，在进程初始化时可以把进程的部分或者全部页面装入内存中以减少缺页中断的发生，例如，PC（程序计数器）所指的页面肯定是需要的。

当缺页中断发生时，操作系统必须通过读硬件寄存器来确定是哪个虚拟地址造成了缺页中断。通过该信息，它要计算需要哪个页面，并在磁盘上对该页面进行定位。它必须找到合适的页框来存放新页面，必要时还要置换老的页面，然后把所需的页面读入页框。最后，还要回退程序计数器，使程序计数器指向引起缺页中断的指令，并重新执行该指令。

当进程退出的时候，操作系统必须释放进程的页表、页面和页面在硬盘上所占用的空间。如果某些页面是与其他进程共享的，当最后一个使用它们的进程终止的时候，才可以释放内存和磁盘上的页面。



##### 3.6.2   缺页中断处理

现在终于可以讨论缺页中断发生的细节了。缺页中断发生时的事件顺序如下：

1) 硬件陷入内核，在堆栈中保存程序计数器。大多数机器将当前指令的各种状态信息保存在特殊的 CPU 寄存器中。

2) 启动一个汇编代码例程保存通用寄存器和其他易失的信息，以免被操作系统破坏。这个例程将操作系统作为一个函数来调用。

3) 当操作系统发现一个缺页中断时，尝试发现需要哪个虚拟页面。通常一个硬件寄存器包含了这一信息，如果没有的话，操作系统必须检索程序计数器，取出这条指令，用软件分析这条指令，看看它在缺页中断时正在做什么。

4) 一旦知道了发生缺页中断的虚拟地址，操作系统检查这个地址是否有效，并检查存取与保护是否一致。如果不一致，向进程发出一个信号或杀掉该进程。如果地址有效且没有保护错误发生，系统则检查是否有空闲页框。如果没有空闲页框，执行页面置换算法寻找一个页面来淘汰。

5) 如果选择的页框 “脏” 了，安排该页写回磁盘，并发生一次上下文切换，挂起产生缺页中断的进程，让其他进程运行直至磁盘传输结束。无论如何，该页框被标记为忙，以免因为其他原因而被其他进程占用。

6) 一旦页框 “干净” 后（无论是立刻还是在写回磁盘后），操作系统查找所需页面在磁盘上的地址，通过磁盘操作将其装入。该页面正在被装入时，产生缺页中断的进程仍然被挂起，并且如果有其他可运行的用户进程，则选择另一个用户进程运行。

7) 当磁盘中断发生时，表明该页已经被装入，页表已经更新可以反映它的位置，页框也被标记为正常状态。

8) 恢复发生缺页中断指令以前的状态，程序计数器重新指向这条指令。

9) 调度引发缺页中断的进程，操作系统返回调用它的汇编语言例程。

10) 该例程恢复寄存器和其他状态信息，返回到用户空间继续执行，就好像缺页中断没有发生过一样。



##### 3.6.3   指令备份

当程序访问不在内存中的页面时，引起缺页中断的指令会半途停止并引发操作系统的陷阱。在操作系统取出所需的页面后，它需要重新启动引起陷阱的指令。但这并不是一件容易实现的事。

在最坏情形下考察这个问题的实质，考虑一个有双地址指令的 CPU，比如 Motorola 680x0，这是一种在嵌入式系统中广泛使用的 CPU。例如，指令

```assembly
MOVE.L#6(A1), 2(A0) 
```

为 6 字节（见图 3-27）。为了重启该指令，操作系统要知道该指令第一个字节的位置。在陷阱发生时，程序计数器的值依赖于引起缺页中断的那个操作数以及 CPU 中微指令的实现方式。

在图 3-27 中，从地址 1000 处开始的指令进行了 3 次内存访问：指令字本身和操作数的 2 个偏移量。从可以产生缺页中断的这3次内存访问来看，程序计数器可能在 1000、1002 和 1004 时发生缺页中断，对操作系统来说要准确地判断指令是从哪儿开始的通常是不可能的。如果发生缺页中断时程序计数器是 1002，操作系统无法弄清在 1002 位置的字是与 1000 的指令有关的内存地址（比如，一个操作数的位置），还是一个操作码。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE92.jpg"/>
</div>

这种情况已经很糟糕了，但可能还有更糟的情况。一些 680x0 体系结构的寻址方式采用自动增量，这也意味着执行这条指令的副作用是会增量一个或多个寄存器。使用自动增量模式也可能引起错误。这依赖于微指令的具体实现，这种增量可能会在内存访问之前完成，此时操作系统必须在重启这条指令前将软件中的寄存器减量。自动增量也可能在内存访问之后完成，此时，它不会在陷入时完成而且不必由操作系统恢复。自动减量也会出现相同的问题。自动增量和自动减量是否在相应内存引用之前完成随着指令和 CPU 模式的不同而不同。

幸运的是，在某些计算机上，CPU 的设计者们提供了一种解决方法，就是通过使用一个隐藏的内部寄存器。在每条指令执行之前，把程序计数器的内容复制到该寄存器。这些机器可能会有第二个寄存器，用来提供哪些寄存器已经自动增加或者自动减少以及增减的数量等信息。通过这些信息，操作系统可以消除引起缺页中断的指令所造成的所有影响，并使指令可以重新开始执行。如果该信息不可用，那么操作系统就要找出所发生的问题从而设法来修复它。看起来硬件设计者是不能解决这个问题了，于是他们就推给操作系统的设计者来解决这个问题。



##### 3.6.4   锁定内存中的页面

尽管本章对 I/O 的讨论不多，但计算机有虚拟内存并不意味着 I/O 不起作用了。虚拟内存和 I/O 通过微妙的方式相互作用着。设想一个进程刚刚通过系统调用从文件或其他设备中读取数据到其地址空间中的缓冲区。在等待 I/O 完成时，该进程被挂起，另一个进程被允许运行，而这个进程产生一个缺页中断。

如果分页算法是全局算法，包含 I/O 缓冲区的页面会有很小的机会（但不是没有）被选中换出内存。如果一个 I/O 设备正处在对该页面进行 DMA 传输的过程之中，将这个页面移出将会导致部分数据写入它们所属的缓冲区中，而部分数据被写入到最新装入的页面中。一种解决方法是锁住正在做 I/O 操作的内存中的页面以保证它不会被移出内存。锁住一个页面通常称为在内存中**钉住**（pinning）页面。另一种方法是在内核缓冲区中完成所有的 I/O 操作，然后再将数据复制到用户页面。



##### 3.6.5   后备存储

在前面讨论过的页面置换算法中，我们已经知道了如何选择换出内存的页面。但是却没有讨论当页面被换出时会存放在磁盘上的哪个位置，现在我们讨论一下磁盘管理相关的问题。

在磁盘上分配页面空间的最简单的算法是在磁盘上设置特殊的交换分区，甚至从文件系统划分一块独立的磁盘（以平衡 I/O 负载）。大多数 UNIX 是这样处理的。在这个分区里没有普通的文件系统，这样就消除了将文件偏移转换成块地址的开销。取而代之的是，始终使用相应分区的起始块号。

当系统启动时，该交换分区为空，并在内存中以单独的项给出它的起始和大小。在最简单的情况下，当第一个进程启动时，留出与这个进程一样大的交换区块，剩余的为总空间减去这个交换分区。当新进程启动后，它们同样被分配与其核心映像同等大小的交换分区。进程结束后，会释放其磁盘上的交换区。交换分区以空闲块列表的形式组织。更好的算法在第 10 章里讨论。

与每个进程对应的是其交换区的磁盘地址，即进程映像所保存的地方。这一信息是记录在进程表里的。写回一个页面时，计算写回地址的过程很简单：将虚拟地址空间中页面的偏移量加到交换区的开始地址。但在进程启动前必须初始化交换区，一种方法是将整个进程映像复制到交换区，以便随时可将所需内容装入，另一种方法是将整个进程装入内存，并在需要时换出。

但这种简单模式有一个问题：进程在启动后可能增大，尽管程序正文通常是固定的，但数据有时会增长，堆栈也总是在随时增长。这样，最好为正文、数据和堆栈分别保留交换区，并且允许这些交换区在磁盘上多于一个块。

另一个极端的情况是事先什么也不分配，在页面换出时为其分配磁盘空间，并在换入时回收磁盘空间，这样内存中的进程不必固定于任何交换空间。其缺点是内存中每个页面都要记录相应的磁盘地址。换言之，每个进程都必须有一张表，记录每一个页面在磁盘上的位置。这两个方案如图 3-28 所示。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE93.jpg"/>
</div>

在图 3-28a 中，有一个带有 8 个页面的页表。页面 0、3、4 和 6 在内存中。页面 1、2、5 和 7 在磁盘上。磁盘上的交换区与进程虚拟地址空间（8 页面）一样大，每个页面有固定的位置，当它从内存中被淘汰时，便写到相应位置。该地址的计算需要知道进程的分页区域的起始位置，因为页面是按照它们的虚拟页号的顺序连续存储的。内存中的页面通常在磁盘上有镜像副本，但是如果页面装入后被修改过，那么这个副本就可能是过期的了。内存中的深色页面表示不在内存，磁盘上的深色页面（原则上）被内存中的副本所替代，但如果有一个内存页面要被换回磁盘并且该页面在装入内存后没有被修改过，那么将使用磁盘中（深色）的副本。

在图 3-28b 中，页面在磁盘上没有固定地址。当页面换出时，要及时选择一个空磁盘页面并据此来更新磁盘映射（每个虚拟页面都有一个磁盘地址空间）。内存中的页面在磁盘上没有副本。它们在磁盘映射表中的表项包含一个非法的磁盘地址或者一个表示它们未被使用的标记位。

不能保证总能够实现固定的交换分区。例如，没有磁盘分区可用时。在这种情况下，可以利用正常文件系统中的一个或多个较大的、事前定位的文件。Windows 就使用这个方法。然而，可以利用优化方法减少所需的磁盘空间量。既然每个进程的程序正文来自文件系统中某个（可执行的）文件，这个可执行文件就可用作交换区。而更好的方法是，由于程序正文通常是只读的，当内存资源紧张、程序页不得不移出内存时，尽管丢弃它们，在需要的时候再从可执行文件读入即可。共享库也可以用这个方式工作。



##### 3.6.6   策略和机制的分离

控制系统复杂度的一种重要方法就是把策略从机制中分离出来。通过使大多数存储管理器作为用户级进程运行，就可以把该原则应用到存储管理中。在 Mach（Young 等人，1987）中首先应用了这种分离。下面的讨论是基于 Mach 的。

一个如何分离策略和机制的简单例子可以参见图 3-29。其中存储管理系统被分为三个部分：

1) 一个底层 MMU 处理程序。

2) 一个作为内核一部分的缺页中断处理程序。

3) 一个运行在用户空间中的外部页面调度程序。

所有关于 MMU 工作的细节都被封装在 MMU 处理程序中，该程序的代码是与机器相关的，而且操作系统每应用到一个新平台就要被重写一次。缺页中断处理程序是与机器无关的代码，包含大多数分页机制。策略主要由作为用户进程运行的外部页面调度程序所决定。

当一个进程启动时，需要通知外部页面调度程序以便建立进程页面映射，如果需要的话还要在磁盘上分配后备存储。当进程正在运行时，它可能要把新对象映射到它的地址空间，所以还要再一次通知外部页面调度程序。

一旦进程开始运行，就有可能出现缺页中断。缺页中断处理程序找出需要哪个虚拟页面，并发送一条消息给外部页面调度程序告诉它发生了什么问题。外部页面调度程序从磁盘中读入所需的页面，把它复制到自己的地址空间的某一位置。然后告诉缺页中断处理程序该页面的位置。缺页中断处理程序从外部页面调度程序的地址空间中清除该页面的映射，然后请求 MMU 处理程序把它放到用户地址空间的正确位置，随后就可以重新启动用户进程了。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE94.jpg"/>
</div>

这个实现方案没有给出放置页面置换算法的位置。把它放在外部页面调度程序中比较简单，但会有一些问题。这里有一条原则就是外部页面调度程序无权访问所有页面的R位和M位。这些二进制位在许多页面置换算法起重要作用。这样就需要有某种机制把该信息传递给外部页面调度程序，或者把页面置换算法放到内核中。在后一种情况下，缺页中断处理程序会告诉外部页面调度程序它所选择的要淘汰的页面并提供数据，方法是把数据映射到外部页面调度程序的地址空间中或者把它包含到一条消息中。两种方法中，外部页面调度程序都把数据写到磁盘上。

这种实现的主要优势是有更多的模块化代码和更好的适应性。主要缺点是由于多次交叉“用户－内核”边界引起的额外开销，以及系统模块间消息传递所造成的额外开销。现在看来，这一主题有很多争议，但是随着计算机越来越快，软件越来越复杂，从长远来看，对于大多数实现，为了获得更高的可靠性而牺牲一些性能也是可以接受的。



#### 3.7   分段

到目前为止讨论的虚拟内存都是一维的，虚拟地址从 0 到最大地址，一个地址接着另一个地址。对许多问题来说，有两个或多个独立的地址空间可能比只有一个要好得多。比如，一个编译器在编译过程中会建立许多表，其中可能包括：

1) 被保存起来供打印清单用的源程序正文（用于批处理系统）。

2) 符号表，包含变量的名字和属性。

3) 包含用到的所有整型量和浮点常量的表。

4) 语法分析树，包含程序语法分析的结果。

5) 编译器内部过程调用使用的堆栈。

前 4 个表随着编译的进行不断地增长，最后一个表在编译过程中以一种不可预计的方式增长和缩小。在一维存储器中，这 5 个表只能被分配到虚拟地址空间中连续的块中，如图 3-30 所示。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE95.jpg"/>
</div>

考虑一下如果一个程序中变量的数量要远比其他部分的数量多时的情况。地址空间中分给符号表的块可能会被装满，但这时其他表中还有大量的空间。

所需要的是一种能令程序员不用管理表扩张和收缩的方法，这与虚拟内存解决程序段覆盖问题所用的方法相同。

一个直观并且通用的方法是在机器上提供多个互相独立的称为**段**（segment）的地址空间。每个段由一个从 0 到最大的线性地址序列构成。各个段的长度可以是 0 到某个允许的最大值之间的任何一个值。不同的段的长度可以不同，并且通常情况下也都不相同。段的长度在运行期间可以动态改变，比如，堆栈段的长度在数据被压入时会增长，在数据被弹出时又会减小。

因为每个段都构成了一个独立的地址空间，所以它们可以独立地增长或减小而不会影响到其他的段。如果一个在某个段中的堆栈需要更多的空间，它就可以立刻得到所需要的空间，因为它的地址空间中没有任何其他东西阻挡它增长。段当然有可能会被装满，但通常情况下段都很大，因此这种情况发生的可能性很小。要在这种分段或二维的存储器中指示一个地址，程序必须提供两部分地址，一个段号和一个段内地址。图 3-31 给出了前面讨论过的编译表的分段内存，其中共有 5 个独立的段。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE96.jpg"/>
</div>

需要强调的是，段是一个逻辑实体，程序员知道这一点并把它作为一个逻辑实体来使用。一个段可能包括一个过程、一个数组、一个堆栈、一组数值变量，但一般它不会同时包含多种不同类型的内容。

除了能简化对长度经常变动的数据结构的管理之外，分段存储管理还有其他一些优点。如果每个过程都位于一个独立的段中并且起始地址是 0，那么把单独编译好的过程链接起来的操作就可以得到很大的简化。当组成一个程序的所有过程都被编译和链接好以后，一个对段 n 中过程的调用将使用由两个部分组成的地址（n，0）来寻址到字 0（入口点）。

如果随后位于段 n 的过程被修改并被重新编译，即使新版本的程序比老的要大，也不需要对其他的过程进行修改（因为没有修改它们的起始地址）。在一维地址中，过程被一个挨一个紧紧地放在一起，中间没有空隙，因此修改一个过程的大小会影响其他无关的过程的起始地址，而这又需要修改调用了这些被移动过的过程的所有过程，以使它们的访问指向这些过程的新地址。在一个有数百个过程的程序中，这个操作的开销可能是相当大的。

分段也有助于在几个进程之间共享过程和数据。这方面一个常见的例子就是共享库（shared library）。运行高级窗口系统的现代工作站经常要把非常大的图形库编译进几乎所有的程序中。在分段系统中，可以把图形库放到一个单独的段中由各个进程共享，从而不再需要在每个进程的地址空间中都保存一份。虽然在纯的分页系统中也可以有共享库，但是它要复杂得多，并且这些系统实际上是通过模拟分段来实现的。

因为每个段是一个为程序员所知道的逻辑实体，比如一个过程或一个数组，故不同的段可以有不同种类的保护。一个过程段可以被指明为只允许执行，从而禁止对它的读出和写入；一个浮点数组可以被指明为允许读写但不允许执行，任何试图向这个段内的跳转都将被截获。这样的保护有助于找到编程错误，图 3-32 对分段和分页进行了比较。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE97.jpg"/>
</div>



##### 3.7.1   纯分段的实现

分段和分页的实现本质上是不同的：页面是定长的而段不是。图 3-33a 所示的物理内存在初始时包含了 5 个段。现在让我们考虑当段 1 被淘汰后，比它小的段 7 放进它的位置时会发生什么样的情况。这时的内存配置如图 3-33b 所示，在段 7 与段 2 之间是一个未用区域，即一个空闲区。随后段 4 被段 5 代替，如图 3-33c 所示；段 3 被段 6 代替，如图 3-33d 所示。在系统运行一段时间后内存被划分为许多块，一些块包含着段，一些则成了空闲区，这种现象称为**棋盘形碎片**或**外部碎片**（external fragmentation）。空闲区的存在使内存被浪费了，而这可以通过内存紧缩来解决，如图 3-33e 所示。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE98.jpg"/>
</div>



##### 3.7.2	分段和分页实现：MUTICS

略



##### 3.7.3	分段和分页结合：Intel x86

略



#### **3.8   有关内存管理的研究**

略



#### 3.9	小结

本章主要讲解内存管理。我们看到在最简单的系统中是根本没有任何交换或分页的。一旦程序装入内存，它将持续在内存中运行，直到结束。一些操作系统一次只允许一个进程在内存中运行，而另一些操作系统支持多道程序设计。这种模型在小型或嵌入式实时系统中仍有用武之地。

接下来是交换技术。通过交换技术，系统可以同时运行总内存占用超过实际物理内存大小的多个进程。如果一个进程没有内存空间可用。它将会被交换到磁盘上。内存和磁盘上的空闲空间可以使用位图或空闲区链表来记录。

现代计算机都有某种形式的虚拟内存。最简单的情况下，每一个进程的地址空间被划分为同等大小的块，称为页面，页面可以被放入内存中任何可用的页框内。有多种页面置换算法，其中两个比较好的算法是老化算法和工作集时钟算法。

为了使分页系统工作良好，仅选择算法是不够的，还要关注诸多问题，例如工作集的确定，内存分配策略以及所需页面大小等。

如果要处理在执行过程中大小有变化的数据结构，分段是一个有用的选择，它还能简化链接和共享。不仅如此，分段还有利于为不同的段提供不同的保护。有时，可以把分段和分页结合起来，以提供二维的虚拟内存。MULTICS 系统以及 32 位 Intel x86 即使如此，支持分段也支持分页。不过，几乎没有操作系统开发者会仔细考虑分段（因为他们更青睐其他的内存模型），这导致分段逐渐乏人问津。如今，即使 64 位版本的 x86 也不支持真正的分段。





### 第 4 章	文件系统

所有的计算机应用程序都需要存储和检索信息。进程运行时，可以在它自己的地址空间存储一定量的信息，但存储容量受地址空间大小的限制。对于某些应用程序，它自己的地址空间已经足够用了；但是对于其他一些应用程序，例如航空订票系统、银行系统或者公司记账系统，这些存储空间又显得太小了。

在进程的地址空间上保存信息的第二个问题是：进程终止时，它保存的信息也随之丢失。对于很多应用（如数据库）而言，有关信息必须能保存几星期、几个月，甚至永久保留。在使用信息的进程终止时，这些信息是不可以消失的，甚至，即使是系统崩溃致使进程消亡了，这些信息也应该保存下来。

第三个问题是：经常需要多个进程同时访问同一信息（或者其中部分信息）。如果我们在单个进程的地址空间内存储了在线电话目录，则只有该进程才能访问它。 解决此问题的方法是使信息本身独立于任何一个过程。

因此，长期存储信息有三个基本要求：

1）能够存储大量信息。

2）使用信息的进程终止时，信息仍旧存在。

3）必须能使多个进程并发访问有关信息。

磁盘（magnetic disk）由于其长期存储的性质，已经有多年的使用历史。近些年，固态硬盘逐渐流行起来，因为它不仅没有易损坏的移动部件，而且可以提供快速的随机访问。相比而言，虽然磁带和光盘也被广泛使用，但是它们的性能相对较差，通常应用于备份。在第 5 章会学习更多有关磁盘的知识，目前可以先把磁盘当作一种大小固定的块的线性序列，并且支持如下两种操作。

1）读块k；

2）写块k。

事实上磁盘支持更多的操作，但只要有了这两种操作，原则上就可以解决长期存储的问题。

不过，这里存放着很多不便于实现的操作，特别是在有很多程序或者多用户使用着的大型系统上（如服务器）。在这种情况下，很容易产生一些问题，例如：

1）如何找到信息？

2）如何防止一个用户读取另一个用户的数据？

3）如何知道哪些块是空闲的？

就像操作系统提取处理器的概念来建立进程的抽象，以及提取物理存储器的概念来建立进程（虚拟）地址空间的抽象那样，我们可以用一个新的抽象——文件来解决这个问题。进程（与线程）、地址空间和文件，这些抽象概念均是操作系统中最重要的概念。如果真正深入理解了这三个概念，那么读者就迈上了成为一个操作系统专家的道路。

**文件**是进程创建的信息逻辑单元。一个磁盘一般含有几千甚至几百万个文件，每个文件是独立于其他文件的，唯一不同的是文件是对磁盘的建模，而非对 RAM 的建模。事实上，如果能把每个文件看成一个地址空间，那么读者就能理解文件的本质了。

进程可以读取已经存在的文件，并在需要时建立新的文件。存储在文件中的信息必须是**持久的**，也就是说，不会因为进程的创建与终止而受到影响。一个文件只能在其所有者明确删除它的情况下才会消失。尽管读写文件是最常见的操作，但还有很多其他操作，其中一些将在下面加以介绍。

文件是受操作系统管理的。有关文件的构造、命名、访问、使用、保护、实现和管理方法都是操作系统设计的主要内容。从总体上看，操作系统中处理文件的部分称为**文件系统**（file system），这就是本章的论题。

从用户角度来看，文件系统中最重要的是它在用户眼中的表现形式，也就是文件是由什么组成的，怎样给文件命名，怎样保护文件，以及可以对文件进行哪些操作等。至于用链表还是用位图来记录空闲存储区以及在一个逻辑磁盘块中有多少个扇区等细节并不是用户所关心的，当然对文件系统的设计者来说这些内容是相当重要的，正因为如此，本章将分为几节讲述，前两节分别介绍文件和目录的用户接口，随后详细讨论文件系统的实现，最后介绍一些文件系统的实例。



#### 4.1	文件

在本节中，我们从用户角度来考察文件，即用户如何使用文件？文件具有哪些特性？

##### 4.1.1	文件命名

文件是一种抽象机制，它提供了一种在磁盘上保存信息而且方便以后读取的方法。这种方法可以使用户不必了解存储信息的方法、位置和实际磁盘工作方式等有关细节。

也许任何一种抽象机制的最重要的特性就是对管理对象的命名方式，所以，我们将从对文件的命名开始考察文件系统。在进程创建文件时，它给文件命名。在进程终止时，该文件仍旧存在，并且其他进程可以通过对这个文件名对它进行访问。

文件的具体命名规则则在各个系统中是不同的，不过所有的现代操作系统都允许用 1 至 8 个字母组成的字符串作为合法的文件名。因此，andrea、btuce 和 cathy 都是合法文件名。通常，文件名中也允许有数字和一些特殊字符，所以像 2、rugent! 和 Fig.2-14 也是合法的。许多文件系统支持长达 255 个字符的文件名。

有些文件系统区分大小写字母，有些则不区分。UNIX 属于前一类，老的文件系统 MS-DOS 则属于后一类。（顺便提一下，尽管 MS-DOS 很古老了，但它仍然非常广泛地应用于嵌入式系统，所以 MS-DOS 绝对没有过时。）

Windos 95 和 Windows 98 用的都是 MS-DOS 的文件系统，即 **FAT-16**，因此继承了其很多特性，例如有关文件名的构造方法。WIndows 98 对 FAT-16 进行了一些扩展，从而成为 **FAT-32**。但这两者是很相似的。另外，虽然 FAT 已经过试，但很多 Windows 系统仍然支持该文件系统。然而，较新版本的操作系统已经拥有更先进的本地文件系统（**NTFS**（New Technology File System））。该文件系统具有一些新的特性（例如基于 Unicode 编码的文件名）。事实上，Windows 8 配备了另一种文件系统，简称为 ReFS（或弹性文件系统），但该文件系统一般用于 Windows 8 的服务器版本。在本章中，当提到 MS-DOS 或 FAT 文件系统的时候，除非特别指明，否则所指的就是 Windows 的 FAT-16 与 FAT-32。本章后面将讨论 FAT 文件系统，在第 11 章详细分析 Windows 8 时将讨论 NTFS 文件系统。顺便说一下，有一种类似 FAT 的新型文件系统，叫做 **exFAT**。它是微软公司对闪存和大文件系统开发的一种优化的 FAT32 扩展版本。ExFAT 是现在微软唯一能满足 OS X 读写操作的文件系统。

许多操作系统支持文件名用圆点隔开分为两部分，如文件名 prog.c。圆点后面的部分称为文件扩展名（file extension）。文件扩展名通常表示文件的一些信息，如 MS-DOS 中，文件名由 1 至 8 个字符以及 1 至 3 个字符的可选扩展名组成。在 UNIX 里，如果有扩展名，则扩展名长度完全由用户决定，一个文件甚至可以包含两个或更多的扩展名，如 homepage.html.zio，这里 .html 表明 HTML 格式的一个 Web 页面，.zip 表示该文件（homepage.html）已经采用 zip 程序压缩过。一些常用文件扩展名及其含义如图 4-1 所示。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE99.jpg"/>
</div>

在某些系统中（如所有 UNIX 版本），文件扩展名只是一种约定，操作系统并不强迫采用它。名为 file.txt 的文件也许是文本文件，这个文件名更多的是提醒所有者，而不是表示传送什么信息给计算机。但是另一方面，C 编译器可能要求它编译的文件以 .c 结尾，否则它会拒绝编译。然而，操作系统不关心这一点。

对于可以处理多种类型文件的某个程序，这类约定是特别有用的。例如，C 编译器可以编译、链接多种文件，包括 C 文件和汇编语言文件。这时扩展名就很有必要，编译器利用它区分哪些是 C 文件，哪些是汇编文件，哪些是其他文件。

与 UNIX 相反，Windows 关注扩展名并对其赋予了含义。用户（或进程）可以在操作系统中注册扩展名，并且规定哪个程序 “拥有” 该扩展名。当用户双击某个文件名时，“拥有” 该文件扩展名的程序就启动并运行该文件。例如，双击 file.docx 启动了 Microsoft Word 程序，并以 file.docx 作为待编辑的初始文件。



##### 4.1.2	文件结构

文件可以有多种构造方式，在图 4-2 中列出了常用的三种方式。图 4-2a 中的文件是一种无结构的字节序列，事实上操作系统不知道也不关心文件内容是什么，操作系统所见到的就是字节，其文件内容的任何含义只在用户程序中解释。UNIX 和 Windows 都采用这种方法。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE100.jpg"/>
</div>

把文件看成字节序列为操作系统提供了最大的灵活性。用户程序可以向文件中加入任何内容，并以任何方便的形式命名。操作系统不提供任何帮助，但也不会构成障碍。对于想做特殊操作的用户来说，后者是非常重要的。所有 UNIX 版本（包括 Linux 和 OS X）以及 Windows 都采用这种文件模型。

图 4-2b 表示在文件结构上的第一步改进。在这个模型中，文件是具有固定长度记录的序列，每个记录都有其内部结构。把文件作为记录序列的中心思想是：读操作返回一个记录，而写操作重写或追加一个记录。这里对 “记录” 给予一个历史上的说明，几十年前，当 80 列的穿孔卡片还是主流的时候，很多（大型机）操作系统把文件系统建立在由 80 个字符的记录组成的文件基础之上。这些操作系统也支持 132 个字符的记录组成的文件，这是为了适应行式打印机（当时的行式打印机有 132 列宽）。程序以 80 个字符为单位读入数据，并以 132 个字符为单位写数据，其中后面 52 个字符都是空格。现在已经没有使用这种文件系统的通用系统了，但是在 80 列穿孔卡片和 132 列宽行式打印机流行的日子里，这是大型计算机系统中的常见模式。

第三种文件结构如图 4-2c 所示。文件在这种结构中由一颗记录树构成，每个记录不必具有相同的长度，记录的固定位置上有一个**键**字段。这棵树按 “键” 字段进行排序，从而可以对特定 “键” 进行快速查找。

虽然在这这类结构中取 “下一个” 记录是可以的，但是基本操作并不是取 “下一个” 记录，而是获得具有特定键的记录。如图 4-2c 中的文件是 zoo，用户可以要求系统读取键为 pony 的记录，而不必关心记录在文件中的确切位置。更进一步地，用户可以在文件中添加新记录。但是，用户不能决定把记录添加在文件的什么位置，这是由操作系统决定的。这类文件结构与 UNIX 和 Windows 中采用的无结构字节流明显不同，但它在一些处理商业数据的大型计算机中获得广泛使用。



##### 4.1.3	文件类型

很多操作系统支持多种文件类型。如 UNIX（当然，包括 OS X）和 Windows 中都有普通文件和目录，UNIX 还有**字符特殊文件**（character special file）和**块特殊文件**（block special file）。**普通文件**（regular file）是包含有用户信息的文件。图 4-2 中的所有文件都是普通文件。**目录**（directory）是管理文件系统结构的系统文件，将在以后的章节中讨论。字符特殊文件和输入/输出有关，用于串行 I/O 类设备，如终端、打印机、网络等。块特殊文件用于磁盘类设备。本章主要讨论普通文件。

普通文件一般分为 ASCII 文件和二进制文件。ASCII 文件由多行正文组成。在某些系统中，每行用回车符结束，其他系统则用换行符结束。有些系统还同时采用回车符和换行符（如 MS-DOS）。文件中各行的长度不一定相同。

ASCII 文件的最大优势是可以显示和打印，还可以用任何文件编辑器进行编辑。再者，如果很多程序都以 ASCII 文件作为输入和输出，就很容易把一个程序的输出作为另一个程序的输入，如 shell 管道一样。（用管道实现进程间通信并非更容易，但若以一种公认的标准（如 ASCII 码）来表示，则更易于信息翻译。）

其他与 ASCII 文件不同的是二进制文件。打印出来的二进制文件是无法理解的、充满混乱字符的一张表。通常，二进制文件有一定的内部结构，使用该文件的程序才了解这种结构。

如图 4-3a 是一个简单的可执行二进制文件，它取自某个早期版本的 UNIX。尽管这个文件只是一个字节序列，但只有文件的格式正确时，操作系统才会执行这个文件。这个文件有五个段：文件头、正文、数据、重定位位及字符表。文件头以所谓的**魔数**（magic number）开始，表明该文件是一个可执行的文件（防止非这种格式的文件偶然运行）。魔数后面是文件中各段的长度、执行的起始地址和一些标志位。程序本身的正文和数据在文件头后面。这些被装入内存，并使用重定位位重新定位。符号表则用于调试。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE101.jpg"/>
</div>

二进制文件的第二个例子是 UNIX 的存档文件，它由已编译但没有链接的库过程（模块）组合而成。每个文件以模块头开始，其中记录了名称、创建日期、所有者、保护码和文件大小。该模块头与可执行文件一样，也都是二进制数字，打印输出它们毫无意义。

所有操作系统必须至少能够识别它们自己的可执行文件的文件类型，其中有些操作系统还可识别更多的文件类型。一种老式的 TOPS-20 操作系统（用于 DECsustem20 计算机）甚至可检查可执行文件的创建时间，然后，它可以找到相应的源文件，看它在二进制文件生成后是否被修改过。如果修改过，操作系统自动重新编译这个文件。在 UNIX 中，就是在 shell 中嵌入 make 程序。这时操作系统要求用户必须采用固定的文件扩展名，从而确定哪个源程序生成哪个二进制文件。

如果用户执行了系统设计者没有考虑到的某种操作，这种强制类型的文件有可能会引起麻烦。比如在一个系统中，程序输出文件的扩展名是 .dat（数据文件），若用户写一个格式化程序，读入 .c（C 程序）文件并转换它（比如把该文件转换成标准的首行缩进），再把转换后的文件以 .dat 类型输出。如果用户试图用 C 编译器来编译这个文件，因为文件扩展名不对，C 编译器会拒绝编译。若想把 file.dat 复制到 file.c 也不行，因为系统会认为这是无效的复制（防止用户错误）。

尽管对初学者而言，这类 “保护” 是有利的，但一些有经验的用户却感到很烦恼，因为他们要花很多精力来适应操作系统对合理和不合理操作的划分。



##### 4.1.4	文件访问

早期操作系统只有一种文件访问方式：**顺序访问**（sequential access）。进程在这些系统中可从头按顺序读取文件的全部字节或记录，但不能跳过某一些内容，也不能不按顺序读取。顺序访问文件是可以返回到起点的，需要时可多次读取该文件。在存储介质是磁带而不是磁盘时，顺序访问文件是很方便的。

当用磁盘来存储文件时，可以不按顺序地读取文件中的字节或记录，或者按照关键字而不是位置来访问记录。这种能够以任何次序读取其中字节或记录地文件称为**随机访问文件**（random access file）。许多应用程序需要这种类型的文件。

随机访问文件对很多应用程序而言是必不可少的，如数据库系统。如果乘客打电话预订某航班机票，订票程序必须能直接访问该航班记录，而不必先读出其他航班的成千上万个记录。

有两种方法可以指示从何处开始读取文件。一种是每次 read 操作都给出开始读文件的位置。另一种是用一个特殊的 seek 操作设置当前位置，在 seek 操作后，从这个当前位置顺序地开始读文件。UNIX 和 Windows 使用的是后一种方法。



##### 4.1.5	文件属性

文件都有文件名和数据。另外，所有的操作系统还会保存其他与文件有关的信息，如文件创建的日期和时间、文件大小等。这些附加信息称为文件**属性**（attribute），有些人称为**元数据**（metadata）。文件的属性在不同系统中差别很大。一些常用的属性在图 4-4 中列出，但还存在其他的属性。没有一个系统具有所有这些属性，但每个属性都在某个系统中采用。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE102.jpg"/>
</div>

前 4 个属性与文件保护相关，它们指出了谁可以访问这个文件，谁不能访问这个文件。有各种不同的文件保护方案，以后会讨论其他一些保护方案。在一些系统中，用户必须给出口令才能访问文件。此时，口令也必须是文件属性之一。

标志是一些位或短字段，用于控制或启用某些特殊属性。例如，隐藏文件位表示该文件不在文件列表中出现。存档标志位用于记录文件是否备份过，由备份程序清除该标志位；若文件被修改，操作系统则设置该标志位。用这种方法，备份程序可以知道哪些文件需要备份。临时标志表明当创建该文件的进程终止时，文件会被自动删除。

记录长度、键的位置和键的长度等字段只能出现在用关键字查找记录的文件里，它们提供了查找关键字所需的信息。

不同的时间字段记录了文件的创建时间、最近一次访问时间以及最后一次修改时间，它们的作用不同。例如，目标文件生成后被修改的源文件需要重新编译生成目标文件。这些字段提供了必要的信息。

当前大小字段指出了当前的文件大小。在一些老式大型机操作系统中创建文件时，要给出文件的最大长度，以便操作系统事先按照最大长度留出存储空间。工作站和个人计算机中的操作系统则聪明多了，不需要这一点提示。



##### 4.1.6	文件操作

使用文件的目的是存储信息并方便以后的检索。对于存储和检索，不同系统提供了不同的操作。以下是与文件有关的最常用的一些系统调用：

1）create。创建不包含任何数据的文件。该调用的目的是表明文件即将建立，并设置文件的一些属性。

2）delete。当不再需要某个文件时，必须删除该文件以释放磁盘空间。任何文件系统总有一个系统调用用来删除文件。

3）open。在使用文件之前，必须先打开文件。open 调用的目的是：把文件属性和磁盘地址表装入内存，便于后续调用的快速访问。

4）close。访问结束后，不再需要文件属性和磁盘地址，这时应该关闭文件以释放内部表空间。很多系统限制进程打开文件的个数，以鼓励用户关闭不再使用的文件。磁盘以块为单位写入，关闭文件时，写入该文件的最后一块，即使这个块还没有满。

5）read。在文件中读取数据。一般地，读取的数据来自文件的当前位置。调用者必须指明需要读取多少数据，并且提供存放这些数据的缓冲区。

6）write。向文件写数据，写操作一般也是从文件当前位置开始。如果当前位置是文件末尾，文件长度增加。如果当前位置在文件中间，则现有数据被覆盖，并且永远丢失。

7）append。此调用是 write 的限制形式，它只能在文件末尾添加数据。若系统只提供最小系统调用集合，则通常没有 append。很多系统对同一操作提供了多种实现方法，这些系统中有时有 append 调用。

8）seek。对于随机访问文件，要制定从何处开始获取数据，通常的方法是用 seek 系统调用把当前位置指针指向文件中特定位置。seek 调用结束后，就可以从该位置开始读写数据了。

9）get attribute。进程进行常需要读取文件属性。例如，UNIX 中 make 程序通常用于管理由多个源文件组成的软件开发项目。在调用 make 时，它会检查全部源文件和目标文件的修改时间，实现最小编译，使得全部文件都为最新版本。为达到此目的，需要查找文件的某一些属性，即修改时间。

10）set attribute。某些属性是可由用户设置的，甚至是在文件创建之后，实现该功能的是 set attribute 系统调用。保护模式信息是一个典型的例子，大多数标志也属于此类属性。

11）rename。用户常常要改变已有文件的名字，rename 系统调用用于这一目的。严格地说，rename 系统调用不是必需的，因为先把文件复制到一个新文件中，然后删除原来的文件，就可以达到同样地目的。



##### 4.1.7	使用文件系统调用的一个示例程序

**文件描述符**：打开一个文件时返回的一个小整数。





#### 4.2	目录

文件系统通常提供**目录**或**文件夹**用于记录文件的位置，在很多系统中目录本身也是文件。本节讨论目录、目录的组成、目的特性和可以对目录进行的操作。



##### 4.2.1	一级目录系统

目录系统的最简单形式是在一个目录中包含所有的文件。这有时称为**根目录**，但是由于只有一个目录，所以其名称并不重要。在早期的个人计算机中，这种系统很普遍，部分原因是因为只有一个用户。有趣的是，世界第一台超级计算机 CDC 6600 对于所有的文件也只有一个目录，尽管该机器同时被许多用户使用。这种决策毫无疑问是是为了简化软件设计。

一个单层目录系统的例子如图 4-6 所示。该目录中有四个文件。这一设计的优点在于简单，并且能够快速定位文件——事实上只有一个地方要查看。这种目录系统经常用于简单的嵌入式装置中，诸如电话、数码相机以及一些便携式音乐播放器等。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE103.jpg"/>
</div>





##### 4.2.2	层次目录系统

对于简单的特殊应用而言，单层目录是合适的（单层目录甚至用在了第一代个人计算机中），但是现在的用户有着数以千计的文件，如果所有的文件都在一个目录中，寻找文件就很困难。这样，就需要有一种方式将相关的文件组合在一起。例如，某个教授可能有多组文件，每组文件的作用不同。

这里所需要的是层次结构（即一个目录树）。通过这种方式，可以用很多目录把文件以自然的方式分组。进而，如果多个用户分享同一个文件服务器，如许多公司的网络系统，每个用户可以为自己的目录树拥有自己的私人根目录。这种方式如图 4-7 所示，其中，根目录含有目录 A、B 和 C，分别属于不同用户，其中有两个用户为他们的项目创建了子目录。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE104.jpg"/>
</div>

用户可以创建任意数量的子目录，这为用户组织其工作提供了强大的结构化工具。因此，几乎所有现代文件系统都是用这个方式组织的。



##### 4.2.3	路径名

**绝对路径名**（absolute path name）：每个文件都有一个绝对路径名，它由从根目录到文件的路径组成。

**相对路径名**（relative path name）：它常和**工作目录**（working directory）（也称作**当前目录**（current directory））一起使用。用户可以指定一个目录作为当前工作目录，这时，所有的不从根目录开始的路径名都是相对于工作目录的。每个进程都有自己的工作目录，这样在进程改变工作目录并退出后，其他进程不会受到影响，文件系统中也不会有改变的痕迹。对进程而言，切换工作目录是安全的，所以只要需要，就可以改变当前工作目录。但是，如果改变了库过程的工作目录，并且工作完毕之后没有修改回去，则其他程序有可能无法正常运行，因为它们关于当前目录的假设已经失效。所以库过程很少改变工作目录，若非改不可，必定要在返回之前改回到原有的工作目录。

支持层次目录结构的大多数操作系统在每个目录中有两个特殊的目录项 "." 和 ".."，常读作 "dot" 和 "dotdot"。dot 指当前目录，dotdot 指其父目录（在根目录中例外，在根目录中它指向自己）。



##### 4.2.4	目录操作

不同系统中管理目录的系统调用的差别比管理文件的系统调用的差别大。为了了解这些系统调用有哪些及它们怎样工作，下面给出一个例子（取自 UNIX）。

1）create。创建目录。除了目录项 "." 和 ".." 外，目录内容为空。目录项 "." 和 ".." 是系统自动放在目录中的（有时通过 mkdir 程序完成）。

2）deleta。删除目录。只有空目录可删除。只包含目录项 "." 和 ".." 的目录被认为是空目录，这两个目录项通常不能删除。

3）opendir。目录内容可被读取。例如，为列出目录中全部文件，程序必须先打开该目录，然后读其中全部文件的文件名。与打开和读文件相同，在读目录前，必须打开目录。

4）closedir。读目录结束后，应关闭目录以释放内部表空间。

5）readdir。系统调用 readdir 返回打开目录的下一个目录项。以前也采用 read 系统调用来读目录，但这方法有一个缺点：程序员必须了解和处理目录的内部结构。相反，不论采用哪一种目录结构，readdir 总是以标准格式返回一个目录项。

6）rename。在很多方面目录和文件都相似。文件可换名，目录也可以。

7）link。链接技术允许在多个目录中出现同一个文件。这个系统调用指定一个存在的文件和一个路径名，并建立从该文件到路径所指名字的链接。这样，可以在多个目录中出现同一个文件。这种类型的链接增加了该文件的 i 节点（i-node）计数器的计数（记录含有该文件的目录项数目），有时称为**硬链接**（hard link）。

8）unlink。删除目录项。如果被解除连接的文件只出现在一个目录中（通常情况），则将它从文件系统中删除。如果它出现在多个目录中，则只删除指定路径名的连接，依然保留其他路径名的连接。在 UNIX 中，用于删除文件的系统调用（前面已有论述）实际上就是 unlink。

最主要的系统调用已在数目列出，但还有其他一些调用，如与目录相关的管理保护信息的系统调用。

关于链接文件的一种不同想法是**符号链接**。不同于使用两个文件名指向同一个内部数据结构来代表一个文件，在符号链接中，一个文件名指向命名另一个文件的一个小文件。当使用这个小文件时，例如打开文件，文件系统沿着路径最终找到文件名，再用新名字启动查找文件的过程。符号链接的优点在于它能够跨越磁盘的界限，甚至可以命名再远程计算机上的文件，不过符号链接的实现并不如硬链接那样有效率。



#### 4.3	文件系统的实现

现在从用户角度转到实现者角度来考察文件系统。用户关心的是文件是怎样命名的、可以进行哪些操作、目录树是怎么样的以及类似的表面问题。而实现者感兴趣的是文件和目录是怎样存储的、磁盘空间是怎样管理的以及怎样使系统有效而可靠地工作等。在下面几节中，我们会考虑这些文件系统的实现中出现的问题，并讨论怎样解决这些问题。



##### 4.3.1	文件系统布局

文件系统存放在磁盘上。多数磁盘划分为一个或多个分区，每个分区中有一个独立的文件系统。磁盘的 0 号扇区称为**主引导记录**（Master Boot Record，MBR），用来引导计算机。在 MBR 的结尾是分区表。该表给出了每个分区的起始和结束地址。表中的一个分区被标记为活动分区。在计算机被引导时，BIOS 读入并执行 MBR。MBR 做的第一件事是确定活动分区，读入它的第一个快，称为**引导块**（boot block），并执行之。引导块中的程序将装载该分区中的操作系统。为统一起见，每个分区都从一个引导块开始，即使它不含有一个可启动的操作系统。不过，未来这个分区也许会有一个操作系统的。

除了从引导块开始之外，磁盘分区的布局是随着文件系统的不同而变化的。文件系统经常包含有如图 4-9 所列的一些项目。第一个是**超级块**（superblock）。超级块包含文件系统的所有关键参数，在计算机启动时，或者在该文件系统首次使用时，超级块会被读入内存。超级块中的典型信息包括：确定文件系统类型用的魔数、文件系统中的块的数量以及其他重要的管理信息。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE105.jpg"/>
</div>

接着是文件系统中空闲块的信息，例如，可以用位图或指针列表的形式给出。后面也许跟随的是一组 i 节点，这是一个数据结构数组，每个文件一个，i 节点说明了文件的方方面面。接着可能是根目录，它存放文件系统目录树的根部。最后，磁盘的其他部分存放了其他所有的目录和文件。



##### 4.3.2	文件的实现

文件存储实现的关键问题是记录各个文件分别用到了哪些磁盘块。不同操作系统采用不同的方法。这一节，我们讨论其中的一些方法。

**1.连续分配**

最简单的分配方案是把每个文件作为一连串连续数据块存储在磁盘上。所以，在块大小为 1KB 的磁盘上，50KB 的文件要分配 50 个连续的块。对于块大小为 2KB 的磁盘，将分配 25 个连续的块。

在图 4-10a 中是一个连续分配的例子。这里列出了头 40 块，从左面从 0 块开始。初始状态下，磁盘是空的。接着，从磁盘开始处（块 0）开始写入长度为 4 块的文件 A。紧接着，在文件 A 的结尾开始写入一个 3 块的文件 B。

请注意，每个文件都从一个新的块开始，这样如果文件 A 实际上只有 3.5 块，那么最后一块的结尾会浪费一些空间。在图 4-10 中，一共列出了 7 个文件，每一个都从前面文件结尾的后续块开始。加阴影是为了容易表示文件分隔，在存储中并没有实际的意义。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE106.jpg"/>
</div>

连续磁盘空间分配方案有两大优势。首先，实现简单，记录每个文件用到的磁盘块简化为只需记住两个数字即可：第一块的磁盘地址和文件的块数。给定了第一块的编号，一个简单的加法就可以找到任何其他块的编号。

其次，读操作性能较好，因为在单个操作中就可以从磁盘上读出整个文件。只需要一次寻找（对第一个块）。之后不再需要寻道和旋转延迟，所以，数据以磁盘全带宽的速录输入。可见连续分配实现简单且具有高的性能。

但是，连续分配方案也同样有相当明显的不足之处：随着时间的推移，磁盘会变得零碎。为了了解这是如何发生的，请考察图 4-10b。这里有两个文件（D 和 F）被删除了。当删除一个文件时，它占用的块自然就释放了，在磁盘上留下一堆空闲块。磁盘不会在这个位置挤压掉这个空洞，因为这样会涉及复制空洞之后的所有文件，可能会有上百万的块。结果是，磁盘上最终既包括文件也有空洞，如图 4-10 中所描述的那样。

开始时，碎片并不是问题，因为每个新的文件都在先前文件的结尾部分之后的磁盘空间里写入。但是，磁盘最终会被充满，所以要么压缩磁盘，要么重新使用空洞所在的空闲空间。前者由于代价太高而不可行；后者需要维护一个空洞列表，这是可行的。但是，当创建一个新的文件时，为了挑选合适大小的空洞存入文件，就有必要知道该文件的最终大小。

设想这样一种设计的结果：为了录入一个文档，用户启动了文本编辑器或字处理软件。程序首先询问最终文件的大小会是多少。这个问题必须回答，否则程序就不能继续。如果给出的数字最后被证明小于文件的实际大小，该程序会终止，因为所使用的磁盘空洞已经满了，没有地方放置文件的剩余部分。如果用户为了避免这个问题而给出不实际的较大的数字作为最后文件的大小，比如，100MB，编辑器可能找不到如此大的空洞，从而宣布无法创建该文件。当然，用户有权下一次使用比如 50MB 的数字再次启动编辑器，如此进行下去，直到找到一个合适的空洞为止。不过，这种方式看来不会使用户高兴。

然而，存在着一种情形，使得连续分配方案是可行的，而且，实际上这个方法在 CD-ROM 上被广泛使用。在这里所有文件的大小都事先直到，并且在 CD-ROM 文件系统的后续使用中，这些文件的大小也不再改变。

DVD 的情况有些复杂。原则上，一个 90 分钟的电影可以编码成一个独立的、大约 4.5GB 的文件。但是文件系统所使用的 **UDF**（Universal Disk Format）格式，使用了一个 30 位的数来代表文件长度，从而把文件大小限制在 1GB。其结果是，DVD 电影一般存储在 3 个或 4 个 1GB 的连续文件中。这些构成一个逻辑文件（电影）的物理文件块被称作 **extends**。

正如第 1 章中所提到的，在计算机科学中，随着新一代技术的出现，历史往往重复着自己。多年前，连续分配由于其简单和高性能（没有过多考虑用户友好性）被实际用在磁盘文件系统中。后来由于用户不希望再文件创建时必须指定最终文件的大小，于是放弃了这个相反。但是随着 CD-ROM、DVD、蓝光光盘以及其他一些一次性写光学介质的出现，突然间连续分配又成为一个好主意。所以研究那些具有清晰和简洁概念的老式系统和思想是很重要的，因为它们有可能以一种令人吃惊的方式在未来系统中获得应用。



**2.链表分配**

存储文件的第二种方法是为每个文件构造磁盘块链表，如图 4-11 所示。每个块的每一个字作为指向下一块的指针，块的其他部分存放数据。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE107.jpg"/>
</div>

与连续分配方案不同，这一方法可以充分利用每个磁盘块。不会因为磁盘碎片（除了最后一块中的内部碎片）而浪费存储空间。同样，在目录项中，只需要存放第一块的磁盘地址，文件的其它块就可以从这个首块地址查找到。

另一方面，在链表分配方案中，尽管顺序读文件非常方便，但是随机访问却相当缓慢。要获得块 n，操作系统每一次都必须从开开始，并且要先读前面的 n-1 块。显然，进行如此多的读操作太慢了。

而且，由于指针占去了一些字节，每个磁盘块存储数据的字节数不再是 2 的整数次幂。虽然这个问题并不是非常严重，但是怪异的大小确实降低了系统的运行效率，因为许多程序都是以长度为 2 的整数次幂来读写磁盘块的。由于每个块的前几个字节被指向下一个块的指针所占据，所以要读出完整的一个块的大小的信息，就需要从两个磁盘块中获得和拼接信息，这就因复制引发了额外的开销。



**3.采用内存中的表进行链表分配**

如果取出每个磁盘块的指针字，把它们放在内存中的一个表中，就可以解决上述链表的两个不足。图 4-12 表示了图 4-11 所示例子的内存中表的内容。这两个图中都有两个文件，文件 A 一次使用了磁盘块 4、7、2、10 和 12，文件 B 依次使用了磁盘块 6、3、11 和 14。利用图 4-12 中的表，可以从第 4 块开始，顺着链走到最后，找到文件 A 的全部磁盘块。同样，从第 6 块开始，顺序链走到最后，也能够找出文件 B 的全部磁盘块。这两个链都以一个不属于有效磁盘编号的特殊标记（如 -1）结束。内存中的这样一个表格称为**文件分配表**（File Allocation Table，FAT）。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE108.jpg"/>
</div>

按这类方式组合，整个块都可以存放数据。进而，随机访问也容易得多。虽然仍要顺着链在文件中查找给定的偏移量，但是整个链都存放在内存中，所以不需要任何磁盘引用。与前面的方法相同，不管文件有多大，在目录项中只需记录一个整数（起始块号），按照它就可以找到文件的全部块。

这种方法的主要缺点是必须把整个表都存放在内存中。对于 1TB 的磁盘和 1KB 大小的块，这张表需要有 10 亿项，每一项对应于这 10 亿个磁盘块中的一个块。每项至少 3 个字节，为了提高查找速度，有时需要 4 个字节。根据系统对空间或时间的优化方案，这张表要占用 3GB 或 2.4GB 内存。上述方法并不实用，FAT 的管理方法不能较好地扩展并应用于大型磁盘中。而这正是最初的 MS-DOS 文件系统，并仍被各个 Windows 版本所完全支持。



**4.i 节点**

最后一个记录各个文件分别包含哪些磁盘块的方法是给每个文件赋予一个称为 **i 节点**（index-node）的数据结构，其中列出了文件属性和文件块的磁盘地址。图 4-13 中是一个简单例子的描述。给定 i 节点，就能找到文件的所有块。相对于在内存中采用表的方式而言，这种机制具有很大的优势，即只有在对应文件打开时，其 i 节点才在内存中。如果每个 i 节点占有 n 个字节，最多 k 个文件同时打开，那么为了打开文件而保留 i 节点的数组所占据的全部内存仅仅是 kn 个字节，只需要提前保留这么多空间即可。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE109.jpg"/>
</div>

这个数组通常比上一节中叙述的文件分配表（FAT）所占据的空间要小。其原因很简单，保留所有磁盘块的链表的大小正比于磁盘自身的大小。如果磁盘有 n 块，该表需要 n 个表项。由于磁盘变得更大，该表格也随之线性增加。相反，i 节点机制需要在内存中有一个数组，其大小正比于可能要同时打开的最大文件个数。它与磁盘是 100GB、400GB 还是 10000GB 无关。

i 节点的一个问题是，如果每个 i 节点只能存储固定数量的磁盘地址，那么当一个文件所含的磁盘块的数目超出了 i 节点所能容纳的数目怎么办？一个解决方案是最后一个 ”磁盘地址“ 不指向数据块，而是指向一个包含额外磁盘块地址的块的地址，如图 4-13 所示。更高级的解决方案是：可以有两个或更多个包含磁盘地址的块，或者指向其他存放地址的磁盘块的磁盘块。在第 10 章讨论 UNIX 时，我们还将涉及 i 节点。同样，Windows 的 NTFS 文件系统采用了相似的方法，所不同的仅仅是大的 i 节点也可以表示小的文件。



##### 4.3.3	目录的实现

在读文件前，必须先打开文件。打开文件时，操作系统利用用户给出的路径名找到相应目录项。目录项中提供了查找文件磁盘块所需要的信息。因系统而异，这些信息有可能是整个文件的磁盘地址（对于连续分配方案）、第一个块的编号（对于两种链表分配方案）或者是 i 节点号。无论怎样，目录系统的主要功能是把 ASCII 文件名映射成定位文件数据所需的信息。

与此密切相关的问题是在何处存放文件属性。每个文件系统维护诸如文件所有者以及创建时间等文件属性，它们必须存储在某个地方。一种显然易见的方法是把文件属性直接存放在目录项中。很多系统确实是这样实现的。这个方法用图 4-14a 说明。在这个简单设计中，目录中有一个固定大小的目录项列表，每个文件对应一项，其中包含一个（固定长度）文件名、一个文件属性的结构体以及用以说明磁盘块位置的一个或多个磁盘地址（至某个最大值）。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE110.jpg"/>
</div>

对于采用 i 节点的系统，还存在另一种方法，即把文件属性存放在 i 节点中而不是目录项中。在这种情形下，目录项会更短：只有文件名和 i 节点号。这种方法参见图 4-14b。后面会看到，与把属性存放到目录项中相比，这种方法更好。

到目前为止，我们已经假设文件具有较短的、固定长度的名字。在 MS-DOS 中，文件有 1~8 个字符的基本名和 1~3 字符的可选扩展名。在 UNIX V7 中文件名有 1~14 个字符，包括任何扩展名。但是，几乎所有的现代操作系统都支持可变长度的长文件名。那么它们是如何实现的呢？

最简单的方法是给予文件名一个长度限制，典型值为 255 个字符，然后使用图 4-14 中的一种设计，并为每个文件名保留 255 个字符空间。这种处理很简单，但是浪费了大量的目录空间，因为只有很少的文件会有如此长的名字。从效率考虑，我们希望有其他的结构。

一种替代方案是放弃 ”所有目录项大小一样“ 的想法。这种方法中，每个目录项有一个固定部分，这个固定部分通常以目录项的长度开始，后面是固定格式的数据，通常包括所有者、创建时间、保护信息以及其他属性。这个固定长度的头的后面是一个任意长度的实际文件名，可能是如图 4-15a 中的正序格式放置（如 SPARC 机器）（注释：处理机中的一串字符存放的顺序有正序（big-endian）和逆序（little-endian）之分。正序存放就是高字节存放在前低字节在后，而逆序存放就是低字节在前高字节子在后。例如，十六进制数为 A02B，正序存放就是 A02B，逆序存放就是 2BA0）。在这个例子中，有三个文件，project-budget、personnel 和 foo。每个文件名以一个特殊字符（通常是 0）结束，在图 4-15 中用带叉的矩形表示。为了使每个目录项从字的边界开始，每个文件名被填充成整数个字，如图 4-15 中带阴影的矩形表示。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE111.jpg"/>
</div>

这个方法的缺点是，当移走文件后，就引入了一个长度可变的空隙，而下一个进来的文件不一定正好适合这个空隙。这个问题与我们已经看到的连续磁盘文件的问题是一样的，由于整个目录在内存中共，所以只有对目录进行紧凑操作才可节省空间。另一个问题是，一个目录项可能会分布在多个页面上，在读取文件名时可能发生缺页中断。

处理可变长度文件名字的另一种方法是，使目录项自身都有固定长度，而将文件名放置在目录后面的堆中，如图 4-15b 所示，这一方法的优点是，当一个文件目录项被移走后，另一个文件的目录项总是可以适合这个空隙。当然，必须要对堆进行管理，而在处理文件名时缺页中断仍旧会发生。另一个小优点是文件名不再需要从字的边界开始，这样，原先在图 4-15a 中需要的填充字符，在图 4-15b 中的文件名之后就不再需要了。

到目前为止，在需要查找文件名时，所有的方案都是线性地从头到尾对目录进行搜索。对于非常长的目录，线性查找就太慢了。加快查找速度的一个方法是在每个目录中使用散列表。设表的大小为 n。在输入文件名时，文件名被散列成 1 和 n-1 之间的一个值，例如，它被 n 除，并取余数。其他可以采用的方法有，对构成文件名的字求和，其结果被 n 除，或某些类似的方法。

添加一个文件时，不论哪种方法都要对与散列值相对应的散列表表项进行检查。如果该表项没有被使用，就将一个指向文件目录项的指针放入，文件目录项紧连在散列表后面。如果该表项被使用了，就构造一个链表，该链表的表头指针存放在该表项中，并链接所有具有相同散列值的文件目录项。（可以参考 C 程序设计语言 6.6）

查找文件按照相同的过程进行。散列处理文件名，以便选择一个散列表项。检查链表头在该位置上的链表的所有表项，查看要找的文件名是否存在。如果名字不在该链上，该文件就不在这个目录上。

使用散列表的优点是查找非常迅速。其缺点是需要复杂的管理。只有在预计系统中的目录经常会有成百上千个文件时，才把散列方案真正作为备用方案考虑。

一种完全不同的加快大型目录查找速度的方法是，将查找结果存入高速缓存。在开始查找之前，先查看文件名是否在告诉缓存中。如果是，该文件可以立即定位。当然，只有在查询目标集中在相对小范围的文件集合的时候，高速缓存的方案才有效果。



##### 4.3.4	共享文件

当几个用户同在一个项目里工作时，他们常常需要共享文件。其结果是，如果一个共享文件同时出现在属于不同用户的不同目录下，工作起来就很方便。图 4-16 再次给出图 4-7 所示的文件系统，只是 C 的一个文件现在也出现在 B 的目录下。B 的目录与该共享文件的联系称为一个**链接**（link）。这样，文件系统本身是一个**有向无环图**（Directed Acyclic Graph，DAG）而不是一棵树。将文件系统组织成有向无环图使得维护复杂化，但也是必须付出的代价。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE112.jpg"/>
</div>

共享文件是方便的，但也带来一些问题。如果目录中包含磁盘地址，则当链接文件时，必须把 C 目录中的磁盘地址复制到 B 目录中。如果 B 或 C 随后又往该文件中添加内容，则新的数据块将只列入进行添加工作的用户的目录中。其他的用户对此改变是不知道的。所以违背了共享的目的。

有两种方法可以解决这一问题。在第一种解决方案中，磁盘块不列入目录，而是列入一个与文件本身关联的小型数据结构中。目录将指向这个小型数据结构。这是 UNIX 系统中所采用的方法（小型数据结构即是 i 节点）。

在第二种解决方案中，通过让系统建立一个类型为 LINK 的新文件，并把该文件放在 B 的目录下，使得 B 与 C 的一个文件存在链接。新的文件中只包含了它所链接的文件的路径名。当 B 读该链接文件时，操作系统查看到要读的文件是 LINK 类型，则找到该文件所链接的文件的名字，并且去读那个文件。与传统（硬）链接相对比起来，这一方法称为**符号链接**（symbolic linking）。

以上每一种方法都有其缺点。第一种方法中，当 B 链接到共享文件时，i 节点记录文件的所有者是 C。建立一个链接并不改变所有关系（见图 4-17）但它将 i 节点的链接计数加 1，所以系统知道目前有多少目录项指向这个文件。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE113.jpg"/>
</div>

如果以后 C 试图删除这个文件，系统将面临问题。如果系统删除文件并清除 i 节点，B 则有一个目录指向一个无效的 i 节点，如果该 i 节点以后分配给另一个文件，则 B 的链接指向一个错误的文件。系统通过 i 节点中的计数可知该文件仍然被引用，到那时没有办法找到指向该文件的全部目录项以删除它们。指向目录的指针不能存储在 i 节点中，原因是有可能有无数个这样的目录。

唯一能做的就是只删除 C 的目录项，但是将 i 节点保留下来，并将计数置为 1，如图 4-17c 所示。而现在的状况是，只有 B 有指向该文件的目录项，而该文件的所有者是 C。如果系统进行记账或有配额，那么 C 将继续为该文件付账直到 B 决定删除它，如果真是这样，只有到计数变为 0 的时刻，才会删除该文件。

对于符号链接，以上问题不会发生，因为只有真正的文件所有者才有一个指向 i 节点的指针。链接到该文件上的用户只有路径名，没有指向 i 节点的指针。当文件所有者删除文件时，该文件被销毁。以后若试图通过符号链接访问该文件将导致失败，因为系统不能找到该文件。删除符号链接根本不影响该文件。

符号链接的问题是需要额外的开销。必须读取包含路径的文件，然后要一个部分一个部分地扫描路径，直到找到 i 节点。这些操作也许需要很多次额外的磁盘访问。此外，每个符号链接都需要额外的 i 节点，以及额外的一个磁盘块用于存储路径，虽然如果路径名很短，作为一种优化，系统可以将它存储在 i 节点中。符号链接有一个优势，即只要简单地提供一个机器的网络地址以及文件在该机器上驻留的路径，就可以链接全球任何地方的机器上的文件。

还有另一个由链接带来的问题，在符号链接和其他方式中都存在。如果允许链接，文件有两个或多个路径。查找一指定目录及其子目录下的全部文件的程序将多次定位到被链接的文件。例如，一个将某一目录及其子目录下的文件转储到磁带上的程序有可能多次复制一个被链接的文件。进而，如果接着把磁带读进另一台机器，除非转储程序具有智能，否则被链接的文件将被两次复制到磁盘上，而不是只是被链接起来。



##### 4.3.5	日志结构文件系统

不断进步的科技给现有的文件系统带来了更多的压力。特别是 CPU 的运行速度越来越快，磁盘容量越来越大，价格也越来越便宜（但是磁盘速度并没有增快多少），同时内存容量也已制数形式增长。而没有得到快速发展的参数是磁盘的寻道时间（除了固态盘，因为固态盘没有寻道时间）。所以这些问题综合起来，便成为影响很多文件系统性能的一个瓶颈。为此，Berkeley 设计了一种全新的文件系统，试图缓解这个问题，即**日志结构文件系统**（Log-structured File System，LFS）。在这一节里，我们简要描述 LFS 是如何工作的。

促使设计 LFS 的主要原因是：CPU 的运行速度越来越快，RAM 内存容量变得更大，同时磁盘高速缓存也迅速地增加。因此，现在可以直接从文件系统缓存中满足所有读取请求中的很大一部分，而无需访问磁盘。 从该观察结果可以看出，将来，大多数磁盘访问将是写入操作，因此某些文件系统的提前读机制（需要读取数据之前预取磁盘块）并不能获得很大的性能提升。

更为糟糕的情况是，在大多数文件系统中，写操作往往都是零碎的。一个 50us 的磁盘写操作之前通常需要 10ms 的寻道时间和 4ms 的旋转延迟时间，可见零碎的磁盘写操作是极其没有效率的。根据这些参数，磁盘的利用率降低到 1% 以下。

为了看看这样小的零碎写操作从何而来，考虑在 UNIX 文件系统上创建一个新文件。为了写这个文件，必须写该文件目录的 i 节点、目录块、文件的 i 节点以及文件本身。而这些写操作都有可能被延迟，那么如果在写操作完成之前发生死机，就可能在文件系统中造成严重的不一致性。正因为如此，i 节点的写操作一般是立即完成的。

出与这一原因，LFS 的设计者决定重新实现一种 UNIX 文件系统，该系统即使面对一个大部分由零碎的随机写操作组成的任务，同样能够充分利用磁盘的带宽。其基本思想是将整个磁盘结构化为一个日志。每隔一段时间，或是有特殊需求时，被缓冲在内存中的所有即将发生的写操作都被收集到一个单独的段中，并在日志末尾作为单个连续段写入磁盘。这个单独的段可能会包括 i 节点、目录块、数据块或者都有。每一个段的开始都是该段的摘要，说明该段中都包含哪些内容。如果所有的段平均在 1MB 左右，那么就几乎可以利用磁盘的完整带宽。

在 LFS 的设计中，同样存在着 i 节点，且具有与 UNIX 中一样的结构，但是 i 节点分散在整个日志中，而不是放在磁盘的某一个固定位置。尽管如此，当一个 i 节点被定位后，定位一个块就用通常的方式来完成。当然，由于这种设计，要在磁盘中找到一个 i 节点就变得比较困难了，因为 i 节点的地址不能像在 UNIX 中那样简单地通过计算得到。为了能够找到 i 节点，必须要维护一个由 i 节点编号索引组成的 i 节点图。在这个图中的表项 i 指向磁盘中的第 i 个 i 节点。这个图保存在磁盘上，但是也保存在高速缓存中，因此，大多数情况下这个图的最常用部分还是在内存中。

总而言之，所有的写操作最初都被缓冲在内存中，然后周期性地把所有已缓冲的写操作作为一个单独的段，在日志的末尾处写入磁盘。要打开一个文件，则首先需要从 i 节点图中找到文件的 i 节点。一旦 i 节点定位之后就可以找到相应的块的地址。所有的块都放在段中，在日志的某个位置上。

如果磁盘空间无限大，那么有了前面的讨论就足够了但是，实际的硬盘空间是有限的，这样最终日志将会占用整个磁盘，到那个时候将不能往日志中写任何新的段。幸运的是，许多已有的段包含了很多不再需要的块，例如，如果一个文件被覆盖了，那么它的 i 节点就会指向新的块，但是旧的磁盘块仍然在先前写入的段中占据着空间。

为了解决这个问题，LFS 有一个**清理**线程，该清理线程周期性地扫描日志进行磁盘压缩。该线程首先读日志中的第一个段的摘要，检查有哪些 i 节点和文件。然后该线程查看当前 i 节点图，判断该 i 节点是否有效以及文件块是否仍在使用中。如果没有使用，则该信息被丢弃。如果仍然使用，那么 i 节点和块就进入内存等待写回到下一个段中。接着，原来的段被标记为空闲，以便日志可以用它来存放新的数据。用这种方法，清理线程遍历日志，从后面移走旧的段，然后将有效的数据放入内存等待写到下一个段中。由此，整个磁盘成为一个大的环形的循环缓冲区，写线程将新的段写到前面，而清理线程则将旧的段从后面移走。

日志的管理并不简单，因为当一个文件块被写回到一个新段的时候，该文件的 i 节点（在日志的某个地方）必须首先要定位、更新，然后放到内存中准备写回到下一个段中。i 节点图接着必须更新以指向新的位置。尽管如此，对日志进行管理还是可行的，而且性能分析的结果表明，这种由管理而带来的复杂性是值得的。在上面所引用文章中的测试数据表明，LFS 在处理大量的零碎的写操作时性能上比 UNIX 好上一个数量级，而在读和大块写操作的性能方面并不比 UNIX 文件系统差，甚至更好。



##### 4.3.6	日志文件系统

虽然基于日志结构的文件系统是一个很吸引人的想法，但是由于它们和现有的文件系统不相匹配，所以还没有被广泛应用。尽管如此，它们内在的一个思想，即面对出错的鲁棒性，却可以被其他文件系统所借鉴。这里的基本想法是保存一个用于记录系统下一步将要做什么的日志。这样当系统在完成它们即将完成的任务崩溃时，重新启动后，可以通过查看之日，获取崩溃前计划完成的任务，并完成它们。这样的文件系统称为**日志文件系统**，并已经被实际应用。微软的 NTFS 文件系统、Linux ext3 和 ReiserFS 文件系统都使用日志。OS X 将日志文件系统作为可选项提供。接下来，我们会对这一主题进行简短介绍。

为了看清这个问题的实质，考虑一个简单、普遍并经常发生的操作：移除文件。这个操作（在 UNIX 中）需要三个步骤完成：

1）在目录中删除文件；

2）释放 i 节点到空闲 i 节点池；

3）将所有磁盘块归还空闲磁盘块池。

在 Windows 中，也需要类似的步骤。不存在系统崩溃时，这些步骤执行的顺序不会带来问题；但是当存在系统崩溃时，就会带来问题。假如在第一步完成后系统崩溃。i 节点和文件块将不会被任何文件获得，也不会被再分配；它们只存在于废物池中的某个地方，并因此减少了可利用的资源。如果崩溃发生在第二步后，那么只有磁盘块会丢失。

如果操作顺序被更改，并且 i 节点最先被释放，这样在系统重启后，i 节点可以被再分配，但是旧的目录入口将继续指向它，因此指向错误文件。如果磁盘块最先被释放，这样一个在 i 节点被清除前的系统崩溃将意味着一个有效的目录入口指向一个 i 节点，它所列出的磁盘块当前存在于空闲块存储池中并可能很快被再利用。这将导致两个或更多的文件分享同样的磁盘块。这样的结果都是不好的。

日志文件系统则先写一个日志项，列出三个将要完成的动作。然后日志项被写入磁盘（并且为了良好地实施，可能从磁盘读回来验证它的完整性）。只有当日志项已经被写入，不同的操作才可以进行。当所有的操作成功完成后，擦除日志项。如果系统这时崩溃，系统恢复后，文件系统可以通过检查日志来查看是不是有未完成的操作。如果有，可以重新运行所有未完成的操作（这个过程在系统崩溃重复发生时执行多次），直到文件被准确地删除。

为了让日志文件系统工作，被写入日志的操作必须是**幂等的**（对同一个系统，使用同样的条件，一次请求和重复的多次请求对系统资源的影响是一致的。），它意味着只要有必要，它们就可以重复执行很多次，并不会带来破坏。像操作 “更新位表并标记 i 节点 k 或者块 n 是空闲的” 可以重复任意次。同样地，查找一个目录并且删除所有叫 foobar 的项也是幂等的。相反，把从 i 节点 k 新释放的块加入空闲表的末端不是幂等的，因为它们可能已经被释放并存放在那里了。更复杂的操作如 “查找空闲块列表并且如果块 n 不在列表就将块 n 加入” 是幂等的。日志文件系统必须安排它们的数据结构和可写入日志的操作以使它们都是幂等的。在这些条件下，崩溃恢复可以被快速安全地实施。

为了增加可靠性，一个文件系统可以引入数据库中**原子事务**（atomic transaction）的概念。使用这个概念，一组动作可以被界定在开始事务和结束事务操作之间。这样，文件系统就会知道它或者必须完成所有被界定的操作，或者什么也不做，而没有其他选择。

NTFS 有一个扩展的日志文件系统，并且它的结构几乎不会因系统崩溃而受到破坏。自 1993 年 NTFS 第一次随 Windows NT 一起发行以后就在不断地发展。Linux 上有日志功能的第一个文件系统是 ReiserFS，但是因为它和后来标准化的 ext2 文件系统不相匹配，它的推广受到阻碍。相比之下，ext3——一个不像 ReiserFS 那么有野心的工程，也具有日志文件功能并且和之前的 ext2 系统可以共存。



##### 4.3.7	虚拟文件系统

即使在同一台计算机上或在同一个操作系统下，都会使用很多不同的文件系统。Windows 有一个主要的 NTFS 文件系统，但是也有一个包含老的但仍然使用的 FAT-32 或者 FAT-16 驱动器或分区，并且不时地需要一个CD-ROM 或者 DVD（第一个包含特定的文件系统）。Windows 通过指定不同的盘符来处理这些不同的文件系统，比如 "C:" "D:" 等。当一个进程打开一个文件，盘符是显式或者隐式存在的，所以 Windows 知道向哪个文件系统传递请求，不需要尝试将不同类型文件系统整合成为统一的模式。

相比之下，所有现代的 UNIX 系统做了一个很认真地尝试，即将多种文件系统整合到一个统一的结构中。一个 Linux 系统可以用 ext2 作为根文件系统，ext3 分区装载在 /usr 下，另一块采用 ReiserFS 文件系统的硬盘装载在 /home 下，以及一个 ISO 9660 的 CD-ROM 临时装载在 /mnt 下。从用户的观点来看，只有一个文件系统层级。它们事实上是多种（不相容的）文件系统，对于用户和进程是不可见的。

但是，多种文件系统的存在，在实际应用中是明确可见的，而且因为以前 Sun 公司所做的工作，绝大多数 UNIX 操作系统都使用**虚拟文件系统**（Virtual File System，VFS）概念尝试将多种文件系统统一成一个有序的结构。关键的思想就是抽象出所有文件系统都共有的部分，并且将这部分代码放在单独的一层，该层调用底层的实际文件系统来具体管理数据。大体上的结构在图 4-18 中有阐述。以下的介绍不是单独针对 Linux 和 FreeBSD 或者其他版本的 UNIX，而是给出了一种普遍的关于 UNIX 下文件系统的描述。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE114.jpg"/>
</div>

所有和文件相关的系统调用在最初的处理上都指向虚拟文件系统。这些来自用户进程的调用，都是标准的 POSIX 系统调用，比如 open、read、write 和 seek 等。因此，VFS 对用户进程有一个 “上层” 接口，它就是著名的 POSIX 接口。

VFS 也有一个对于实际文件系统的 “下层” 接口，就是在图 4-18 中被标记为 **VFS 接口**的部分。该接口包含数十个函数调用，VFS 可以对每个文件系统进行该函数调用以完成工作。因此，当创造一个新的文件系统和 VFS 一起工作时，新文件系统的设计者就必须确定它提供 VFS 所需要的功能调用。关于这个功能的一个明显的例子就是从磁盘上读某个特定的块，把它放在文件系统的高速缓冲中，并且返回指向它的指针，因此，VFS 有两个不同的结构：上层给用户进程的接口和下层给实际文件系统的接口。

尽管 VFS 下大多数的文件系统体现了本地磁盘的划分，但并不总是这样。事实上，Sun 建立虚拟文件系统最原始的动机是支持使用 **NFS**（Network File System，网络文件系统）协议的远程文件系统。VFS 设计是只要实际的文件系统提供 VFS 需要的功能，VFS 就不需知道或者关心数据具体存储在什么地方或者底层的文件系统是什么样的。

大多数 VFS 应用本质上都是面向对象的，即便它们用 C 语言而不是 C++ 编写。有几种通常支持的主要的对象类型，包括超块（描述文件系统）、v 节点（描述文件）和目录（描述文件系统目录）。这些中的每一个都有实际文件系统必须支持的相关操作。另外，VFS 有一些供它自己使用的内部数据结构，包括用于跟踪用户进程中所有打开文件的装载表和文件描述符的数组。

为了理解 VFS 是如何工作的，让我们按时间的先后运行一个实例。当系统启动时，根文件系统在 VFS 中注册。另外，当装载其他文件系统时，不管在启动时还是在操作过程中，它们也必须在 VFS 中注册。当一个文件系统注册时，它做的最基本的工作就是提供一个包含 VFS 所需要的函数地址的列表，可以是一个长的调用矢量（表），或者是许多这样的矢量（如果 VFS 需要），每个 VFS 对象一个。因此，只要一个文件系统在 VFS 注册，VFS 就知道如何从它那里读一个块——它从文件系统提供的矢量中直接调用第 4 个（或者任何一个）功能。同样地，VFS 也知道如何执行实际文件系统提供的每一个其他的功能：它只需调用某个功能，该功能所在的地址在文件系统注册时就提供了。

装载文件系统后就可以使用它了。比如，如果一个文件系统装载在 /usr 并且一个进程调用它：

open("/usr/include/unistd.h", O_RDONLY)

当解析路径时，VFS 看到新的文件系统被装载在 /usr，并且通过搜索已经装载文件系统的超块表来确定它的超块。做完这些，它可以找到它所装载的文件的根目录，在那里查找路径 include/unistd.h。然后 VFS 创建一个 v 节点并调用实际文件系统，以返回所有的在文件 i 节点中的信息。这个信息和其他信息一起复制到 v 节点中（在 RAM 中），而这些所谓其他信息中最重要的是指向包含调用 v 节点操作的函数表的指针，比如 read、write 和 close 等。

当 v 节点被创建以后，为了进程调用，VFS 在文件描述符表中创建一个表项，并且将它指向新的 v 节点（为了简单，文件描述符实际上指向另一个包含当前文件位置和指向 v 节点的指针的数据结构，但是这个细节对于我们这里的陈述并不重要）。 最后，VFS 向调用者返回文件描述符，所以调用者可以用它去读、写或者关闭文件。

随后，当进程用文件描述符进行一个读操作，VFS 通过进程表和文件描述符表确定 v 节点的位置，并跟随指针指向函数表（所有这些都是被请求文件所在的实际文件系统中的地址）。这样就调用了处理 read 的函数，运行在实际文件系统中的代码并得到所请求的块。VFS 并不知道数据是来源于本地硬盘，还是来源于网络中的远程文件系统、CD-ROM、USB 存储棒或者其他介质。所有有关的数据结构在图 4-19 中展示。从调用者进程号和文件描述符开始，进而是 v 节点，读函数指针，然后是对实际文件系统的访问函数定位。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE115.jpg"/>
</div>

通过这种方法，加入新的文件系统变得相当直接。为了加入一个文件系统，设计者首先获得一个 VFS 期待的功能调用的列表，然后编写文件系统实现这些功能。或者，如果文件系统已经存在，它们必须提供 VFS 需要的包装功能，通常通过建造一个或者多个内在的指向实际文件系统的调用来实现。



#### 4.4	文件系统管理和优化

要使文件系统工作是一件事，使真实世界中的文件系统有效、鲁棒地工作是另一回事。本节中，我们将考察有关管理磁盘的一些问题。

##### 4.4.1	磁盘空间管理

文件通常存放在磁盘上，所以对磁盘空间的管理是系统设计者要考虑地一个主要问题。存储一个有 n 个字节的文件可以有两种策略：分配 n 个字节的连续磁盘空间，或者把文件分成很多个连续（或并不一定连续）的块。在存储管理系统中，分段处理和分页处理之间也要进行同样的权衡。

正如我们已经见到的，按连续字节序列存储文件有一个明显问题，当文件扩大时，有可能需要在磁盘上移动文件。内存中分段也有同样的问题。不同的是，相对于把文件从磁盘的一个位置移动到另一个位置，内存中段的移动操作要快得多。因此，几乎所有的文件系统都把文件分割成固定大小的块来存储，各块之间不一定相邻。

**1.块大小**

一旦决定把文件按固定大小的块来存储，就会出现一个问题：块的大小应该是多少？按照磁盘组织方式，扇区、磁道和柱面显然都可以作为分配单位（虽然它们都与设备相关，这是一种负面因素）。在分页系统中，页面大小也是主要讨论的问题之一。

拥有大的块尺寸意味着每个文件，甚至一个 1 字节的文件，都要占用一整个柱面，也就是说小的文件浪费了大量的磁盘空间。另一方面，小的块尺寸意味着大多数文件会跨越多个块，因此需要多次寻道与旋转延迟才能读出它们，从而降低了性能。因此，如果分配的单元太大，则浪费了空间；如果太小，则浪费时间。

根据某个论文（2006）统计：如果块大小是 1KB，则只有 30%~50% 的文件能够放在一个块内，如果块大小是 4KB，这一比例将上升到 60%~70%。那篇论文中的其他数据显示，如果块大小是 4KB，则 93% 的磁盘块会被 10% 最大的文件使用。这意味着在每个小文件末尾浪费一些空间几乎不会有任何关系，因为磁盘被少量的大文件（视频）给占用了，并且小文件所占空间的总量根本就无关紧要，甚至将那 90% 最小的文件所占的空间翻一倍亦不会引人注目。

另一方面，分配的那位很小意味着每个文件由很多块组成，每读一块都有寻道和旋转延迟时间，所以，读取由很多小块组成的文件会非常慢。

图 4-21 的虚线表示一个磁盘的数据率与块大小之间的函数关系。要计算空间利用率，则要对文件的平均大小做出假设。为简单起见，假设所有文件都是 4KB。尽管这个数据稍微大于论文统计的数据，但是学生们大概应该有比公司数据中心更多的小文件，所以这样整体上也许更好些。图 4-21 中的实线表示作为盘块大小函数的空间利用率。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE116.jpg"/>
</div>

可以按下面的方式理解这两条曲线。对一个块的访问时间完全由寻道时间和旋转延迟所决定，所以若要花费 9ms 的代价访问一个盘块，那么取的数据越多越好。因此，数据率随着磁盘块的增大而线性增大（直到传输花费很长的时间以至于传输时间成为主导因素）。

现在考虑空间利用率。对于 4KB 文件和 1KB、2KB 或 4KB 的磁盘块，这个文件分别使用 4、、2、1 块的文件，没有浪费。对于 8KB 块以及 4kB 文件，空间利用率降至 50%，而 16KB 块则降至 25%。实际实，很少有文件的大小是磁盘块整数倍的，所以一个文件的最后一个磁盘块中总是有一些空间浪费。

然而，这些曲线显示出性能与空间利用率天生就是矛盾的。小的块会导致低的性能但是搞得空间利用率。对于这些数据，不存在合理的折中方案。在两条曲线的相交处的大小大约是 64KB，但是数据（传输）速率只有 6.6MB/s 并且空间利用率只有大约 7%，两者都不是很好。从历史观点上来说，文件系统将大小设在 1~4KB 之间，但现在随着磁盘超过了 1TB，还是将块的大小提升到 64KB 并且接收浪费的磁盘空间，这样也许更好。磁盘空间几乎不会再短缺了。



**2.记录空闲块**

一旦选定了块大小，下一个问题就是怎样跟踪空闲块。有两种方法被广泛采用，如图 4-22 所示。第一种方法是使用磁盘块的链表，链表的每个块中将容纳尽可能多的空闲磁盘块号。对于 1KB 大小的块和 32 位的磁盘块号，空闲表中每个块包含有 255 个空闲块的块号（32位 = 4字节，1KB = 1024字节，1024/4 = 256，需要有一个位置存放指向下一个块的指针）。考虑一个 1TB 的磁盘，拥有 10 亿个磁盘块。为了存储全部地址块号，如果每块可以保存 255 个块号，则需要 400 万块（4000000/1024/1024=3.81G）。通常情况下，采用空闲块存放空闲表，这样不会影响存储器。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE117.jpg"/>
</div>

另一种空闲磁盘空间管理的方法是采用位图。n 个块的磁盘需要 n 位位图。在位图中，空闲块用 1 表示，已分配块 0 表示（或者反之）。对于 1TB 磁盘的例子，需要 10 亿位表示，即需要大约 130 000 个 1KB 块存储（0.124G）。只有在磁盘快满时（即几乎没有空闲块时）链表方案需要的块才比位图少。

如果空闲块趋向于成为一个长的连续分块的话，则空闲列表系统可以改成记录连续分块而不是单个的块。一个 8、16、32 位的计数可以与每一个块相关联，来记录连续空闲块的数目。在最好的情况下，一个基本上空的磁盘可以用两个数表达：第一个空闲块的地址，以及空闲块的计数。另一方面，如果磁盘产生了很严重的碎片，记录连续分块会比记录单独的块效率要低，因为不仅要存储地址，而且还要存储计数。

这个情形说明了操作系统设计者经常遇到的一个问题。有许多数据结构与算法可以用来解决一个问题，但选择其中最好的则需要数据，而这些数据是设计者无法预先拥有的。

现在回到空闲表方法，只需要在内存中保存一个指针块。当文件创建时，所需要的块从该指针块中取出。现有的指针块用完时，从磁盘中读入一个新的指针块。类似地，当删除文件时，其磁盘块被释放，并添加到内存的指针块中。当这个块填满时，就把它写入磁盘。

在某些特定情形下，这个方法产生了不必要的磁盘 I/O。考虑图 4-23a 中的情形，内存中共的指针块只有两个表项了。如果释放了一个有三个磁盘块的文件，该指针块就溢出了，必须将其写入磁盘，这就产生了图 4-23b 的情形。如果现在写入含有三个块的文件，满的指针块不得不再次读入，这将回到图 4-23a 的情形。如果有三个块的文件只是作为临时文件被写入，当它被释放时，就需要另一个磁盘写操作，以便把满的指针块写回磁盘。总之，当指针块几乎为空时，一系列短期的临时文件就会引起大量的磁盘 I/O。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE118.jpg"/>
</div>

一个可以避免过多磁盘 I/O 的替代策略是，拆分满了的指针块。这样，当释放三个块时，不再是从图 4-23a 变化到图 4-23b，而是从图 4-23a 变化到图 4-23c。现在，系统可以处理一系列临时文件，而不需进行任何磁盘 I/O。如果内存中指针块满了，就写入磁盘，半满的指针块从磁盘中读入。这里的思想是：保持磁盘上的大多数指针块为满的状态（减少磁盘的使用），但是在内存中保留了一个半满的指针块。这样，它可以即处理文件的创建又同时处理文件的删除操作，而不会为空闲表进行磁盘 I/O。

对于位图，在内存中只保留一个块是有可能的，只有在该块满了或空了的情形下，才到磁盘上取另一块。这样处理的附加好处是，通过在位图的单一块上进行所有的分配操作，磁盘块会较为紧密地聚集在一起，从而减少了磁盘臂地移动。由于位图是一种固定大小的数据结构，所以如果内核是（部分）分页的，就可以把位图放在虚拟内存内，在需要时将位图的页面调入。



**3.磁盘配额**

为了防止人们贪心而占有太多的磁盘空间，多用户操作系统常常提供一种强制性磁盘配额机制。其思想是系统管理员分给每个用户拥有文件和块的最大数量，操作系统确保每个用户不超过分给他们的配额。下面将介绍一种典型的机制。

当用户打开一个文件时，系统找到文件属性和磁盘地址，并把它们送入内存中的打开文件表。其中一个属性告诉文件所有者是谁。任何有关该文件大小的增长都记到所有者的配额上，以防止一个用户垄断所有 i 节点。

第二张表包含了每个用户当前打开文件的配额记录，即使是其他人打开该文件也一样。这张表如图 4-24 所示，该表的内容是从被打开文件的所有者的磁盘配额文件中提取出来的。当所有文件关闭时，该记录被写回配额文件。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE119.jpg"/>
</div>

当在打开文件表中建立一新表项时，会产生一个指向所有者配额记录的指针，以便很容易找到不同的限制。每一次往文件中添加一块时，文件所有者所用数据块的总数也增加，引发对配额硬限制和软限制检查。可以超出软限制，但硬限制不可以超出。当已达到硬限制时，再往文件中添加内容将引发错误。同时，对文件数目也存在着类似的检查。

当用户试图登录时，系统检查配额文件，查看该用户文件数目或磁盘块数目是否超过软限制。如果超过了任一限制，则显示一个警告，保存的警告计数减 1。如果该计数已为 0，表示用户多次忽略该警告，因而将不允许该用户登录。要想再得到登陆的许可，就必须与系统管理员协商。

这一方法具有这样的性质，即只要用户在退出系统前消除索超过的部分，他们就可以在一次中断会话期间超过其软限制，但无论什么情况下都不能超过硬限制。



##### 4.4.2	文件系统备份

略



##### 4.4.3	文件系统的一致性

略



##### 4.4.4	文件系统性能

访问磁盘比访问内存慢得多。读内存中一个 32 位字大概要 10ns。从磁盘上读的速度大约为 100MB/s，对每 32 位字来说，大约要慢 4 倍，还要加上 5~10ms 寻道时间，并等待所需的扇面抵达磁头下。如果只需要一个字，内存访问则比磁盘访问快百万数量级。考虑到访问时间的这个差异，许多文件系统采用了各种优化措施以改善性能。本节我们将介绍其中三种方法。

**1.高速缓存**

最常用的减少磁盘访问次数技术是**块高速缓存**（block cache）或者**缓冲区高速缓存**（buffer cache）。在本书中，高速缓存指的是一系列的块，它们在逻辑上属于磁盘，但实际上基于性能的考虑被保存在内存中。

管理高速缓存有不同的算法，常用的算法是：检查全部的读请求，查看在高速缓冲中是否有所需要的块。如果存在，可执行读操作而无须访问磁盘。如果该块不在高速缓存中，首先要把它读到高速缓存，再复制到所需地方。之后，对同一个块的请求都通过高速缓存完成。

高速缓存的操作如图 4-28 所示。由于在高速缓存中有许多块（通常有上千块），所以需要有某种方法快速确定所需要的块是否存在。常用方法是将设备和磁盘地址进行散列操作，然后，在散列表中查找结果。具有相同散列值的块在一个链表中连接在一起，这样就可以沿着冲突链查找其他块。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE120.jpg"/>
</div>

如果高速缓存已满，此时需要调入新的块，则要把原来的某一块调出高速缓存（如果要调出的块在上次调入以后修改过，则要把它写回磁盘）。这种情况与分页非常相似，所有常用的页面置换算法在第 3 张章中已经介绍，例如 FIFO 算法、第二次机会算法、LRU 算法等，它们都适用于高速缓存。与分页相比，高速缓存的好处在于对高速缓存的引用不很频繁，所以按精确的 LRU 顺序在链表中记录全部的块是可行的。

在图 4-28 中可以看到，除了散列表中的冲突链之外，还有一个双向链表把所有的块按照使用时间的先后次序链接起来，近来使用最少的块在该链表的前端，而近来使用最多的块在该链表的后端。当引用某个块时，该块可以从双向链表中移走，并放置到该表的尾部去。用这种方法，可以维护一种准确的 LRU 顺序。

但是，这又带来了意想不到的难题。现在存在一种情形，使我们有可能获得精确的 LRU，但是碰巧该 LRU 却又不符合要求。这个问题与前一节讨论的系统崩溃和文件一致性有关。如果一个关键块（比如 i 节点块）读进了高速缓存并做过修改，但是没有写回磁盘，这时，系统崩溃会导致文件系统的不一致。如果把 i 节点块放在 LRU 链的尾部，在它到达链首并写回磁盘前，有可能需要相当长的一段时间。

此外，某一些块，如 i 节点块，极少可能在短时间内被引用两次。基于这些考虑需要修改 LRU 方案，并应注意如下两点：

1）这一块是否不久后会再次使用？

2）这一块是否与文件系统一致性有本质的联系？

考虑以上两个问题时，可将块分为 i 节点块、间接块、目录块、满数据块、部分数据块等几类。把有可能最近不再需要的块放在 LRU 链表的前部，而不是 LRU 链表的后端，于是它们所占用的缓冲区可以很快被重用。对很快就可能再次使用的块，比如正在写入的部分满数据块，可放在链表的尾部，这样它们能在高速缓存中保存较长的一段时间。

第二个问题独立于前一个问题。如果关系到文件系统一致性（除数据块之外，其他块基本上都是这样）的某块被修改，都应立即将该块写回磁盘，不管它是否被放在 LRU 链表尾部。将关键块快速写回磁盘，将大大减少在计算机崩溃后文件系统被破坏的可能性。用户的文件崩溃了，该用户会不高兴，但是如果整个文件系统都丢失了，那么这个用户会更生气。

尽管用这类方法可以保证文件系统一致性不受到破坏，但我们仍然不希望数据块在高速缓存中放很久之后才写入磁盘。设想某人正在用个人计算机编写一本书。尽管作者让编辑程序将正在编辑的文件定期写回磁盘，所有的内容只存在高速缓存中而不在磁盘上的可能性仍然非常大。如果这时系统崩溃，文件系统的结构并不会被破坏，但他一整天的工作就会丢失。

即使只发生几次这类情况，也会让人感到不愉快。系统采用两种方法解决这一问题。在 UNIX 系统中有一个系统调用 sync，它强制性地把全部修改过的块立即写回磁盘。系统启动时，在后台运行一个通常名为 update 的程序，它在无限循环中不断执行 sync 调用，每两次调用之间休眠 30s。于是，系统即使崩溃，也不会丢失超过 30 秒的工作。

虽然目前 Windows 有一个等价于 sync 的系统调用——FlushFileBuffers，不过过去没有。取而代之的是，windows 采用一个在某种程度上比 UNIX 方式更好（某种程度更坏）的策略。其做法是，只要被写入高速缓存，就把每个被修改的块写回磁盘。将高速缓存中所有被修改的块立即写回磁盘称为**通写高速缓存**（write-through cache）。与非通写高速缓存相比，通写高速缓存需要更多的磁盘 I/O。

若某程序要写满 1KB 的块，每次写一个字符，这时可以看到这两种方法的区别。UNIX 在高速缓存中保存全部字符，并且每 30 秒把该块写回磁盘一次，或者当从高速缓存删除这一块时，将该块写回磁盘。在通写高速缓存里，每写入一字符就要访问一次磁盘。当然，多数程序有内部缓冲，通常情况下，在每次执行 write 系统调用时并不是只写入一个字符，而是写入一行或更大的单位。

 采用者两种不同的高速缓冲策略的结果是：在 UNIX 系统中，若不调用 sync 就移动磁盘，往往会导致数据丢失，在被毁坏的文件系统中也经常如此。而在通写高速缓存中，就不会出现这类情况。选择不同策略的原因是，在 UNIX 开发环境中，全部磁盘都是硬盘，不可移动。而第一代 Windows 文件源自 MS-DOS，是从软盘世界中发展起来的。由于 UNIX 方案有更高的效率它成为当然的选择（但可靠性更差），随着硬盘成为标准，它目前也用在 Windows 的磁盘上。但是，NTFS 使用其他方法（日志）改善其可靠性，这在前面已经讨论过。

一些操作系统将高速缓存与页缓存集成，这种方式在支持内存映射文件的时候特别吸引人。如果一个文件被映射到内存上，则它其中的一些页就会在内存中，因为它们被要求按页进入。这些页面与在高速缓存中的文件块几乎没有不同。在这种情况下，它们能被以同样的方式来对待，也就是说，用一个缓存来同时存储文件块与页。

**3.块提前读**

第二个明显提高文件系统性能的技术是：在需要用到块之前，试图提前将其写入高速缓存，从而提高命中率。特别地，许多文件都是顺序读的。如果请求文件系统在某个文件中生成块 k，文件系统执行相关操作且在完成之后，会在用户不察觉的情形下检查高速缓存，以便确定块 k+1 是否已经在高速缓存。如果还不在，文件系统会为块 k+1 安排一个预读，因为文件系统希望在需要用到该块时，它已经在高速缓存或者至少马上就要在高速缓存中了。

当然，块提前读策略只适用于实际顺序读取的文件。对随机访问文件，提前读丝毫不起作用。相反，它还会帮倒忙，因为读取无用的块以及从高速缓存中删除潜在有用的块将会占用固定的磁盘带宽（如果有 “脏” 块的话，还需要将它们写回磁盘，这就占用了更多的磁盘带宽）。那么提前读策略是否值得采用呢？文件系统通过跟踪每一个打开文件的访问方式来确定这一点。例如，可以使用与文件相关联的某个位协助跟踪该文件到底是 “顺序访问方法” 还是 “随机访问方式”。在最初不能确定文件属于哪种存取方式时，先将该位设置成顺序访问方法。但是，查找一完成，就将该位取出。如果再次发生顺序读取，就再次设置该位。这样，文件系统可以通过合理的猜测，确定是否应该采取提前读的策略。即便弄错了一次也不会产生严重后果，不过是浪费一小段磁盘的带宽罢了。

**3.减少磁盘臂运动**

高速缓存和块提前读并不是提高文件系统性能的唯一方法。另一种重要技术是把有可能顺序访问的块放在一起，当然最好是在同一个柱面上，从而减少磁盘臂的移动次数。当写一个输出文件时，文件系统就必须按照要求一次一次地分配磁盘块。如果用位图来记录空闲块，并且整个位图在内存中，那么选择与前一块最近的空闲块是很容易的。如果用空闲块，并且链表的一部分存在磁盘上，要分配紧邻着的空闲块就困难得多。

不过，即便采用空闲表，也可以采用块簇技术。这里用到一个小技巧，既不用块而用连续块簇来跟踪磁盘存储区。如果一个扇区有 512 个字节，有可能系统采用 1KB 得块（2 个扇区），但却按每 2 块（4 个扇区）一个单位来分配磁盘存储区。这和 2KB 的磁盘块并不相同，因为在高速缓存中它仍然使用 1KB 的块，磁盘与内存数据之间传送也是以 1KB 为单位进行，但在一个空闲的系统上顺序读取文件，寻道的次数可以减少一半，从而使文件系统的性能大大改善。若考虑旋转定位则可以得到这类方案的变体。在分配块时，系统尽量把一个文件中的连续块存放在同一柱面上。

在使用 i 节点或任何类似 i 节点的系统中，另一个性能瓶颈是，读取一个很短的文件也需要两次磁盘访问：一次是访问 i 节点，另一次是访问块。通常情况下，i 节点的位置如图 4-29a 所示。其中，全部 i 节点都放在靠近磁盘开始位置，所以 i 节点和它指向的块之间的平均距离是柱面数的一半，这将需要较长的寻道时间。

<div align=center>
	<img src="https://raw.githubusercontent.com/BufferedStream/cs-learning-notes/master/notes/images/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E5%9B%BE121.jpg"/>
</div>

一个简单的改进方法是，在磁盘中部而不是开始处存放 i 节点，此时，在 i 节点和第一块之间的平均寻道实际减为原来的一半。另一种做法是：将磁盘分成多个柱面组，每个柱面组有自己的 i 节点、数据块和空闲表，见图 4-29b。在文件创建时，可选取任一 i 节点，但选定之后，首先在该 i 节点所在的柱面组上查找块。如果在该柱面组中没有空闲的块，就选用与之相邻的柱面组的一个块。

当然，仅当磁盘中装有磁盘臂的时候，讨论寻道时间和旋转时间才是有意义的。越来越多的点啊弄开始装配不带移动部件的**固态硬盘**（SSD）。对于这些硬盘，由于采用了和闪存同样的制造技术，使得随机访问与顺序访问在传输速度上已经较为接近，传统硬盘的许多问题就消失了。不幸的是，新的问题又随之出现。

例如，固态硬盘在读取、写入和删除时表现出一些特性，尤其是每一块只可写入有限次数的特征，导致使用时需要十分小心以达到均匀分散磨损的目的。



##### 4.4.5	磁盘碎片整理

在初始安装操作系统后，从磁盘的开始位置，一个接一个地连续安装了程序与文件。所有的空闲磁盘空间放在一个单独的、与被安装的文件邻近的单元里。但随着时间的流逝，文件被不断地创建与删除，于是磁盘会产生很多碎片，文件与空穴到处都是。结果是，当创建一个新文件时，它使用的块会散布在整个磁盘上，造成性能的降低。

磁盘性能可以通过如下方式恢复：移动文件使它们相邻，并把所有的（至少是大部分的）空闲空间放在一个或多个大的连续的区域内。Windows 有一个程序 defrag 就是从事这个工作的。Windows 的用户应该定期使用它，当然，SSD 盘除外。

磁盘碎片整理程序会在一个在分区末端的连续区域内有大量空闲空间的文件系统上很好地运行。这段空间会允许磁盘碎片整理程序选择在分区开始端的碎片文件，并复制它们所有的块放到空闲空间内。这个动作在磁盘开始处释放出一个连续的块空间，这样原始或其他的文件可以在其中相邻地存放。这个过程可以在下一大块地磁盘空间上重复，并继续下去。

有些文件不能被移动，包括页文件、休眠文件以及日志，因为移动这些文件所需的管理成本要大于移动它们所获得的收益。在一些系统中，这些文件是固定大小的连续地区域，因此它们不需要进行碎片整理。这类文件缺乏灵活性会造成一些问题，一种情况是，它们恰好在分区的末端附近并且用户想减小分区的大小。解决这种问题的唯一的方法是把它们一起删除，改变分区的大小，然后再重新建立它们。

Linux 文件系统（特别是 ext2 和 ext3）由于其选择磁盘块的方式，在磁盘碎片整理上一般不会遭受像 Windows 那样的困难，因此很少需要手动的磁盘碎片整理。而且，固态硬盘并不受磁盘碎片的影响。事实上，在固态硬盘上做磁盘碎片整理反倒是多此一举，不仅没有提高性能，反而磨损了固态硬盘。所以碎片整理只会缩短固态硬盘的寿命。



#### 4.5	文件系统实例

略



#### 4.6	有关文件系统的研究

略



#### 4.7	小结

从外部看，文件系统是一组文件和目录，以及对文件和目录的操作。文件可以被读写，目录可以被创建和删除，并可将文件从一个目录移动另一个目录中。大多数现代操作系统都支持层次目录系统，其中，目录中还有子目录，子目录中还可以有子目录，如此无限下去。

而在内部看，文件系统又是另一番景象。文件系统的设计者必须考虑存储区是如何分配的，系统如何记录哪个块分给了哪个文件。可能的方案有连续文件、链表、文件分配表和 i 节点等。不同的系统有不同的目录结构。属性可以存在目录中或存在别处（比如，在 i 节点中）。磁盘空间可以通过位图的空闲表来管理。通过增量转储以及用程序修复故障文件系统的方法，可以调高文件系统的可靠性。文件系统的性能非常重要，可以通过多种途径提高性能，包括高速缓存、预读取以及尽可能仔细地将一个文件中的块紧密地放置在一起等方法。日志结构文件系统通过大块单元写入的操作也可以改善性能。

文件系统的例子有 ISO 9460、MS-DOS 以及 UNIX。它们之间在怎样记录每个文件所使用的块、目录结构以及对空闲磁盘空间管理等方面都存在着差别。





### 第 5 章	输入/输出

略























